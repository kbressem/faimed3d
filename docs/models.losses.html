---

title: Losses and metrics


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/05d_models.losses.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05d_models.losses.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>generate images for testing</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([(</span><span class="n">mask</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mask</span><span class="o">.</span><span class="n">unique</span><span class="p">()],</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[:,:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">pred_1</span> <span class="o">=</span> <span class="n">one_hot</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> 
<span class="n">pred_2</span> <span class="o">=</span> <span class="n">one_hot</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># prediction completely off</span>
<span class="n">pred_3</span> <span class="o">=</span> <span class="n">one_hot</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># prediction partly off</span>

<span class="n">show_images_3d</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="c1"># show_images_3d assumes [B x D x H x W]</span>
<span class="n">show_images_3d</span><span class="p">(</span><span class="n">pred_1</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="n">show_images_3d</span><span class="p">(</span><span class="n">pred_2</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="n">show_images_3d</span><span class="p">(</span><span class="n">pred_3</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>../faimed3d/basics.py:61: UserWarning: Object is not a rank 3 tensor but a rank 4 tensor. Assuming the 1st dimension is a (fake) color channel it will be removed
  warn(w)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-functions">Loss functions<a class="anchor-link" href="#Loss-functions"> </a></h2><h3 id="DICE-Loss">DICE Loss<a class="anchor-link" href="#DICE-Loss"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BaseLoss" class="doc_header"><code>class</code> <code>BaseLoss</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/models/losses.py#L13" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BaseLoss</code>(<strong><code>weights</code></strong>=<em><code>None</code></em>, <strong><code>avg</code></strong>=<em><code>'macro'</code></em>)</p>
</blockquote>
<p>Base class for loss functions</p>
<p>Args:
    targ:    A tensor of shape [B, C, D, H, W].
    pred:    A tensor of shape [B, C, D, H, W]. Corresponds to
             the raw output or logits of the model.
    weights: A list ot tuple, giving weights for each class or None
    avg:     'macro' computes loss for each B x C and averages the losses
             'micro' computes loss for each B and acverages the losses
Returns:
    loss:    computed loss (scalar)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DiceLoss" class="doc_header"><code>class</code> <code>DiceLoss</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/models/losses.py#L62" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DiceLoss</code>(<strong><code>method</code></strong>=<em><code>'miletari'</code></em>, <strong><code>alpha</code></strong>=<em><code>0.5</code></em>, <strong><code>beta</code></strong>=<em><code>0.5</code></em>, <strong><code>eps</code></strong>=<em><code>1e-07</code></em>, <strong><code>smooth</code></strong>=<em><code>1.0</code></em>, <strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/faimed3d/models.losses.html#BaseLoss"><code>BaseLoss</code></a></p>
</blockquote>
<p>Simple DICE loss as described in:
    <a href="https://arxiv.org/pdf/1911.02855.pdf">https://arxiv.org/pdf/1911.02855.pdf</a></p>
<p>Computes the Sørensen–Dice loss. Larger is better.
Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1.</p>
<p>Args:
    inherited from <a href="/faimed3d/models.losses.html#BaseLoss"><code>BaseLoss</code></a>
    targ:    A tensor of shape [B, C, D, H, W].
    pred:    A tensor of shape [B, C, D, H, W]. Corresponds to
             the raw output or logits of the model.
    weights: A list ot tuple, giving weights for each class or None
    avg:     'macro' computes loss for each B x C and averages the losses
             'micro' computes loss for each B and acverages the losses</p>

<pre><code>Unique for [`DiceLoss`](/faimed3d/models.losses.html#DiceLoss)
method:  The method, how the DICE score should be calcualted.
            "simple"   = standard DICE loss
            "miletari" = squared denominator for faster convergence
            "tversky"  = variant of the DICE loss which allows to weight FP vs FN.
alpha, beta: weights for FP and FN for "tversky" loss, if both values are 0.5 the
         "tversky" loss corresponds to the "simple" DICE loss
smooth:  Added smoothing factor.
eps: added to the denominator for numerical stability (acoid division by 0).
</code></pre>
<p>Returns:
    dice_loss: the Sørensen–Dice loss</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">DiceLoss</span><span class="p">()(</span><span class="n">pred_1</span><span class="p">,</span> <span class="n">mask</span><span class="p">),</span> <span class="n">DiceLoss</span><span class="p">()(</span><span class="n">pred_2</span><span class="p">,</span> <span class="n">mask</span><span class="p">),</span> <span class="n">DiceLoss</span><span class="p">()(</span><span class="n">pred_3</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(-0.0082), tensor(0.9960), tensor(0.2550))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="MCC-Loss">MCC Loss<a class="anchor-link" href="#MCC-Loss"> </a></h3><p>From Wikipedia (<a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">https://en.wikipedia.org/wiki/Matthews_correlation_coefficient</a>):</p>
<blockquote><p>The coefficient takes into account true and false positives and negatives and is generally 
regarded as a balanced measure which can be used even if the classes are of very different sizes
The MCC is in essence a correlation coefficient between the observed 
and predicted binary classifications; it returns a value between −1 and +1. 
A coefficient of +1 represents a perfect prediction, 0 no better than random prediction
and −1 indicates total disagreement between prediction and observation</p>
</blockquote>
<p>Implementing the MCC score as loss function:$$\frac{         \sum_{i}^{n} p_{ i }g_{ i } * \sum_{i}^{n}  1-p_{ i } 1-g_{ i } +
        \sum_{i}^{n}  1-p_{ i } g_{ i } * \sum_{i}^{n}  p_{ i } 1-g_{ i }}{ \sqrt{ 
        (\sum_{i}^{n}  p_{ i } g_{ i } + \sum_{i}^{n}  1-p_{ i } g_{ i }) * 
        (\sum_{i}^{n}  p_{ i } g_{ i } + \sum_{i}^{n} p_{ i } 1-g_{ i }) *  
        (\sum_{i}^{n}  1-p_{ i } g_{ i } + \sum_{i}^{n} 1-p_{ i } 1-g_{ i }) * 
        (\sum_{i}^{n}  p_{ i } 1-g_{ i } + \sum_{i}^{n} 1-p_{ i } 1-g_{ i }) 
     } }$$</p>
<p>where p_i is the prediction for pixel i and g_i the corresponding ground truth pixel and gamma is the smoothing factor.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MCCLoss" class="doc_header"><code>class</code> <code>MCCLoss</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/models/losses.py#L124" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MCCLoss</code>(<strong><code>eps</code></strong>=<em><code>1e-07</code></em>, <strong><code>smooth</code></strong>=<em><code>1.0</code></em>, <strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/faimed3d/models.losses.html#BaseLoss"><code>BaseLoss</code></a></p>
</blockquote>
<p>Computes the MCC loss.</p>
<p>For this loss to work best, the input should be in range 0-1, e.g. enforced through a sigmoid or softmax.
Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1.
While the MCC score can become negative, the MCC loss should not go below 0</p>
<p>Args:
    inherited from <a href="/faimed3d/models.losses.html#BaseLoss"><code>BaseLoss</code></a>
    targ:    A tensor of shape [B, C, D, H, W].
    pred:    A tensor of shape [B, C, D, H, W]. Corresponds to
             the raw output or logits of the model.
    weights: A list ot tuple, giving weights for each class or None
    avg:     'macro' computes loss for each B x C and averages the losses
             'micro' computes loss for each B and acverages the losses</p>

<pre><code>Unique for [`MCCLoss`](/faimed3d/models.losses.html#MCCLoss)
smooth:  Smoothing factor, default is 1.
eps:     Added for numerical stability.

</code></pre>
<p>Returns:
    mmc_loss: loss based on Matthews correlation coefficient</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">MCCLoss</span><span class="p">()(</span><span class="n">pred_1</span><span class="p">,</span> <span class="n">mask</span><span class="p">),</span> <span class="n">MCCLoss</span><span class="p">()(</span><span class="n">pred_2</span><span class="p">,</span> <span class="n">mask</span><span class="p">),</span> <span class="n">MCCLoss</span><span class="p">()(</span><span class="n">pred_3</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(0.), tensor(1.9999), tensor(0.5342))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SoftMCCLoss</span><span class="p">(</span><span class="n">MCCLoss</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Same as MCCLoss but can handle float values in the mask (e.g. from MixUp). </span>
<span class="sd">    Example: </span>
<span class="sd">        t = torch.randn(2,5); t</span>
<span class="sd">        &gt;&gt;&gt; tensor([[ 0.9113, -0.7525, -2.1771, -0.2420, -0.2245],</span>
<span class="sd">                    [ 1.9503, -1.2903,  0.1201,  0.2830,  0.0473]])</span>
<span class="sd">                   </span>
<span class="sd">        MCCLoss().make_binary(t, 1)</span>
<span class="sd">        &gt;&gt;&gt; tensor([[0., 0., 0., 0., 0.],</span>
<span class="sd">                    [0., 0., 0., 0., 0.]])</span>
<span class="sd">        </span>
<span class="sd">        SoftMCCLoss().soft_binary(t, 0)</span>
<span class="sd">        &gt;&gt;&gt; tensor([[0.9113, 0.0000, 0.0000, 0.0000, 0.0000],</span>
<span class="sd">                    [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">soft_binary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">set_to_one</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">set_to_one</span> <span class="o">-</span> <span class="mf">0.49</span><span class="p">)</span> <span class="o">!=</span> <span class="n">t</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">set_to_one</span> <span class="o">+</span> <span class="mf">0.49</span><span class="p">),</span> 
                           <span class="n">t</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> 
                           <span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">set_to_one</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">to_one_hot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># remove the solitary color channel (if there is one) and set type to int64</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">soft_binary</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">set_to_one</span><span class="o">=</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">one_hot</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">SoftMCCLoss</span><span class="p">()(</span><span class="n">pred_1</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">WeightedMCCLoss</span><span class="p">(</span><span class="n">MCCLoss</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Weighted version of MCCLoss </span>
<span class="sd">    Note that class specific weight can still be added through `weights` during initialization. </span>
<span class="sd">    </span>
<span class="sd">    Args: </span>
<span class="sd">        alpha: weight for true positives</span>
<span class="sd">        beta: weight for false positives</span>
<span class="sd">        gamma: weight for false negatives</span>
<span class="sd">        delta: weight for true negatives</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">store_attr</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">dims</span><span class="p">):</span>
        <span class="n">tps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">input</span> <span class="o">*</span> <span class="n">target</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span> 
        <span class="n">fps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">input</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">target</span><span class="p">),</span> <span class="n">dims</span><span class="p">)</span> 
        <span class="n">fns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">input</span><span class="p">)</span> <span class="o">*</span> <span class="n">target</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span>
        <span class="n">tns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">input</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">target</span><span class="p">),</span> <span class="n">dims</span><span class="p">)</span>

        <span class="n">numerator</span> <span class="o">=</span> <span class="p">(</span><span class="n">tps</span> <span class="o">*</span> <span class="n">tns</span> <span class="o">-</span> <span class="n">fps</span> <span class="o">*</span> <span class="n">fns</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">smooth</span>
        <span class="n">denominator</span> <span class="o">=</span>  <span class="p">((</span><span class="n">tps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">fps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">fns</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">fps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">+</span> <span class="n">tns</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tns</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">+</span> <span class="n">fns</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">smooth</span>

        <span class="n">mcc_loss</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="p">(</span><span class="n">denominator</span><span class="p">)</span>

        <span class="k">return</span> <span class="mi">1</span><span class="o">-</span><span class="n">mcc_loss</span>
    
    <span class="k">def</span> <span class="nf">activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> 
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">WeightedMCCLoss</span><span class="p">()(</span><span class="n">pred_1</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

