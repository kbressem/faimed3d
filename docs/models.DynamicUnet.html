---

title: 3D UNet


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/05c_models.DynamicUnet.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05c_models.DynamicUnet.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">CAMVID_TINY</span><span class="p">)</span>
<span class="n">build_dls</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">SegmentationDataLoaders</span><span class="o">.</span><span class="n">from_label_func</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> 
                    <span class="n">bs</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">fnames</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;images&#39;</span><span class="p">),</span>
                    <span class="n">label_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">o</span><span class="p">:</span> <span class="n">path</span><span class="o">/</span><span class="s1">&#39;labels&#39;</span><span class="o">/</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">o</span><span class="o">.</span><span class="n">stem</span><span class="si">}</span><span class="s1">_P</span><span class="si">{</span><span class="n">o</span><span class="o">.</span><span class="n">suffix</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">codes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;codes.txt&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">body_3d</span> <span class="o">=</span> <span class="n">create_body</span><span class="p">(</span><span class="n">resnet18_3d</span><span class="p">)</span>
<span class="n">body_2d</span> <span class="o">=</span> <span class="n">create_body</span><span class="p">(</span><span class="n">resnet18</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">DynamicUnet</span><span class="p">(</span><span class="n">body_2d</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">))(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([5, 2, 100, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">DynamicUnet</span><span class="p">(</span><span class="n">SequentialEx</span><span class="p">):</span>
    <span class="s2">&quot;Create a U-Net from a given architecture.&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">blur</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">blur_final</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">self_attention</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">y_range</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_cross</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bottle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">defaults</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
                 <span class="n">init</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">imsize</span> <span class="o">=</span> <span class="n">img_size</span>
        <span class="n">sizes</span> <span class="o">=</span> <span class="n">model_sizes</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">imsize</span><span class="p">)</span>
        
        <span class="n">sz_chg_idxs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">_get_sz_change_idxs</span><span class="p">(</span><span class="n">sizes</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sfs</span> <span class="o">=</span> <span class="n">hook_outputs</span><span class="p">([</span><span class="n">encoder</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sz_chg_idxs</span><span class="p">],</span> <span class="n">detach</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">dummy_eval</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">imsize</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="n">ni</span> <span class="o">=</span> <span class="n">sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">middle_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">ni</span><span class="p">,</span> <span class="n">ni</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">act_cls</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type</span><span class="p">,</span> <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">imsize</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span>
                                    <span class="n">ConvLayer</span><span class="p">(</span><span class="n">ni</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">ni</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">act_cls</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type</span><span class="p">,</span> <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">imsize</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">middle_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">encoder</span><span class="p">,</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="n">ni</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">middle_conv</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sz_chg_idxs</span><span class="p">):</span>
            <span class="n">not_final</span> <span class="o">=</span> <span class="n">i</span><span class="o">!=</span><span class="nb">len</span><span class="p">(</span><span class="n">sz_chg_idxs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
            <span class="n">up_in_c</span><span class="p">,</span> <span class="n">x_in_c</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">do_blur</span> <span class="o">=</span> <span class="n">blur</span> <span class="ow">and</span> <span class="p">(</span><span class="n">not_final</span> <span class="ow">or</span> <span class="n">blur_final</span><span class="p">)</span>
            <span class="n">sa</span> <span class="o">=</span> <span class="n">self_attention</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">sz_chg_idxs</span><span class="p">)</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">unet_block</span> <span class="o">=</span> <span class="n">UnetBlock</span><span class="p">(</span><span class="n">up_in_c</span><span class="p">,</span> <span class="n">x_in_c</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sfs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">final_div</span><span class="o">=</span><span class="n">not_final</span><span class="p">,</span> <span class="n">blur</span><span class="o">=</span><span class="n">do_blur</span><span class="p">,</span> <span class="n">self_attention</span><span class="o">=</span><span class="n">sa</span><span class="p">,</span>
                                   <span class="n">act_cls</span><span class="o">=</span><span class="n">act_cls</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unet_block</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">unet_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">ni</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">imsize</span> <span class="o">!=</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">2</span><span class="p">:]:</span> <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PixelShuffle_ICNR</span><span class="p">(</span><span class="n">ni</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">act_cls</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ResizeToOrig</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">last_cross</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MergeLayer</span><span class="p">(</span><span class="n">dense</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="n">ni</span> <span class="o">+=</span> <span class="n">in_channels</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ni</span><span class="p">,</span> <span class="n">ni</span><span class="o">//</span><span class="mi">2</span> <span class="k">if</span> <span class="n">bottle</span> <span class="k">else</span> <span class="n">ni</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">act_cls</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">ni</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">ks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)]</span>
        <span class="n">apply_init</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]),</span> <span class="n">init</span><span class="p">)</span>
        <span class="c1">#apply_init(nn.Sequential(layers[2]), init)</span>
        <span class="k">if</span> <span class="n">y_range</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SigmoidRange</span><span class="p">(</span><span class="o">*</span><span class="n">y_range</span><span class="p">))</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;sfs&quot;</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">sfs</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_sizes</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">)):</span>
    <span class="s2">&quot;Pass a dummy input through the model `m` to get the various sizes of activations.&quot;</span>
    <span class="k">with</span> <span class="n">hook_outputs</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">as</span> <span class="n">hooks</span><span class="p">:</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">dummy_eval</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">o</span><span class="o">.</span><span class="n">stored</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">hooks</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">dummy_eval</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">)):</span>
    <span class="s2">&quot;Evaluate `m` on a dummy input of a certain `size`&quot;</span>
    <span class="n">ch_in</span> <span class="o">=</span> <span class="n">in_channels</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">one_param</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ch_in</span><span class="p">,</span> <span class="o">*</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">eval</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">in_channels</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="s2">&quot;Return the shape of the first weight layer in `m`.&quot;</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">flatten_model</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">l</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">l</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;No weight layer&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">DynamicUnet</span><span class="p">(</span><span class="n">body_3d</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-24-c5d6b2d6af4f&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>DynamicUnet<span class="ansi-blue-fg">(</span>body_3d<span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">10</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">100</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">100</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/fastcore/meta.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(cls, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     36</span>         <span class="ansi-green-fg">if</span> type<span class="ansi-blue-fg">(</span>res<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">==</span>cls<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     37</span>             <span class="ansi-green-fg">if</span> hasattr<span class="ansi-blue-fg">(</span>res<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">&#39;__pre_init__&#39;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> res<span class="ansi-blue-fg">.</span>__pre_init__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 38</span><span class="ansi-red-fg">             </span>res<span class="ansi-blue-fg">.</span>__init__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     39</span>             <span class="ansi-green-fg">if</span> hasattr<span class="ansi-blue-fg">(</span>res<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">&#39;__post_init__&#39;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> res<span class="ansi-blue-fg">.</span>__post_init__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     40</span>         <span class="ansi-green-fg">return</span> res

<span class="ansi-green-fg">&lt;ipython-input-20-fecd9056583b&gt;</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, encoder, n_classes, img_size, blur, blur_final, self_attention, y_range, last_cross, bottle, act_cls, init, norm_type, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>                                    act_cls=act_cls, init=init, norm_type=norm_type, **kwargs).eval()
<span class="ansi-green-intense-fg ansi-bold">     26</span>             layers<span class="ansi-blue-fg">.</span>append<span class="ansi-blue-fg">(</span>unet_block<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 27</span><span class="ansi-red-fg">             </span>x <span class="ansi-blue-fg">=</span> unet_block<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     28</span> 
<span class="ansi-green-intense-fg ansi-bold">     29</span>         ni <span class="ansi-blue-fg">=</span> x<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/fastai/vision/models/unet.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, up_in)</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> up_in<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     34</span>         s <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>hook<span class="ansi-blue-fg">.</span>stored
<span class="ansi-green-fg">---&gt; 35</span><span class="ansi-red-fg">         </span>up_out <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>shuf<span class="ansi-blue-fg">(</span>up_in<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     36</span>         ssh <span class="ansi-blue-fg">=</span> s<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     37</span>         <span class="ansi-green-fg">if</span> ssh <span class="ansi-blue-fg">!=</span> up_out<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    421</span> 
<span class="ansi-green-intense-fg ansi-bold">    422</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 423</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_conv_forward<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>weight<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    424</span> 
<span class="ansi-green-intense-fg ansi-bold">    425</span> <span class="ansi-green-fg">class</span> Conv3d<span class="ansi-blue-fg">(</span>_ConvNd<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ansi-cyan-fg">_conv_forward</span><span class="ansi-blue-fg">(self, input, weight)</span>
<span class="ansi-green-intense-fg ansi-bold">    418</span>                             _pair(0), self.dilation, self.groups)
<span class="ansi-green-intense-fg ansi-bold">    419</span>         return F.conv2d(input, weight, self.bias, self.stride,
<span class="ansi-green-fg">--&gt; 420</span><span class="ansi-red-fg">                         self.padding, self.dilation, self.groups)
</span><span class="ansi-green-intense-fg ansi-bold">    421</span> 
<span class="ansi-green-intense-fg ansi-bold">    422</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">RuntimeError</span>: Expected 4-dimensional input for 4-dimensional weight [1024, 512, 1, 1], but got 5-dimensional input of size [1, 512, 1, 7, 7] instead</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>UnetBlock<span class="o">??</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea ">
<pre><span class="ansi-red-fg">Init signature:</span>
UnetBlock<span class="ansi-blue-fg">(</span>
    up_in_c<span class="ansi-blue-fg">,</span>
    x_in_c<span class="ansi-blue-fg">,</span>
    hook<span class="ansi-blue-fg">,</span>
    final_div<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span>
    blur<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>
    act_cls<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&lt;</span><span class="ansi-green-fg">class</span> <span class="ansi-blue-fg">&#39;torch.nn.modules.activation.ReLU&#39;</span><span class="ansi-blue-fg">&gt;</span><span class="ansi-blue-fg">,</span>
    self_attention<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>
    init<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&lt;</span>function kaiming_normal_ at <span class="ansi-cyan-fg">0x7f1773681320</span><span class="ansi-blue-fg">&gt;</span><span class="ansi-blue-fg">,</span>
    norm_type<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>
    ks<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">3</span><span class="ansi-blue-fg">,</span>
    stride<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span>
    padding<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>
    bias<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>
    ndim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span>
    bn_1st<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span>
    transpose<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>
    xtra<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>
    bias_std<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.01</span><span class="ansi-blue-fg">,</span>
    dilation<span class="ansi-blue-fg">:</span> Union<span class="ansi-blue-fg">[</span>int<span class="ansi-blue-fg">,</span> Tuple<span class="ansi-blue-fg">[</span>int<span class="ansi-blue-fg">,</span> int<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span>
    groups<span class="ansi-blue-fg">:</span> int <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span>
    padding_mode<span class="ansi-blue-fg">:</span> str <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">&#39;zeros&#39;</span><span class="ansi-blue-fg">,</span>
<span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Source:</span>        
<span class="ansi-green-fg">class</span> UnetBlock<span class="ansi-blue-fg">(</span>Module<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
    <span class="ansi-blue-fg">&#34;A quasi-UNet block, using `PixelShuffle_ICNR upsampling`.&#34;</span>
    <span class="ansi-blue-fg">@</span>delegates<span class="ansi-blue-fg">(</span>ConvLayer<span class="ansi-blue-fg">.</span>__init__<span class="ansi-blue-fg">)</span>
    <span class="ansi-green-fg">def</span> __init__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> up_in_c<span class="ansi-blue-fg">,</span> x_in_c<span class="ansi-blue-fg">,</span> hook<span class="ansi-blue-fg">,</span> final_div<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> blur<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span> act_cls<span class="ansi-blue-fg">=</span>defaults<span class="ansi-blue-fg">.</span>activation<span class="ansi-blue-fg">,</span>
                 self_attention<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span> init<span class="ansi-blue-fg">=</span>nn<span class="ansi-blue-fg">.</span>init<span class="ansi-blue-fg">.</span>kaiming_normal_<span class="ansi-blue-fg">,</span> norm_type<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        self<span class="ansi-blue-fg">.</span>hook <span class="ansi-blue-fg">=</span> hook
        self<span class="ansi-blue-fg">.</span>shuf <span class="ansi-blue-fg">=</span> PixelShuffle_ICNR<span class="ansi-blue-fg">(</span>up_in_c<span class="ansi-blue-fg">,</span> up_in_c<span class="ansi-blue-fg">//</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span> blur<span class="ansi-blue-fg">=</span>blur<span class="ansi-blue-fg">,</span> act_cls<span class="ansi-blue-fg">=</span>act_cls<span class="ansi-blue-fg">,</span> norm_type<span class="ansi-blue-fg">=</span>norm_type<span class="ansi-blue-fg">)</span>
        self<span class="ansi-blue-fg">.</span>bn <span class="ansi-blue-fg">=</span> BatchNorm<span class="ansi-blue-fg">(</span>x_in_c<span class="ansi-blue-fg">)</span>
        ni <span class="ansi-blue-fg">=</span> up_in_c<span class="ansi-blue-fg">//</span><span class="ansi-cyan-fg">2</span> <span class="ansi-blue-fg">+</span> x_in_c
        nf <span class="ansi-blue-fg">=</span> ni <span class="ansi-green-fg">if</span> final_div <span class="ansi-green-fg">else</span> ni<span class="ansi-blue-fg">//</span><span class="ansi-cyan-fg">2</span>
        self<span class="ansi-blue-fg">.</span>conv1 <span class="ansi-blue-fg">=</span> ConvLayer<span class="ansi-blue-fg">(</span>ni<span class="ansi-blue-fg">,</span> nf<span class="ansi-blue-fg">,</span> act_cls<span class="ansi-blue-fg">=</span>act_cls<span class="ansi-blue-fg">,</span> norm_type<span class="ansi-blue-fg">=</span>norm_type<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
        self<span class="ansi-blue-fg">.</span>conv2 <span class="ansi-blue-fg">=</span> ConvLayer<span class="ansi-blue-fg">(</span>nf<span class="ansi-blue-fg">,</span> nf<span class="ansi-blue-fg">,</span> act_cls<span class="ansi-blue-fg">=</span>act_cls<span class="ansi-blue-fg">,</span> norm_type<span class="ansi-blue-fg">=</span>norm_type<span class="ansi-blue-fg">,</span>
                               xtra<span class="ansi-blue-fg">=</span>SelfAttention<span class="ansi-blue-fg">(</span>nf<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">if</span> self_attention <span class="ansi-green-fg">else</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
        self<span class="ansi-blue-fg">.</span>relu <span class="ansi-blue-fg">=</span> act_cls<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
        apply_init<span class="ansi-blue-fg">(</span>nn<span class="ansi-blue-fg">.</span>Sequential<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>conv1<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>conv2<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> init<span class="ansi-blue-fg">)</span>

    <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> up_in<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        s <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>hook<span class="ansi-blue-fg">.</span>stored
        up_out <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>shuf<span class="ansi-blue-fg">(</span>up_in<span class="ansi-blue-fg">)</span>
        ssh <span class="ansi-blue-fg">=</span> s<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span>
        <span class="ansi-green-fg">if</span> ssh <span class="ansi-blue-fg">!=</span> up_out<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span>
            up_out <span class="ansi-blue-fg">=</span> F<span class="ansi-blue-fg">.</span>interpolate<span class="ansi-blue-fg">(</span>up_out<span class="ansi-blue-fg">,</span> s<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> mode<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;nearest&#39;</span><span class="ansi-blue-fg">)</span>
        cat_x <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>torch<span class="ansi-blue-fg">.</span>cat<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>up_out<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>bn<span class="ansi-blue-fg">(</span>s<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
        <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>conv2<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>conv1<span class="ansi-blue-fg">(</span>cat_x<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">File:</span>           ~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/fastai/vision/models/unet.py
<span class="ansi-red-fg">Type:</span>           PrePostInitMeta
<span class="ansi-red-fg">Subclasses:</span>     
</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

