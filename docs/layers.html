---

title: Layers


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/05_layers.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_layers.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/radiopaedia_cases.csv&#39;</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">ImageDataLoaders3D</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> 
                                 <span class="n">item_tfms</span> <span class="o">=</span> <span class="n">ResizeCrop3D</span><span class="p">(</span><span class="n">crop_by</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">resize_to</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span> <span class="n">perc_crop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">),</span>
                                 <span class="n">bs</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
                                 <span class="n">val_bs</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">body_3d</span> <span class="o">=</span> <span class="n">create_body</span><span class="p">(</span><span class="n">resnet50_3d</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Helper-functions">Helper functions<a class="anchor-link" href="#Helper-functions"> </a></h2><p>Some functions from <code>fastai.layers</code> are needed to construct learners (see next notebook). For this some slight modifications had to be made. 
The <code>in_channel</code> function had to be modified to also accept 3D models wich have 5D weights and the <a href="/layers.html#num_features_model"><code>num_features_model</code></a> function was adapted to pass a size tuple of len 3 instead of 2. The other functions were not changed but copied to avoid conflicts when loaded directly from fastai.<br>
<a href="/learner.html#cnn_learner_3d"><code>cnn_learner_3d</code></a> is essentially the same function as fastais <code>cnn_learner</code>, just adds a new callback.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/layers.html#in_channels"><code>in_channels</code></a> from fastai only returns a result if <code>weight.ndim == 4</code> but in 3D convolutional layers, it will be 5 dimensions, so the functions has to be adapted.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="in_channels" class="doc_header"><code>in_channels</code><a href="https://github.com/fastai/fastai/tree/master/fastai/layers.py#L597" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>in_channels</code>(<strong><code>m</code></strong>)</p>
</blockquote>

<pre><code>Return the shape of the first weight layer in `m`.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/layers.html#num_features_model"><code>num_features_model</code></a> is unchanged, but needs to be defined here to correctly call the adapted <a href="/layers.html#in_channels"><code>in_channels</code></a> function</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="num_features_model" class="doc_header"><code>num_features_model</code><a href="https://github.com/fastai/fastai/tree/master/fastai/callback/hook.py#L88" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>num_features_model</code>(<strong><code>m</code></strong>)</p>
</blockquote>

<pre><code>Return the number of output features for `m`.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>model_sizes</code> and <a href="/layers.html#dummy_eval_4d"><code>dummy_eval_4d</code></a> both need to be extendet to handle multiple inputs in form of lists.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="model_sizes_4d" class="doc_header"><code>model_sizes_4d</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L50" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>model_sizes_4d</code>(<strong><code>m</code></strong>, <strong><code>size</code></strong>=<em><code>(8, 64, 64)</code></em>, <strong><code>n_inp</code></strong>=<em><code>1</code></em>)</p>
</blockquote>

<pre><code>Pass a dummy input through the model `m` to get the various sizes of activations. same as fastai func</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="dummy_eval_4d" class="doc_header"><code>dummy_eval_4d</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L57" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>dummy_eval_4d</code>(<strong><code>m</code></strong>, <strong><code>size</code></strong>=<em><code>(8, 64, 64)</code></em>, <strong><code>n_inp</code></strong>=<em><code>1</code></em>)</p>
</blockquote>

<pre><code>Evaluate `m` on a dummy input of a certain `size`. Same as fastai func</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>create_cnn_model</code> is unchanged, but needs to be redefined to correctly call <a href="/layers.html#num_features_model"><code>num_features_model</code></a> which then calls the changed <a href="/layers.html#in_channels"><code>in_channels</code></a> function</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4D-modules">4D modules<a class="anchor-link" href="#4D-modules"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If a radiologists views an image, he or she looks at multiple sequences and tries to combine information for those sequences. We want our network to be able to do the same. So, if we pass multiple inputs, information from one sequence should be kept when a second sequence is passed (similar to a RNN). But we also want to use pretrained networks, so building a new recurrent CNN is not possible. Faimed3d tries to address this issue by making those parts of the CNN recurrent, in which the size of input and output is the same.</p>

</div>
</div>
</div># export
class MultiStem(SequentialEx):
    'applies one input of inputs to only one layer of layers'
    def forward(self, inputs)->list:
        out = []
        for i, inp in enumerate(inputs):
            out.append(self.layers[i](inp))
        return out
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After this, we send the feature maps from each stem through the same encoder. This is achieved by the <a href="/layers.html#RepeatedSequential"><code>RepeatedSequential</code></a> class, which takes a list of tensors and applies it's modules to each element of the list. A list of tensors is then returned again so that multiple instances of <a href="/layers.html#RepeatedSequential"><code>RepeatedSequential</code></a> can be chained after each other.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="RepeatedSequential" class="doc_header"><code>class</code> <code>RepeatedSequential</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L64" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>RepeatedSequential</code>(<strong>*<code>layers</code></strong>) :: <code>SequentialEx</code></p>
</blockquote>

<pre><code>passes multiple inputs through the same neural network</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}
# export
class RecurrentSequential(SequentialEx):
    "Makes some parts of the network recurrent"
    def __init__(self, *args):
        "reduces some of the hierachical structure of the network"
        super().__init__(*[submodule for module in args for submodule in module])
    
    def forward(self, inputs):
        inputs = [inputs] if isinstance(inputs, Tensor) else list(inputs)
        shuffle(inputs)    
        for module in self: 
            out = None
            for i, inp in enumerate(inputs): 
                if isinstance(out, Tensor) and out.shape == inp.shape: inp += out
                out = module(inp)
                inputs[i]=out
        return inputs

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The main encoder for the UNet is build with <a href="/layers.html#Arch4D"><code>Arch4D</code></a>, which takes an encoder, splits the stem and body and converts the stem to a <code>MultiStem</code> and the submodules of the body to <a href="/layers.html#RepeatedSequential"><code>RepeatedSequential</code></a>. <a href="/layers.html#Arch4D"><code>Arch4D</code></a> can be indexed as the normal encoder and has the same number of subclasses. If outputs are hooked in <a href="/layers.html#Arch4D"><code>Arch4D</code></a> it will return a list.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Arch4D" class="doc_header"><code>class</code> <code>Arch4D</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L72" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Arch4D</code>(<strong><code>arch</code></strong>, <strong><code>n_inp</code></strong>) :: <code>SequentialEx</code></p>
</blockquote>

<pre><code>repeatedly applies the same network to different inputs</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}
# export
class Arch4D(SequentialEx):
    'repeatedly applies the same network to different inputs'
    def __init__(self, arch, n_inp):
        layers = [RecurrentSequential(l) for l in arch] 
        self.layers = nn.ModuleList(layers)

    def forward(self, inputs):
        for l in self.layers:
            inputs = l(inputs)
        return inputs

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Arch4D</span><span class="p">(</span><span class="n">body_3d</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">)))</span>
<span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">),</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, torch.Size([10, 2048, 2, 2, 2]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Arch4D</span><span class="p">(</span><span class="n">body_3d</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">)])</span>
<span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([10, 2048, 2, 2, 2])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_sizes_4d</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">n_inp</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[torch.Size([1, 128, 9, 21, 21]),
 torch.Size([1, 256, 9, 21, 21]),
 torch.Size([1, 512, 5, 11, 11]),
 torch.Size([1, 1024, 3, 6, 6]),
 torch.Size([1, 2048, 2, 3, 3])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/layers.html#Arch4D"><code>Arch4D</code></a> returns a list of tensors, which needs to be concatenated for further processing.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Concat" class="doc_header"><code>class</code> <code>Concat</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L86" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Concat</code>(<strong><code>ni</code></strong>, <strong><code>ndim</code></strong>, <strong><code>dim</code></strong>=<em><code>1</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Same as `nn.Module`, but no need for subclasses to call `super().__init__`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>fastai</code> performes adaptive concat pooling as first step in the new header, which is adapted to 3D.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AdaptiveConcatPool3d" class="doc_header"><code>class</code> <code>AdaptiveConcatPool3d</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L97" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AdaptiveConcatPool3d</code>(<strong><code>size</code></strong>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Layer that concats `AdaptiveAvgPool3d` and `AdaptiveMaxPool3d`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Wrapper-for-4D-models">Wrapper for 4D models<a class="anchor-link" href="#Wrapper-for-4D-models"> </a></h2><p>In radiology, multiple sequences are often needed for a diagnosis. For example, while viewing a head MRI, T2, DWI and ADC map have to be viewed together for a stroke diagnosis and to advoid false diagnosis from T2 shine trough. The data effectively becomes 4D. There are no modules for 4D convolution, so a workaround needs to be defined which processes the multiple 3D volumes after each other and then pools the information. The models should also still work with available pretrained 3D models, so no completely new architectures are defined in <code>faimed3d</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When using multiple inputs, <code>nn.Sequential</code> will not work as it expects only two inputs (self and input). Therefore, a subclass is defined, which accepts multiple inputs and converts those into a tuple, which is then passed to the modules. The first element of the final model will be the <code>MultiStem</code> which expects a list of tensors and returns a list of tensors. The next submodules are <code>RepeatedSequentials</code> which again take in and return a list of tensors. Next is the concat module, which will take in a list but return a single tensor, so the normal <code>fastai</code> head can be used.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Sequential4D" class="doc_header"><code>class</code> <code>Sequential4D</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L106" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Sequential4D</code>(<strong>*<code>args</code></strong>:<code>Any</code>) :: <code>Sequential</code></p>
</blockquote>

<pre><code>A sequential container.
Modules will be added to it in the order they are passed in the constructor.
Alternatively, an ordered dict of modules can also be passed in.

To make it easier to understand, here is a small example::

    # Example of using Sequential
    model = nn.Sequential(
              nn.Conv2d(1,20,5),
              nn.ReLU(),
              nn.Conv2d(20,64,5),
              nn.ReLU()
            )

    # Example of using Sequential with OrderedDict
    model = nn.Sequential(OrderedDict([
              ('conv1', nn.Conv2d(1,20,5)),
              ('relu1', nn.ReLU()),
              ('conv2', nn.Conv2d(20,64,5)),
              ('relu2', nn.ReLU())
            ]))</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When <code>fastai</code> creates a new model head, first the input is pooled with <code>AdaptiveConcatPool</code>, then flattened and passed trough two linear layers. This might not be the best approach for multiple inputs, as the first layer would receive <code>n_inp</code> <em> <code>n_features</code> inputs and reduce it to 512 features. So the first linear layer will reduce the feature information more than the second. So in <code>faimed3d</code>, an additional convolutional layer with kernel size 1 and stride 1 is used to pool the number of features from <code>n_features</code> </em> <code>n_inp</code> to <code>n_features</code>. Then, the normal <code>fastai</code> head is added. We added the last convolutional layer to the head, so that the freeze and unfreeze operations of <code>fastai</code> still work as expected.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_head" class="doc_header"><code>create_head</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L114" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_head</code>(<strong><code>nf</code></strong>, <strong><code>n_out</code></strong>, <strong><code>n_inp</code></strong>=<em><code>None</code></em>, <strong><code>lin_ftrs</code></strong>=<em><code>None</code></em>, <strong><code>ps</code></strong>=<em><code>0.5</code></em>, <strong><code>concat_pool</code></strong>=<em><code>True</code></em>, <strong><code>bn_final</code></strong>=<em><code>False</code></em>, <strong><code>lin_first</code></strong>=<em><code>False</code></em>, <strong><code>y_range</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

<pre><code>Model head that takes `nf` features, runs through `lin_ftrs`, and out `n_out` classes.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>create_cnn_model_4d</code> is similar to <code>create_cnn_model</code> but expects <code>n_inp</code> as additional argument. Depending on <code>n_inp</code>, the respective network is constructed.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_cnn_model_3d" class="doc_header"><code>create_cnn_model_3d</code><a href="https://github.com/kbressem/faimed3d/tree/master/faimed3d/layers.py#L137" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_cnn_model_3d</code>(<strong><code>arch</code></strong>, <strong><code>n_out</code></strong>, <strong><code>n_inp</code></strong>, <strong><code>cut</code></strong>=<em><code>None</code></em>, <strong><code>pretrained</code></strong>=<em><code>True</code></em>, <strong><code>n_in</code></strong>=<em><code>3</code></em>, <strong><code>init</code></strong>=<em><code>kaiming_normal_</code></em>, <strong><code>custom_head</code></strong>=<em><code>None</code></em>, <strong><code>concat_pool</code></strong>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>

<pre><code>Create custom convnet architecture using `arch`, `n_in` and `n_out`. Identical to fastai func</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">create_cnn_model_3d</span><span class="p">(</span><span class="n">resnet50_3d</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pretrained</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 2])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h6 id="-"> <a class="anchor-link" href="#-"> </a></h6>
</div>
</div>
</div>
</div>
 

