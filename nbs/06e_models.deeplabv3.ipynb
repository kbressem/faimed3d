{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabV3+\n",
    "> 3D implementation of DeepLabV3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.deeplab\n",
    "# export \n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import create_body, hook_outputs\n",
    "from fastai.vision.models.unet import _get_sz_change_idxs\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.layers import *\n",
    "from faimed3d.models.unet import ResizeToOrig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SequentialExForDeepLab(Module):\n",
    "    \"\"\"Like `nn.Sequential`, but with ModuleList semantics, and can access module input. \n",
    "    Also supports hybrid classification and segmentation models\"\"\"\n",
    "    def __init__(self, *layers): self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for l in self.layers:\n",
    "            res.orig = x\n",
    "            nres = l(res)\n",
    "            # We have to remove res.orig to avoid hanging refs and therefore memory leaks\n",
    "            res.orig, nres.orig = None, None\n",
    "            res = nres\n",
    "        if hasattr(res, 'class_pred'): \n",
    "            class_pred = res.class_pred\n",
    "            res.class_pred = None\n",
    "            return res, class_pred\n",
    "        return res\n",
    "\n",
    "    def __getitem__(self,i): return self.layers[i]\n",
    "    def append(self,l):      return self.layers.append(l)\n",
    "    def extend(self,l):      return self.layers.extend(l)\n",
    "    def insert(self,i,l):    return self.layers.insert(i,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLabV3+\n",
    "\n",
    "Implementation of DeepLabV3+ for 3D. Translates the 2D version from https://github.com/giovanniguidi/deeplabV3-PyTorch to 3D. Adds the functionality to allow mulitple encoders, similar to DynamicUnet. However, works probably best with larger encoders, such as ResNet50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASPP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ASPPPooling(nn.Sequential):\n",
    "    \"Pooling Layer for ASPP\"\n",
    "    def __init__(self, ni, nf, norm_type=None, act_cls=defaults.activation):\n",
    "        super(ASPPPooling, self).__init__(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            ConvLayer(ni=ni, nf=nf, ks=1, ndim=3, bias=False, norm_type=None, act_cls=act_cls)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[-3:]\n",
    "        for module in self:\n",
    "            x = module(x)\n",
    "        return F.interpolate(x, size=size, mode='trilinear', align_corners=False)\n",
    "\n",
    "\n",
    "class ASPP(SequentialExForDeepLab):\n",
    "    \"3D Atrous Spatial Pyramid Pooling\"\n",
    "    def __init__(self, ni, dilations, nf, norm_type=None, act_cls=defaults.activation, ps=0.5):\n",
    "        conv_layers = [ConvLayer(ni=ni, nf=nf, ks=1, bias=False, ndim=3, norm_type=norm_type, act_cls=act_cls)]\n",
    "        dilations = tuple(dilations)\n",
    "        for dilation in dilations:\n",
    "            conv_layers.append(ConvLayer(ni=ni, nf=nf, ndim=3, ks=3, dilation=dilation, padding=dilation, \n",
    "                                         norm_type=norm_type, act_cls=act_cls))\n",
    "        pooling = ASPPPooling(ni=ni, nf=nf, norm_type=norm_type, act_cls=act_cls)\n",
    "        self.layers = nn.ModuleList([*conv_layers, pooling])\n",
    "        self.project = nn.Sequential(\n",
    "            ConvLayer(ni=len(self.layers)*nf, nf=nf, ks=1, bias=False, ndim=3, \n",
    "            norm_type=norm_type, act_cls=act_cls),\n",
    "            nn.Dropout(ps))\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = [module(x) for module in self.layers]\n",
    "        return self.project(torch.cat(res, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 1, 3, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASPP(ni=2048, dilations=[1, 6, 12, 18], nf=256, norm_type=NormType.Batch)(torch.randn(10, 2048, 1, 3, 3)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 1, 3, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASPP(ni=2048, dilations=[1, 12, 24, 36], nf=256, norm_type=NormType.Batch)(torch.randn(10, 2048, 1, 3, 3)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DeepLabDecoder(Module):\n",
    "    \"Decoder Block for DynamicDeeplab\"\n",
    "    def __init__(self, ni, low_lvl_ni, hook, n_out, norm_type=None, \n",
    "                 act_cls=defaults.activation, ps=0.5):\n",
    "        self.hook = hook\n",
    "        \n",
    "        self.low_lvl_conv = ConvLayer(low_lvl_ni, low_lvl_ni//2, ks=1, ndim=3, bias=False, \n",
    "                                      norm_type=norm_type, act_cls=act_cls)\n",
    "\n",
    "        self.last_conv = nn.Sequential(\n",
    "                ConvLayer(ni+low_lvl_ni//2, ni, ks=3, ndim=3, stride=1, padding=1, bias=False, \n",
    "                          norm_type=norm_type, act_cls=act_cls), \n",
    "                nn.Dropout(ps),\n",
    "                ConvLayer(ni, ni, ks=3, ndim=3, stride=1, padding=1, bias=False, \n",
    "                          norm_type=norm_type, act_cls=act_cls), \n",
    "                nn.Dropout(ps/5),\n",
    "                nn.Conv3d(ni, n_out, kernel_size=1, stride=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.low_lvl_conv(sum(self.hook.stored))\n",
    "        ssh = s.shape[-3:]\n",
    "        if ssh != x.shape[-3:]:\n",
    "            x = F.interpolate(x, size=ssh, mode='nearest')\n",
    "        x = torch.cat((x, s), dim=1)\n",
    "        return self.last_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DeepLabClassifier(Module):\n",
    "    \"Decoder Block for DynamicDeeplab\"\n",
    "    def __init__(self, ni, n_out, hook, norm_type=None, \n",
    "                 act_cls=defaults.activation, ps=0.25):\n",
    "        self.hook = hook\n",
    "        self.pool = AdaptiveConcatPool3d(1)\n",
    "        self.fc = LinBnDrop(ni*2, n_out, act = act_cls(), p = ps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.pool(sum(self.hook.stored))\n",
    "        x.class_pred = self.fc(s.flatten(1))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DynamicDeepLab(SequentialExForDeepLab):\n",
    "    \"Build DeepLab with different encoders\"\n",
    "    def __init__(self, encoder, n_out, img_size, y_range=None, add_classifier=False, n_out_classifier=2,\n",
    "                       act_cls=defaults.activation, norm_type=NormType.Batch, **kwargs):\n",
    "        \n",
    "        sizes = model_sizes(encoder, size=img_size)\n",
    "        sz_chg_idxs = list(_get_sz_change_idxs(sizes))        \n",
    "        self.sfs = [hook_outputs(encoder[sz_chg_idxs[1]], detach=False)]\n",
    "        if add_classifier: \n",
    "            self.sfs.append(hook_outputs(encoder[len(encoder)-1], detach=False))\n",
    "    \n",
    "        x = dummy_eval(encoder, img_size).detach()\n",
    "        ni = sizes[-1][1]\n",
    "        nf = ni//4\n",
    "        dilations=[1, 12, 24, 36] if ni > 512 else [1, 6, 12, 18]\n",
    "        aspp = ASPP(ni=ni, nf=nf, dilations=dilations, norm_type=norm_type, act_cls=act_cls).eval()\n",
    "        x = aspp(x)\n",
    "        decoder = DeepLabDecoder(ni=nf, low_lvl_ni=sizes[sz_chg_idxs[1]][1], hook=self.sfs[0], n_out=n_out, \n",
    "                                 norm_type=norm_type, act_cls=act_cls).eval()\n",
    "        x = decoder(x)\n",
    "                   \n",
    "        self.layers = nn.ModuleList([encoder, aspp, decoder, ResizeToOrig()])\n",
    "        \n",
    "        if add_classifier: \n",
    "            assert n_out_classifier, 'Number of classes need to be specified'\n",
    "            self.layers.append(DeepLabClassifier(ni, n_out_classifier, self.sfs[1]))\n",
    "\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, \"sfs\"): self.sfs.remove()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.video import r3d_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_3d = create_body(r3d_18, pretrained = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DynamicDeepLab(body_3d, 2, (20, 64, 64), add_classifier=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 20, 64, 64]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = m(torch.randn(2,3,20,64,64))\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_basics.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_transforms.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_layers.ipynb.\n",
      "Converted 06_learner.ipynb.\n",
      "Converted 06a_models.alexnet.ipynb.\n",
      "Converted 06b_models.resnet.ipynb.\n",
      "Converted 06c_model.efficientnet.ipynb.\n",
      "Converted 06d_models.unet.ipynb.\n",
      "Converted 06e_models.deeplabv3.ipynb.\n",
      "Converted 06f_models.losses.ipynb.\n",
      "Converted 07_callback.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
