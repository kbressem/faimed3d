{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabV3+\n",
    "> 3D implementation of DeepLabV3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.deeplab\n",
    "# export \n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import create_body, hook_outputs\n",
    "from fastai.vision.models.unet import _get_sz_change_idxs\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.layers import *\n",
    "from faimed3d.models.unet import AddItems, SequentialEx4D, ResizeToOrig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLabV3+\n",
    "\n",
    "Implementation of DeepLabV3+ for 3D. Translates the 2D version from https://github.com/giovanniguidi/deeplabV3-PyTorch to 3D. Adds the functionality to allow mulitple encoders, similar to DynamicUnet. However, works probably best with larger encoders, such as ResNet50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASPP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ASPPPooling(nn.Sequential):\n",
    "    def __init__(self, ni, nf, norm_type=None, act_cls=defaults.activation):\n",
    "        super(ASPPPooling, self).__init__(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            ConvLayer(ni=ni, nf=nf, ks=1, ndim=3, bias=False, norm_type=norm_type, act_cls=act_cls)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[-3:]\n",
    "        for module in self:\n",
    "            x = module(x)\n",
    "        return F.interpolate(x, size=size, mode='trilinear', align_corners=False)\n",
    "\n",
    "\n",
    "class ASPP(SequentialEx):\n",
    "    def __init__(self, ni, dilations, nf, norm_type=None, act_cls=defaults.activation, ps=0.5):\n",
    "\n",
    "        conv_layers = [ConvLayer(ni=ni, nf=nf, ks=1, bias=False, ndim=3, norm_type=norm_type, act_cls=act_cls)]\n",
    "\n",
    "        dilations = tuple(dilations)\n",
    "        for dilation in dilations:\n",
    "            conv_layers.append(ConvLayer(ni=ni, nf=nf, ndim=3, dilation=dilation, padding=dilation, \n",
    "                                    norm_type=norm_type, act_cls=act_cls))\n",
    "            \n",
    "        pooling = ASPPPooling(ni=ni, nf=nf, norm_type=norm_type, act_cls=act_cls)\n",
    "\n",
    "        self.layers = nn.ModuleList([*conv_layers, pooling])\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            ConvLayer(ni=len(self.layers)*nf, nf=nf, ks=1, bias=False, ndim=3, \n",
    "            norm_type=norm_type, act_cls=act_cls),\n",
    "            nn.Dropout(ps))\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = [module(x) for module in self.layers]\n",
    "        res = torch.cat(res, dim=1)\n",
    "        return self.project(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 1, 3, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASPP(ni=2048, dilations=[1, 6, 12, 18], nf=256, norm_type=NormType.Batch)(torch.randn(10, 2048, 1, 3, 3)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 1, 3, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASPP(ni=2048, dilations=[1, 12, 24, 36], nf=256, norm_type=NormType.Batch)(torch.randn(10, 2048, 1, 3, 3)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DeepLabDecoder(Module):\n",
    "    def __init__(self, ni, low_lvl_ni, hook, n_out, norm_type=None, \n",
    "                 act_cls=defaults.activation, ps=0.5):\n",
    "        self.hook = hook\n",
    "        \n",
    "        self.low_lvl_conv = ConvLayer(low_lvl_ni, low_lvl_ni//2, ks=1, ndim=3, bias=False, \n",
    "                                      norm_type=norm_type, act_cls=act_cls)\n",
    "\n",
    "        self.last_conv = nn.Sequential(\n",
    "                ConvLayer(ni+low_lvl_ni//2, ni, ks=3, ndim=3, stride=1, padding=1, bias=False, \n",
    "                          norm_type=norm_type, act_cls=act_cls), \n",
    "                nn.Dropout(ps),\n",
    "                ConvLayer(ni, ni, ks=3, ndim=3, stride=1, padding=1, bias=False, \n",
    "                          norm_type=norm_type, act_cls=act_cls), \n",
    "                nn.Dropout(ps/5),\n",
    "                nn.Conv3d(ni, n_out, kernel_size=1, stride=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.low_lvl_conv(sum(self.hook.stored))\n",
    "\n",
    "        ssh = s.shape[-3:]\n",
    "        if ssh != x.shape[-3:]:\n",
    "            x = F.interpolate(x, size=ssh, mode='nearest')\n",
    "        x = torch.cat((x, s), dim=1)\n",
    "        return self.last_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DynamicDeepLab(SequentialEx4D):\n",
    "    def __init__(self, encoder, n_out, img_size, n_inp=1, y_range=None, \n",
    "                       act_cls=defaults.activation, norm_type=NormType.Batch, **kwargs):\n",
    "        \n",
    "        encoder = Arch4D(encoder, n_inp)\n",
    "        sizes = model_sizes_4d(encoder, size=img_size, n_inp=n_inp)\n",
    "        sz_chg_idxs = list(_get_sz_change_idxs(sizes))\n",
    "        self.sfs = hook_outputs(encoder[sz_chg_idxs[1]], detach=False)\n",
    "        x = dummy_eval_4d(encoder, img_size, n_inp)\n",
    "        x = [x_.detach() for x_ in x]\n",
    "        ni = sizes[-1][1]\n",
    "        nf = ni//4\n",
    "        dilations=[1, 12, 24, 36] if ni > 1024 else [1, 6, 12, 18]\n",
    "        add_items = AddItems()\n",
    "        aspp = ASPP(ni=ni, nf=nf, dilations=dilations, norm_type=norm_type, act_cls=act_cls).eval()\n",
    "        \n",
    "        x = aspp(add_items(x))\n",
    "        decoder = DeepLabDecoder(ni=nf, low_lvl_ni=sizes[sz_chg_idxs[1]][1], hook=self.sfs, n_out=n_out, \n",
    "                                 norm_type=norm_type, act_cls=act_cls).eval()\n",
    "        x = decoder(x)\n",
    "        self.layers = nn.ModuleList([encoder, add_items, aspp, decoder, ResizeToOrig()])\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, \"sfs\"): self.sfs.remove()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.video import r3d_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_3d = create_body(r3d_18, pretrained = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 20, 112, 112])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DynamicDeepLab(body_3d, 2, (20, 112, 112))\n",
    "m(torch.randn(1, 3, 20, 112, 112)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 20, 112, 112])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DynamicDeepLab(body_3d, 2, (20, 112, 112),n_inp=2)\n",
    "m(torch.randn(1, 3, 20, 112, 112), torch.randn(1, 3, 20, 112, 112)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
