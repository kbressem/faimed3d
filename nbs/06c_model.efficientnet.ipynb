{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiovascular-operator",
   "metadata": {},
   "source": [
    "# EfficientNet\n",
    "\n",
    "Re-Implementation of EfficientNet into fastai using https://github.com/lukemelas/EfficientNet-PyTorch as source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.efficientnet\n",
    "# export\n",
    "from fastai.basics import *\n",
    "from torch.hub import load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-horizon",
   "metadata": {},
   "source": [
    "The kernel size for the layers in efficientnet changes and can be an odd or even number. If the kernel size is an odd number, margins for padding can be calculated with `kernel_size // 2`, however if the kernel size is an odd number this won't work. \n",
    "`ConvLayerDynamicPadding` expands the fastai `ConvLayer` function with an extra padding layer, ensuring padding is sufficient regardless of kernel size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ConvLayerDynamicPadding(nn.Sequential):\n",
    "    \"Same as fastai ConvLayer, but more accurately padds input according to `ks` and `stride`\"\n",
    "    @delegates(nn.Conv3d)\n",
    "    def __init__(self, \n",
    "                 ni, #number of input channels\n",
    "                 nf, # number of output channels\n",
    "                 ks=3, # kernel size (tuple or int)\n",
    "                 stride=1, # kernel stride (tuple or int)\n",
    "                 bias=None, # bias of convolution\n",
    "                 ndim=3, # dimension of convolution (1,2,3)\n",
    "                 norm_type=NormType.Batch, # type of batch nornalization\n",
    "                 bn_1st=True, # batch norm before ReLU\n",
    "                 act_cls=defaults.activation, # activation function\n",
    "                 transpose=False, # if transpose convolution should be constructed\n",
    "                 init='auto', # type of initialization\n",
    "                 xtra=None, # extra layers\n",
    "                 bias_std=0.01, \n",
    "                 **kwargs # further arguments for ConvLayer\n",
    "                ):\n",
    "        \n",
    "        # asymmetric padding\n",
    "        if isinstance(ks, int): ks = (ks, )*ndim\n",
    "        padding = [pad for _ks in ks for pad in self.calculate_padding(_ks)]\n",
    "\n",
    "        # init ConvLayer but set padding to 0\n",
    "        conv_layer = ConvLayer(ni, nf, ks, stride, 0, bias, ndim, norm_type, bn_1st, act_cls, transpose, init, xtra, bias_std, **kwargs)\n",
    "        \n",
    "        # set padding layer to first place, then all other layers\n",
    "        # padding needs to be reverted, as the function expects format (W, W, H, H, D, D)\n",
    "        super().__init__(nn.ConstantPad3d(padding[::-1], 0.), \n",
    "                         *[l for l in conv_layer])\n",
    "        \n",
    "    def calculate_padding(self, ks):\n",
    "        if ks % 2 == 0: return ks // 2, (ks-1) //2\n",
    "        else: return ks //2, ks //2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-comparative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 10, 10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvLayerDynamicPadding(ni=3, nf=64, ks=(2,7,5), ndim=3)(torch.randn(1, 3, 10, 10, 10)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-purse",
   "metadata": {},
   "source": [
    "EfficientNet uses DopConnect and DropOut. DropConnect needs to be implemented as Module to work with `nn.Sequential`.\n",
    "See [paper](https://arxiv.org/pdf/1603.09382.pdf) about stochastic depth for the reason drop connect and skip connections are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DropConnect(nn.Module):\n",
    "    \"Drops connections with probability p\"\n",
    "    def __init__(self, p): \n",
    "        assert 0 <= p <= 1, 'p must be in range of [0,1]'\n",
    "        self.keep_prob = 1 - p\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x): \n",
    "        if not self.training: return x\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # generate binary_tensor mask according to probability (p for 0, 1-p for 1)\n",
    "        random_tensor = self.keep_prob + torch.rand([batch_size, 1, 1, 1, 1], dtype=x.dtype, device=x.device)\n",
    "        return x / self.keep_prob * random_tensor.floor_() # convert random tensor to binary tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-completion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9221, -1.1308, -0.0000,  1.7536,  0.7608, -2.6259,  0.0000, -0.0000,\n",
       "        -1.7968, -0.0000, -0.0000,  0.0770, -2.1631,  0.0000,  0.0000, -0.0000])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DropConnect(0.5)(torch.randn(16, 1, 1, 1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-conditioning",
   "metadata": {},
   "source": [
    "Mobile Inverted Residual Bottleneck Block is the main block of convolutional layers in each EfficientNet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-prince",
   "metadata": {},
   "source": [
    "The Mobile Inverted Residual Bottleneck Block is the main building block of the efficientnet. It is based on this paper: https://arxiv.org/pdf/1801.04381.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"Mobile Inverted Residual Bottleneck Block\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_inp, # number of input channels\n",
    "                 n_out, # number of output channels\n",
    "                 kernel_size, # size of convolution kernel\n",
    "                 stride, # stride of kernel\n",
    "                 se_ratio, # squeeze-expand ratio\n",
    "                 id_skip, # if skip connection shouldbe used\n",
    "                 expand_ratio, # expansion ratio for inverted bottleneck\n",
    "                 drop_connect_rate = 0.2, # percentage of dropped connections\n",
    "                 act_cls=nn.SiLU, # type of activation function\n",
    "                 norm_type=NormType.Batch, # type of batch normalization\n",
    "                 **kwargs # further arguments passed to `ConvLayerDynamicPadding`\n",
    "                ):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "        \n",
    "        # expansion phase (inverted bottleneck)\n",
    "        n_intermed = n_inp * expand_ratio  # number of output channels\n",
    "        if expand_ratio != 1: \n",
    "            self.expand_conv = ConvLayerDynamicPadding(ni=n_inp, nf=n_intermed, \n",
    "                                                       ks = 1,norm_type=norm_type, \n",
    "                                                       act_cls=act_cls, **kwargs)\n",
    "            \n",
    "        # depthwise convolution phase, groups makes it depthwise\n",
    "        self.depthwise_conv = ConvLayerDynamicPadding(ni=n_intermed, nf=n_intermed, \n",
    "                                                      groups=n_intermed, ks=kernel_size, \n",
    "                                                      stride=stride, norm_type=norm_type, \n",
    "                                                      act_cls=act_cls, **kwargs)\n",
    "\n",
    "        # squeeze and excitation layer, if desired\n",
    "        self.has_se = (se_ratio is not None) and (0 < se_ratio <= 1)\n",
    "        if self.has_se:\n",
    "            num_squeezed_channels = max(1, int(n_inp * se_ratio))\n",
    "            self.squeeze_expand = nn.Sequential(\n",
    "                ConvLayerDynamicPadding(ni=n_intermed, nf=num_squeezed_channels, ks=1, \n",
    "                                        act_cls=act_cls, norm_type=None, **kwargs), \n",
    "                ConvLayerDynamicPadding(ni=num_squeezed_channels, nf=n_intermed, ks=1,  \n",
    "                                        act_cls=None, norm_type=None,**kwargs))\n",
    "\n",
    "        # pointwise convolution phase\n",
    "        self.project_conv = ConvLayerDynamicPadding(ni=n_intermed, nf=n_out, ks=1, \n",
    "                                                    act_cls = None, **kwargs)\n",
    "        self.drop_conncet = DropConnect(drop_connect_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.id_skip: inputs = x # save input only if skip connection \n",
    "        \n",
    "        # expansion \n",
    "        if self.expand_ratio != 1: x = self.expand_conv(x)\n",
    "        \n",
    "        # depthwise convolution\n",
    "        x = self.depthwise_conv(x)\n",
    "\n",
    "        # squeeze and excitation (self attention)\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool3d(x, 1)\n",
    "            x_squeezed = self.squeeze_expand(x_squeezed)\n",
    "            x = x * x_squeezed.sigmoid() # inplace saves a bit of memory\n",
    "    \n",
    "        # pointwise convolution\n",
    "        x = self.project_conv(x)\n",
    "\n",
    "        # skip connection and drop connect\n",
    "        if self.id_skip and self.stride == 1 and self.n_inp == self.n_out:\n",
    "            x = self.drop_conncet(x) + inputs  # skip connection\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-complement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 112, 10, 14, 14])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MBConvBlock(80, 112, 4, 1, 0.25, True, 6)(torch.randn(1, 80, 10, 14, 14)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EfficientNet(nn.Sequential):\n",
    "    \"\"\"\n",
    "    EfficientNet implementation into fastai based on \n",
    "    https://arxiv.org/abs/1905.11946 and the PyTorch\n",
    "    implementation of lukemelas (GitHub username)\n",
    "    https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "    \"\"\"\n",
    "    # block arguments remain constant for each model version\n",
    "    block_arguments =  pd.DataFrame({'num_repeat': [1,2,2,3,3,4,1], \n",
    "                                     'kernel_size': [3,3,4,3,4,4,3], \n",
    "                                     'stride':[1,2,2,2,1,2,1], \n",
    "                                     'expand_ratio':[1,6,6,6,6,6,6,], \n",
    "                                     'in_channels':[32,16,24,40,80,112,192], \n",
    "                                     'out_channels':[16,24,40,80,112,192,320], \n",
    "                                     'se_ratio':[0.25]*7, \n",
    "                                     'id_skip':[True]*7})\n",
    "    \n",
    "    # calling Efficientnet() without any parementers will default to efficientnet_b0\n",
    "    def __init__(self, \n",
    "                 ni=3, # number of input channels\n",
    "                 num_classes=101, # number of classes\n",
    "                 width_coefficient=1.0, # width mutliplier\n",
    "                 depth_coefficient=1.0, # depth multiplier\n",
    "                 dropout_rate=0.2, # percentage of units to drop\n",
    "                 drop_connect_rate=0.2, # percentage of inputs to drop\n",
    "                 depth_divisor=8,\n",
    "                 min_depth=None, # min depth of the different blocks\n",
    "                 act_cls = nn.SiLU, # type of activation function, default is Swish (=nn.SiLU)\n",
    "                 norm_type=NormType.Batch, # type of normalization layer, default is BatchNorm\n",
    "                ):\n",
    "        layers = []\n",
    "        \n",
    "        # Stem\n",
    "        nf_stem = self.get_n_channels(32, width_coefficient, depth_divisor, min_depth)  # number of output channels\n",
    "        stem = ConvLayerDynamicPadding(ni=ni, nf=nf_stem, ks=3, stride=2, \n",
    "                                       bias=False, act_cls=None, norm_type=norm_type)\n",
    "        layers.append(stem)\n",
    "        \n",
    "        # body\n",
    "        ## build body layer-by-layer\n",
    "        for idx, row in self.block_arguments.iterrows():\n",
    "            num_repeat, ks, stride, expand_ratio, ni, nf, se_ratio, id_skip = row\n",
    "            ni=self.get_n_channels(ni, width_coefficient, depth_divisor, min_depth)\n",
    "            nf=self.get_n_channels(nf, width_coefficient, depth_divisor, min_depth)\n",
    "            if depth_coefficient: num_repeat = int(math.ceil(depth_coefficient * num_repeat)) \n",
    "            \n",
    "            conv_block = []\n",
    "            for _ in range(num_repeat):\n",
    "                conv_block.append(\n",
    "                    MBConvBlock(n_inp=ni, n_out=nf, kernel_size=ks, stride=stride, se_ratio=se_ratio, \n",
    "                                id_skip=id_skip, expand_ratio=expand_ratio, \n",
    "                                drop_connect_rate=drop_connect_rate * float(idx) / len(self.block_arguments), # scale drop connect_rate\n",
    "                                act_cls=act_cls, norm_type=norm_type\n",
    "                               ))\n",
    "                ni, stride = nf, 1 # modify ni and stride if multiple block get stacked\n",
    "            layers.append(nn.Sequential(*conv_block))\n",
    "\n",
    "        ## add last ConvLayer of body\n",
    "        ni = nf # output of final block\n",
    "        nf = self.get_n_channels(ni, width_coefficient, depth_divisor, min_depth)\n",
    "        layers.append(ConvLayerDynamicPadding(ni, nf, ks=1, bias=False, act_cls=act_cls, norm_type=norm_type))\n",
    "        # Head\n",
    "        head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(nf, num_classes)\n",
    "        )\n",
    "        \n",
    "        layers.append(head)\n",
    "        super().__init__(*layers)\n",
    "        \n",
    "    def get_n_channels(self, n_channels,  width_coefficient, depth_divisor, min_depth):\n",
    "        \"calculate number of channels based on width_coefficient, depth_divisor and min_depth and round\"\n",
    "        if not width_coefficient: return filters\n",
    "        \n",
    "        n_channels *= width_coefficient\n",
    "        min_depth = min_depth or depth_divisor # pay attention to this line when using min_depth\n",
    "        # follow the formula transferred from official TensorFlow implementation\n",
    "        new_channels = max(min_depth, int(n_channels + depth_divisor / 2) // depth_divisor * depth_divisor)\n",
    "        if new_channels < 0.9 * n_channels: # prevent rounding by more than 10%\n",
    "            new_channels += depth_divisor\n",
    "        return int(new_channels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catch 16, 1152, 1, 7, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-austin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1863, -0.0720]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientNet(num_classes = 2)(torch.randn(1, 3, 10, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-patio",
   "metadata": {},
   "source": [
    "Calling models follows the `torchvision` approach taken for ResNets. We have private function `_efficientnet` which passes the building arguments to the `EfficientNet` class and a single function for each class (`efficientnet_b0`, `efficientnet_b1`) which will give the respective model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_model_urls = {\n",
    "           'efficientnet_b0': 'https://rad-ai.charite.de/pretrained_models/efficientnet_b0.pth', \n",
    "           'efficientnet_b1': 'https://rad-ai.charite.de/pretrained_models/efficientnet_b1.pth', \n",
    "           'efficientnet_b2': 'https://rad-ai.charite.de/pretrained_models/efficientnet_b2.pth', \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _efficientnet(arch, width_coefficient, depth_coefficient, dropout_rate, pretrained, progress, **kwargs):\n",
    "    # arch is currently not used, but will be needed when we can provide pretrained versions. \n",
    "    model = EfficientNet(width_coefficient=width_coefficient, depth_coefficient=depth_coefficient, \n",
    "                         dropout_rate=dropout_rate, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(_model_urls[arch],\n",
    "                                              progress=True)\n",
    "        model.load_state_dict(state_dict['model'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-particular",
   "metadata": {},
   "source": [
    " Overview of building arguments for the different efficientnets. Keep in mind, that image size is important for the model. Progressize resizing with efficiennets must be done very carefull. \n",
    " \n",
    " | model name       | width_coeff | depth_coeff | image_size | dropout |\n",
    " |----|-----|-----|-----|-----|\n",
    " |'efficientnet_b0' | 1.0 | 1.0 | 224 | 0.2 |\n",
    " |'efficientnet_b1' | 1.0 | 1.1 | 240 | 0.2 |\n",
    " |'efficientnet_b2' | 1.1 | 1.2 | 260 | 0.3 |\n",
    " |'efficientnet_b3' | 1.2 | 1.4 | 300 | 0.3 |\n",
    " |'efficientnet_b4' | 1.4 | 1.8 | 380 | 0.4 |\n",
    " |'efficientnet_b5' | 1.6 | 2.2 | 456 | 0.4 |\n",
    " |'efficientnet_b6' | 1.8 | 2.6 | 528 | 0.5 |\n",
    " |'efficientnet_b7' | 2.0 | 3.1 | 600 | 0.5 |\n",
    " |'efficientnet_b8' | 2.2 | 3.6 | 672 | 0.5 |\n",
    " |'efficientnet_l2' | 4.3 | 5.3 | 800 | 0.5 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def efficientnet_b0(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    return _efficientnet('efficientnet_b0', width_coefficient=1.0, depth_coefficient=1.0, \n",
    "                         dropout_rate=0.2, pretrained=pretrained, progress=progress, **kwargs)\n",
    "\n",
    "def efficientnet_b1(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    return _efficientnet('efficientnet_b1', width_coefficient=1.0, depth_coefficient=1.1, \n",
    "                         dropout_rate=0.2, pretrained=pretrained, progress=progress, **kwargs)\n",
    "\n",
    "def efficientnet_b2(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    return _efficientnet('efficientnet_b2', width_coefficient=1.1, depth_coefficient=1.2, \n",
    "                         dropout_rate=0.3, pretrained=pretrained, progress=progress, **kwargs)\n",
    "\n",
    "def efficientnet_b3(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    if pretrained: warn('Currently there is no pretrained version available for `efficientnet_b3`. Will load randomly intilialized weights.')\n",
    "    return _efficientnet('efficientnet_b3', width_coefficient=1.2, depth_coefficient=1.4, \n",
    "                         dropout_rate=0.3, pretrained=False, progress=False, **kwargs)\n",
    "\n",
    "def efficientnet_b4(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    if pretrained: warn('Currently there is no pretrained version available for `efficientnet_b4`. Will load randomly intilialized weights.')\n",
    "    return _efficientnet('efficientnet_b4', width_coefficient=1.4, depth_coefficient=2.2, \n",
    "                         dropout_rate=0.4, pretrained=False, progress=False, **kwargs)\n",
    "\n",
    "def efficientnet_b5(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    if pretrained: warn('Currently there is no pretrained version available for `efficientnet_b5`. Will load randomly intilialized weights.')\n",
    "    return _efficientnet('efficientnet_b5', width_coefficient=1.6, depth_coefficient=2.2, \n",
    "                         dropout_rate=0.4, pretrained=False, progress=False, **kwargs)\n",
    "\n",
    "def efficientnet_b6(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    if pretrained: warn('Currently there is no pretrained version available for `efficientnet_b6`. Will load randomly intilialized weights.')\n",
    "    return _efficientnet('efficientnet_b6', width_coefficient=1.8, depth_coefficient=2.6, \n",
    "                         dropout_rate=0.5, pretrained=False, progress=False, **kwargs)\n",
    "\n",
    "def efficientnet_b7(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    if pretrained: warn('Currently there is no pretrained version available for `efficientnet_b7`. Will load randomly intilialized weights.')\n",
    "    return _efficientnet('efficientnet_b7', width_coefficient=2.0, depth_coefficient=3.1, \n",
    "                         dropout_rate=0.5, pretrained=False, progress=False, **kwargs)\n",
    "\n",
    "def efficientnet_b8(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    if pretrained: warn('Currently there is no pretrained version available for `efficientnet_b8`. Will load randomly intilialized weights.')\n",
    "    return _efficientnet('efficientnet_b8', width_coefficient=2.2, depth_coefficient=3.6, \n",
    "                         dropout_rate=0.5, pretrained=False, progress=False, **kwargs)\n",
    "\n",
    "def efficientnet_l2(pretrained=False, progress=True, **kwargs):\n",
    "    \"load efficientnet with specific scaling coefficients\"\n",
    "    if pretrained: warn('Currently there is no pretrained version available for `efficientnet_l2`. Will load randomly intilialized weights.')\n",
    "    return _efficientnet('efficientnet_l2', width_coefficient=4.3, depth_coefficient=5.3, \n",
    "                         dropout_rate=0.5, pretrained=False, progress=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-copper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0825, 0.1869]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_b0(num_classes = 2)(torch.randn(1, 3, 10, 224, 224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-v2",
   "language": "python",
   "name": "fastai-v2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
