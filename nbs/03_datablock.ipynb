{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom datablocks for 3D images and fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp data\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import re\n",
    "import pathlib\n",
    "import torchvision\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Get data paths and labels\n",
    "\n",
    "Data is divided into a train, valid and test dataset of different patients, which either have prostate cancer or are healthy. \n",
    "Each patient has three MRI sequences: T2, T1map and ADC. These sequences differ in number of slices and resolution. \n",
    "\n",
    "At first the paths to the data are specified: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_csv('../../dl-prostate-mapping/data/full_data.csv', sep = ',')\n",
    "sample_data = sample_data[['t2_dcm_path', \"t2_mask_base\", 'is_valid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ScaleDicom(DisplayedTransform):\n",
    "    \"Transforms a TensorDicom3D volume to float and normalizes the data\"\n",
    "    def __init__(self, div=None, scale=True, normalize=True): store_attr()\n",
    "    def encodes(self, x:(TensorDicom3D, TensorMask3D)):\n",
    "        if isinstance(x, TensorMask3D): return x\n",
    "        if self.scale: x=x.hist_scaled()\n",
    "        if self.normalize: x=normalize(x)\n",
    "        if self.div is not None: x=x/self.div\n",
    "        return x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ImageBlock3D(cls=TensorDicom3D, div=None,scale=True, normalize=True):\n",
    "    \"A `TransformBlock` for images of `cls`\"\n",
    "    return TransformBlock(type_tfms=cls.create, batch_tfms=[ScaleDicom(div=div,scale=scale,normalize=normalize)])\n",
    "\n",
    "def MaskBlock3D(cls=TensorMask3D):\n",
    "    \"A `TransformBlock` for images of `cls`\"\n",
    "    return TransformBlock(type_tfms=cls.create, batch_tfms=[ScaleDicom])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders for image classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "              ImageBlock3D(cls=TensorMask3D)),\n",
    "    get_x = lambda x: x[0],\n",
    "    get_y = lambda x: x[1], \n",
    "    item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "    batch_tfms = [\n",
    "        *aug_transforms_3d(), \n",
    "        RandomCrop3D(((3, 2), (25,25), (25,25)), (0, 25, 25)), \n",
    "        PseudoColor],\n",
    "    splitter = RandomSplitter())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mris.summary(subset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mris.dataloaders(sample_data, \n",
    "                       batch_size = 8, \n",
    "                       num_workers = 0\n",
    "                      )\n",
    "dls.valid.bs = 8 # defaults to 64 and will cause Cuda out of Memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def show_batch_3d(dls, max_n=9, with_mask=False, alpha_mask=0.3, figsize = (15, 15), **kwargs):\n",
    "    \"Workarround, until implemented into dls as dls.show_batch_3d()\"\n",
    "    xb, yb = dls.one_batch()\n",
    "    xb.show(figsize=figsize)\n",
    "    if with_mask: yb.show(add_to_existing = True, alpha = alpha_mask, cmap = 'jet', figsize=figsize, **kwargs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch_3d(dls, axis = 0, nrow = 15, with_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.after_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.after_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When displaying the masks it may occure, that Nifti images are rotated and do not fit the original DICOM. Most likely it is due to different frames of reference. \n",
    "in Simple-ITK it is LPS, while NIfTI and FSL use RAS, so those matrices are the same after accounting for frame of reference (taken and adapted from https://discourse.itk.org/t/nifti-orientation-issues/431).\n",
    "So, luckly the malrotations are systematic and can be scripted.\n",
    "\n",
    "```python\n",
    "    def convert(fn):\n",
    "\n",
    "        if 'Gesund' in fn: return # healthy patients were already flipped once\n",
    "        im = sitk.ReadImage(fn)\n",
    "        arr = sitk.GetArrayFromImage(im)\n",
    "        arr = np.rot90(arr, 0)\n",
    "        arr = np.flip(arr, 1)\n",
    "        im2 = sitk.GetImageFromArray(arr)\n",
    "\n",
    "        for k in im.GetMetaDataKeys(): # Copy meta data from original image before overwriting it. \n",
    "            im2.SetMetaData(k, im.GetMetaData(k))\n",
    "\n",
    "        sitk.WriteImage(im2, fn)\n",
    "        return im2\n",
    "    \n",
    "    \n",
    "    for s in segmentation_train: \n",
    "    convert(str(s))\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
