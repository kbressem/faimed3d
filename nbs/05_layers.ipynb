{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# faimed3d layers and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp layers\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.preprocess import *\n",
    "from faimed3d.data import *\n",
    "from fastai.vision.learner import _default_meta, _add_norm, model_meta, create_body\n",
    "from fastai.layers import ResBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('../data/radiopaedia_cases.csv')\n",
    "dls = ImageDataLoaders3D.from_df(d, \n",
    "                                 item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "                                 bs = 2, \n",
    "                                 val_bs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Some functions from `fastai.layers` are needed to construct Learners (see next notebook). For this some slight modifications had to be made. \n",
    "The `in_channel` function had to be modified to also accept 3D models wich have 5D weights and the `num_features_model` function was adapted to pass a size tuple of len 3 instead of 2. The other functions were not changed but copied to avoid conflicts when loaded directly from fastai.   \n",
    "`cnn_learner_3d` is essentially the same function as fastais `cnn_learner`, just adds a new callback. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`in_channels` form fastai only returns a result if `weight.ndim == 4` but in 3D convolutional layers, it will be 5 dimensions, so the functions has to be adapted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def in_channels(m):\n",
    "    \"\"\"\n",
    "    Return the shape of the first weight layer in `m`.\n",
    "    same as fastai.vision.learner.in_channels but allows l.weight.ndim of 4 and 5\n",
    "    \"\"\"\n",
    "    for l in flatten_model(m):\n",
    "        if getattr(l, 'weight', None) is not None and l.weight.ndim in [4,5]:\n",
    "            return l.weight.shape[1]\n",
    "    raise Exception('No weight layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num_features_model` is unchanged, but needs to be defined here to correctly call the adapted `in_channels` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def num_features_model(m):\n",
    "    \"\"\"\n",
    "    Return the number of output features for `m`.\n",
    "    same as fastai.vision.learner.num_features_model passes model_size a len 3 tuple of sz\n",
    "\n",
    "    \"\"\"\n",
    "    sz,ch_in = 32,in_channels(m)\n",
    "    while True:\n",
    "        #Trying for a few sizes in case the model requires a big input size.\n",
    "        try:\n",
    "            return model_sizes(m, (sz,sz,sz))[-1][1]\n",
    "        except Exception as e:\n",
    "            sz *= 2\n",
    "            print(sz)\n",
    "            if sz > 2048: raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_cnn_model` is unchanged, but needs to be redefined to correctly call `num_features_model` which then calls the changed `in_channels` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_cnn_model(arch, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n",
    "                     concat_pool=True, **kwargs):\n",
    "    \"Create custom convnet architecture using `arch`, `n_in` and `n_out`. Identical to fastai func\"\n",
    "    body = create_body(arch, n_in, pretrained, cut)\n",
    "    if custom_head is None:\n",
    "        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n",
    "        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n",
    "    else: head = custom_head\n",
    "    model = nn.Sequential(body, head)\n",
    "    if init is not None: apply_init(model[1], init)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model_sizes` and `dummy_eval` are identical to `fastai` versions, but needed to be redefined so that the correct `in_channels` function is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def model_sizes(m, size=(64,64)):\n",
    "    \"Pass a dummy input through the model `m` to get the various sizes of activations. same as fastai func\"\n",
    "    with hook_outputs(m) as hooks:\n",
    "        _ = dummy_eval(m, size=size)\n",
    "        return [o.stored.shape for o in hooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def dummy_eval(m, size=(64,64)):\n",
    "    \"Evaluate `m` on a dummy input of a certain `size`. Same as fastai func\"\n",
    "    ch_in = in_channels(m)\n",
    "    x = one_param(m).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.)\n",
    "    with torch.no_grad(): return m.eval()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastai` performes adaptive concat pooling as first step in the new header, which is adapted to 3D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AdaptiveConcatPool3d(Module):\n",
    "    \"Layer that concats `AdaptiveAvgPool3d` and `AdaptiveMaxPool3d`\"\n",
    "    def __init__(self, size=None):\n",
    "        self.size = size or 1\n",
    "        self.ap = nn.AdaptiveAvgPool3d(self.size)\n",
    "        self.mp = nn.AdaptiveMaxPool3d(self.size)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper for 4D Models\n",
    "\n",
    "In radiology, often multiple sequences are needed for a diagnosis. For example, while viewing a head MRI DWI and ADC map have to be viewed together for a stroke diagnosis and to advoid false diagnosis from T2 shine trough. The data effectively becomes 4D. There are no modules for 4D convolution, so a workarround needs to be defined which processes the multiple 3D volumes after each other and then pools the information. The models should also still work with available pretrained 3D models, so no completly new architectures are defined in `faimed3d`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using multiple inputs, `nn.Sequential` will not work as it expects only two inputs (self and input). Therefore a subclass is defined, which accepts multiple inputs and converts those into a tuple, which is then passed to the modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Sequential4D(nn.Sequential):\n",
    "    def forward(self, *input):\n",
    "        input = tuple(input)\n",
    "        for module in self:\n",
    "            input = module(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Arch4D` is designed to recieve a (pretrained) model arch from the fastai function `create_body`. It assumes, that the arch is buil following the common structure of PyTorch models. That means it consists out of multiple submodules, where the first is a stem.  \n",
    "For each element in the input, the stem is copied so that the weights of the different stems can differ. After an element of input is passed through the stem, it is further processed by the `main_body`. So the inputs are each passed thorugh an individual CNNs which share all weights except for the stem. The output of each individual CNN is captured and stored in a list which is eventually concatenated to a single tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Arch4D(nn.Module):\n",
    "    def __init__(self, arch, n_inp):\n",
    "        super(Arch4D, self).__init__()\n",
    "        \n",
    "        for i in range(0, n_inp):\n",
    "            setattr(self, 'BasicStem_{}'.format(i), arch[0])\n",
    "        self.main_body = arch[1:]\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = []\n",
    "        for i, x in enumerate(inp):\n",
    "            x = getattr(self, 'BasicStem_{}'.format(i))(x)\n",
    "            out.append(self.main_body(x))\n",
    "        return torch.cat(out, 1)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `fastai` creates a new model head, first the input is pooled with `AdaptiveConcatPool`, then flattened ans passed trough two linear layers might not be the best approach for multiple inputs, as the first layer would recieve `n_inp` * `n_features` inputs and reduces it to 512 features. So the first linear layer wil much more reduce the feature information than the second. So in `faimed3d` an additional convolutional layer with kernel size 1 and stride 1 is used to pool the number of features from `n_features` * `n_inp` to `n_features`. Then the normal `fastai` head is added. We added the last convolutional layer to the head, so that the freeze and unfreeze operations of `fastai` still work as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_head(nf, n_out, n_inp=None, lin_ftrs=None, ps=0.5, concat_pool=True, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and out `n_out` classes.\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    pool = AdaptiveConcatPool3d() if concat_pool else nn.AdaptiveAvgPool3d(1)\n",
    "    if n_inp is not None: \n",
    "        pool = nn.Sequential(pool, \n",
    "                             ConvLayer(n_inp*nf, nf, ndim = 3, ks = 1, stride = 1))\n",
    "    layers = [pool, Flatten()]\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=True, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_cnn_model_4d` is similar to `create_cnn_model` but expects `n_inp` as additional argument. Depending on `n_inp` the respective network is constructed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_cnn_model_4d(arch, n_out, n_inp, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n",
    "                     concat_pool=True, **kwargs):\n",
    "    \"Create custom convnet architecture using `arch`, `n_in` and `n_out`. Identical to fastai func\"\n",
    "    body = create_body(arch, n_in, pretrained, cut)\n",
    "    if custom_head is None:\n",
    "        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n",
    "        head = create_head(nf, n_out, n_inp, concat_pool=concat_pool, **kwargs)\n",
    "    else: head = custom_head\n",
    "    body = Arch4D(body, n_inp)\n",
    "    model = Sequential4D(body, head)\n",
    "    if init is not None: apply_init(model[1], init)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.video import r3d_18\n",
    "model = create_cnn_model_4d(r3d_18, 2, 2)\n",
    "model(torch.randn(2, 3, 3, 10, 10), torch.randn(2, 3, 3, 10, 10)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_basics.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_transforms.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_layers.ipynb.\n",
      "Converted 06_learner.ipynb.\n",
      "Converted 06a_models.alexnet.ipynb.\n",
      "Converted 06b_models.resnet.ipynb.\n",
      "Converted 06d_models.unet.ipynb.\n",
      "Converted 06f_models.losses.ipynb.\n",
      "Converted 07_callback.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
