{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp layers\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.preprocess import *\n",
    "from faimed3d.models.resnet import resnet50_3d\n",
    "from faimed3d.data import *\n",
    "from fastai.vision.learner import _default_meta, _add_norm, model_meta, create_body, has_pool_type, _get_first_layer, _load_pretrained_weights\n",
    "from fastai.layers import ResBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('../data/radiopaedia_cases.csv')\n",
    "dls = ImageDataLoaders3D.from_df(d, \n",
    "                                 item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "                                 bs = 2, \n",
    "                                 val_bs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Some functions from `fastai.layers` are needed to construct learners (see next notebook). For this some slight modifications had to be made. \n",
    "The `in_channel` function had to be modified to also accept 3D models wich have 5D weights and the `num_features_model` function was adapted to pass a size tuple of len 3 instead of 2. The other functions were not changed but copied to avoid conflicts when loaded directly from fastai.   \n",
    "`cnn_learner_3d` is essentially the same function as fastais `cnn_learner`, just adds a new callback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_body(arch, n_in=3, pretrained=True, cut=None):\n",
    "    \"Cut off the body of a typically pretrained `arch` as determined by `cut`\"\n",
    "    model = arch(pretrained=pretrained)\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    #cut = ifnone(cut, cnn_config(arch)['cut'])\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if   isinstance(cut, int):      return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): return cut(model)\n",
    "    else: raise NamedError(\"cut must be either integer or a function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _update_first_layer(model, n_in, pretrained):\n",
    "    \"Change first layer based on number of input channels\"\n",
    "    if n_in == 3: return\n",
    "    first_layer, parent, name = _get_first_layer(model)\n",
    "    assert isinstance(first_layer, nn.Conv3d), f'Change of input channels only supported with Conv3d, found {first_layer.__class__.__name__}. Use the fastai implementation'\n",
    "    assert getattr(first_layer, 'in_channels') == 3, f'Unexpected number of input channels, found {getattr(first_layer, \"in_channels\")} while expecting 3'\n",
    "    params = {attr:getattr(first_layer, attr) for attr in 'out_channels kernel_size stride padding dilation groups padding_mode'.split()}\n",
    "    params['bias'] = getattr(first_layer, 'bias') is not None\n",
    "    params['in_channels'] = n_in\n",
    "    new_layer = nn.Conv3d(**params)\n",
    "    if pretrained:\n",
    "        _load_pretrained_weights(new_layer, first_layer)\n",
    "    setattr(parent, name, new_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai `create_body` can adapt the number of input channels but only for 2d convolutions. With slight changes in the code of the two fastai functions, it can be adapted to work with 3d convolutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_3d = create_body(resnet50_3d, pretrained=True, n_in=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def in_channels(m):\n",
    "    \"\"\"\n",
    "    Return the shape of the first weight layer in `m`.\n",
    "    same as fastai.vision.learner.in_channels but allows l.weight.ndim of 4 and 5\n",
    "    \"\"\"\n",
    "    for l in flatten_model(m):\n",
    "        if getattr(l, 'weight', None) is not None and l.weight.ndim in [4,5]:\n",
    "            return l.weight.shape[1]\n",
    "    raise Exception('No weight layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`in_channels` from fastai only returns a result if `weight.ndim == 4` but in 3D convolutional layers, it will be 5 dimensions, so the functions has to be adapted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(in_channels(body_3d), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num_features_model` is unchanged, but needs to be defined here to correctly call the adapted `in_channels` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def num_features_model(m):\n",
    "    \"\"\"\n",
    "    Return the number of output features for `m`.\n",
    "    same as fastai.vision.learner.num_features_model passes model_size a len 3 tuple of sz\n",
    "\n",
    "    \"\"\"\n",
    "    sz,ch_in = 32,in_channels(m)\n",
    "    while True:\n",
    "        #Trying for a few sizes in case the model requires a big input size.\n",
    "        return model_sizes(m, (sz,sz,sz))[-1][1]\n",
    "        try:\n",
    "            return model_sizes(m, (sz,sz,sz))[-1][1]\n",
    "        except Exception as e:\n",
    "            sz *= 2\n",
    "            print(sz)\n",
    "            if sz > 2048: raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def model_sizes(m, size=(8,64,64)):\n",
    "    \"Pass a dummy input through the model `m` to get the various sizes of activations. same as fastai func\"\n",
    "    with hook_outputs(m) as hooks:\n",
    "        _ = dummy_eval(m, size=size)\n",
    "        return [o.stored.shape for o in hooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def dummy_eval(m, size=(8,64,64)):\n",
    "    \"Evaluate `m` on a dummy input of a certain `size`. Same as fastai func\"\n",
    "    ch_in = in_channels(m)\n",
    "    x = one_param(m).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.)\n",
    "    with torch.no_grad(): return m.eval()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 128, 9, 21, 21]),\n",
       " torch.Size([1, 256, 9, 21, 21]),\n",
       " torch.Size([1, 512, 5, 11, 11]),\n",
       " torch.Size([1, 1024, 3, 6, 6]),\n",
       " torch.Size([1, 2048, 2, 3, 3])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_eval(body_3d).size()\n",
    "model_sizes(body_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(num_features_model(body_3d), 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_cnn_model` is unchanged, but needs to be redefined to correctly call `num_features_model` which then calls the changed `in_channels` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Concat(Module):\n",
    "    \n",
    "    def __init__(self, ni, ndim, dim = 1):\n",
    "        store_attr()\n",
    "        self.bn = BatchNorm(ni, ndim)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs:(list, tuple))->Tensor:\n",
    "        inputs = torch.cat(inputs, self.dim)\n",
    "        return self.act(self.bn(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastai` performes adaptive concat pooling as first step in the new header, which is adapted to 3D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AdaptiveConcatPool3d(Module):\n",
    "    \"Layer that concats `AdaptiveAvgPool3d` and `AdaptiveMaxPool3d`\"\n",
    "    def __init__(self, size=None):\n",
    "        self.size = size or 1\n",
    "        self.ap = nn.AdaptiveAvgPool3d(self.size)\n",
    "        self.mp = nn.AdaptiveMaxPool3d(self.size)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and out `n_out` classes.\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    pool = AdaptiveConcatPool3d() if concat_pool else nn.AdaptiveAvgPool3d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=True, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_head` is the same as fastai function, but used 3d pooling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_cnn_model_3d(arch, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n",
    "                     concat_pool=True, **kwargs):\n",
    "    \"Create custom convnet architecture using `arch`, `n_in` and `n_out`. Identical to fastai func\"\n",
    "    body = create_body(arch, n_in, pretrained, cut)\n",
    "    if custom_head is None:\n",
    "        nf = num_features_model(body) * (2 if concat_pool else 1)\n",
    "        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n",
    "    else: head = custom_head\n",
    "    model = nn.Sequential(body, head)\n",
    "    if init is not None: apply_init(model[1], init)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_cnn_model_3d` is similar to `create_cnn_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn_model_3d(resnet50_3d, 2, 1, pretrained = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(2, 3, 3, 10, 10)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_basics.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_transforms.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_layers.ipynb.\n",
      "Converted 06_learner.ipynb.\n",
      "Converted 06a_models.alexnet.ipynb.\n",
      "Converted 06b_models.resnet.ipynb.\n",
      "Converted 06c_model.efficientnet.ipynb.\n",
      "Converted 06d_models.unet.ipynb.\n",
      "Converted 06e_models.deeplabv3.ipynb.\n",
      "Converted 06f_models.losses.ipynb.\n",
      "Converted 07_callback.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
