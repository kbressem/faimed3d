{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.all import L\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp preprocess\n",
    "import SimpleITK as sitk\n",
    "from fastai.basics import *\n",
    "from fastai.vision.augment import *\n",
    "from faimed3d.basics import *\n",
    "from fastai.torch_core import interp_1d\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially for MRI the pixel values can vary between scanner types. This will lead to a very differnt range of pixel intensities across images in the same batch and the algorithms will have a hard time converging. \n",
    "Various techniques exist for rescaling exists of which some are implemented here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def show_L(l:L, **kwargs): \n",
    "    \"shows all Tensors in L\"\n",
    "    show_images_3d(torch.stack(tuple(l)), **kwargs)\n",
    "    \n",
    "@patch\n",
    "def apply(l:L, fun):\n",
    "    \"applies a function to each element of L\"\n",
    "    return L(fun(item) for item in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = [\"/media/ScaleOut/vahldiek/MRI/SIJ/TRAINING_FINAL/01013/TIRM/\", \n",
    "       \"/media/ScaleOut/vahldiek/MRI/SIJ/TRAINING_FINAL/01014/TIRM/\",\n",
    "       \"/media/ScaleOut/vahldiek/MRI/SIJ/TRAINING_FINAL/01015/TIRM/\",\n",
    "       \"/media/ScaleOut/vahldiek/MRI/SIJ/TRAINING_FINAL/01015/T1/\"]\n",
    "images = L(TensorDicom3D.create(fn) for fn in fns)\n",
    "images.show_L(nrow = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size correction\n",
    "if working with data from differnt scanners of even different sequences, pixel spacing can differ. E.g. T2w images are usually in a higher resolution as DWI images, thus the size of each individual pixel is larger in DWI images than in T2W. Normalizing pixel size to a standartized value can help achiving better performance. However, only the H x W Dimension is rescaled, not the D Dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def size_correction(im:(TensorDicom3D, TensorMask3D), new_spacing=1):\n",
    "    x_sz, y_sz, z_sz  = im.get_spacing()\n",
    "    m = im.metadata\n",
    "    rescale_factor = new_spacing/x_sz\n",
    "    new_sz = (im.size(-3), \n",
    "              int(im.size(-2)*rescale_factor), \n",
    "              int(im.size(-1)*rescale_factor))\n",
    "    mode = 'trilinear' if isinstance(im, TensorDicom3D) else 'nearest'\n",
    "    while im.ndim < 5: im = im.unsqueeze(0)\n",
    "    im = F.interpolate(im, size = new_sz, mode = mode, align_corners=True).squeeze() #changes memory address, restore_metadata won't work anymore\n",
    "    im.metadata = m\n",
    "    im.set_spacing((new_spacing, new_spacing, z_sz))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[im.get_spacing() for im in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[im.get_spacing() for im in images.apply(size_correction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel rescaling\n",
    "rescale intercept: 0028|1052  \n",
    "rescale slope: 0028|1053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faimed3d.basics import TensorDicom3D # for compatibility with show_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def rescale_pixeldata(t:TensorDicom3D):\n",
    "    m = t.metadata\n",
    "    if '0028|1053' in m: # if one tag is present, the other should also\n",
    "        t = t * m['0028|1053'] + m['0028|1052']\n",
    "        m.pop('0028|1052')\n",
    "        m.pop('0028|1053')\n",
    "        t.restore_metadata()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = images[0]\n",
    "print(im.mean())\n",
    "# the example MRI images have no rescale slope or intercept\n",
    "im.metadata['0028|1052'] = 5.\n",
    "im.metadata['0028|1053'] = 0.5\n",
    "im = im.rescale_pixeldata()\n",
    "im.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel Intensity Normalization\n",
    "### Mean / Max / Median scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "@patch\n",
    "def mean_scale(t:TensorDicom3D):\n",
    "    \"Scales pixels by subtracting the mean and dividing by std. 0 pixels are ignored\"\n",
    "    t = t - t.min() # set mit to 0\n",
    "    mask = t.ne(0.)\n",
    "    mean, sd = t[mask].mean(), t[mask].std()\n",
    "    t = (t - mean) / sd\n",
    "    t.restore_metadata()\n",
    "    return t\n",
    "\n",
    "class MeanScale(RandTransform):\n",
    "    split_idx,order = None, 10\n",
    "    def __init__(self, p=1., **kwargs):\n",
    "        super().__init__(p, **kwargs)\n",
    "        store_attr()\n",
    "    def encodes(self, x:TensorDicom3D):\n",
    "        return x.mean_scale()\n",
    "    def encodes(self, x:TensorMask3D): return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.apply(MeanScale()).show_L(nrow = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def median_scale(t:TensorDicom3D):\n",
    "    \"Scales pixels by subtracting the median and dividing by the IQR. 0 pixels are ignored\"\n",
    "    t = t - t.min() # set mit to 0\n",
    "    mask = t.ne(0.)\n",
    "    if mask.view(-1).shape[0] >=2 **16: \n",
    "        # resize to large tensor for quantile\n",
    "        # qunatile takes up to size 2**24, but than takes ~1sec \n",
    "        mask = F.interpolate(t[mask].view(-1).unsqueeze(0).unsqueeze(0), 2**16)\n",
    "    median, iqr = mask.median(), mask.quantile(0.75)-mask.quantile(0.25)\n",
    "    t = (t-median)/iqr\n",
    "    t.restore_metadata()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def max_scale(t:TensorDicom3D):\n",
    "    t = (t - t.min()) / (t.max() - t.min())\n",
    "    t.restore_metadata()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, just scaling wiht one mean (or median) and std (or IQR) might not be the optimal solution. \n",
    "Histgram scaling might be used for a more evendistribution of pixel values. Differnt functions are provided for histogram scaling: \n",
    "\n",
    "#### Method adapted form Jeremy Howard\n",
    "See the excelent [Kaggle kernel](https://www.kaggle.com/jhoward/don-t-see-like-a-radiologist-fastai) form Jeremy Howard for an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor # for compatibility with show_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "@patch\n",
    "def freqhist_bins(t:(TensorDicom3D,Tensor), n_bins=100):\n",
    "    '''\n",
    "    A function to split the range of pixel values into groups, such that each group has around the same number of pixels. \n",
    "    taken from https://github.com/fastai/fastai/blob/master/fastai/medical/imaging.py#L78\n",
    "    '''\n",
    "    imsd = t.view(-1).sort()[0]\n",
    "    t = torch.cat([tensor([0.001]),\n",
    "                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n",
    "                   tensor([0.999])])\n",
    "    t = (len(imsd)*t).long()\n",
    "    return imsd[t].unique()\n",
    "\n",
    "@patch\n",
    "def hist_scaled(t:(TensorDicom3D,Tensor), brks=None):\n",
    "    '''\n",
    "    Scales a tensor using `freqhist_bins` to values between 0 and 1\n",
    "    taken from https://github.com/fastai/fastai/blob/master/fastai/medical/imaging.py#L78\n",
    "    '''\n",
    "    if t.device.type=='cuda': return t.hist_scaled_pt(brks)\n",
    "    if brks is None: brks = t.freqhist_bins()\n",
    "    ys = np.linspace(0., 1., len(brks))\n",
    "    x = t.numpy().flatten()\n",
    "    x = np.interp(x, brks.numpy(), ys)\n",
    "    x = tensor(x).reshape(t.shape).clamp(0.,1.)\n",
    "    return x # will loose meta data in process\n",
    "\n",
    "@patch\n",
    "def hist_scaled_pt(t:(TensorDicom3D,Tensor), brks=None):\n",
    "    \"same as fastai fucntion for PILDicom\"\n",
    "    # Pytorch-only version - switch to this if/when interp_1d can be optimized\n",
    "    if brks is None: brks = t.freqhist_bins()\n",
    "    brks = brks.to(t.device)\n",
    "    ys = torch.linspace(0., 1., len(brks)).to(t.device)\n",
    "    return t.flatten().interp_1d(brks, ys).reshape(t.shape).clamp(0.,1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return x.hist_scaled()\n",
    "images.apply(f).show_L(nrow = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison to SimpleITK Adaptive Histogram Equalization\n",
    "The method from Jeremy Howard is more simple that methods provided in SimpleITK, however it is much faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = TensorDicom3D(images[0][10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sitk.Cast(im1.as_sitk(), sitk.sitkFloat32)\n",
    "output = sitk.AdaptiveHistogramEqualization(image, radius=[20]*3, alpha=0.3, beta=0.3) # ~ 30-60 seconds\n",
    "TensorDicom3D(sitk.GetArrayFromImage(output)).show() \n",
    "im1.hist_scaled().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N4 Bias Field Correction\n",
    "from official [SimpleITK docs](https://simpleitk.readthedocs.io/en/master/link_N4BiasFieldCorrection_docs.html)\n",
    "> The N4 bias field correction algorithm is a popular method for correcting low frequency intensity non-uniformity present in MRI image data known as a bias or gain field. The method has also been successfully applied as flat-field correction in microscopy data. This method assumes a simple parametric model and does not require tissue classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "corrector.SetMaximumNumberOfIterations([3]*3)\n",
    "output = corrector.Execute(sitk.Cast(im1.as_sitk(), sitk.sitkFloat32)) # needs float\n",
    "TensorDicom3D(sitk.GetArrayFromImage(output)).show() #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`faimed3d` provides a wrapper class to apply both N4 Bias Field Correction and Adaptive Histogram Equalization, which basically just simplifies reading the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class ImageCorrectionWrapper(object):\n",
    "    def __init__(self, \n",
    "                 n4_max_num_it = 3, \n",
    "                 hist_radius = [5,5,5], # radius in format [H x W x D]. Computation time scale ^3 with radius.   \n",
    "                 hist_alpha  = 0.3, \n",
    "                 hist_beta = 0.3, \n",
    "                 do_n4 = True, \n",
    "                 do_hist = True, \n",
    "                 verbose = True):\n",
    "        store_attr()\n",
    "        if do_n4: \n",
    "            self.corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "\n",
    "    def __call__(self, orig_file, fn_out=None):\n",
    "        if isinstance(orig_file, str): \n",
    "            if fn_out is None:\n",
    "                fn_out = self.strip_suffix(fn_in)+'corrected.nii.gz'\n",
    "            self.convert_string(orig_file, fn_out)\n",
    "        if isinstance(orig_file, TensorDicom3D):\n",
    "            if fn_out is None:\n",
    "                try: fn_out = self.strip_suffix(orig_file.fn)+'corrected.nii.gz'\n",
    "                except: raise ValueError('Please set a name for the output')\n",
    "            self._convert(orig_file.as_sitk(), fn_out)\n",
    "        if self.verbose: \n",
    "            print('Coreccted and wrote file to {}'.format(fn_out))\n",
    "        \n",
    "    def convert_string(self, fn_in, fn_out):\n",
    "        im = self.read_image(fn_in)\n",
    "        self._convert(im, fn_out)\n",
    "\n",
    "    def _convert(self, im, fn_out):\n",
    "        if self.do_n4:\n",
    "            im = self.n4_bias_correction(im)\n",
    "        if self.do_hist:\n",
    "            im = self.hist_equal(im)\n",
    "        sitk.WriteImage(im, fn_out)\n",
    "    \n",
    "            \n",
    "    def n4_bias_correction(self, im):\n",
    "        self.corrector.SetMaximumNumberOfIterations([self.n4_max_num_it]*3)\n",
    "        return self.corrector.Execute(im) \n",
    "    \n",
    "    def hist_equal(self, im):\n",
    "        return sitk.AdaptiveHistogramEqualization(sitk.Cast(im, sitk.sitkInt16), \n",
    "                                                  radius=self.hist_radius*3, \n",
    "                                                  alpha=self.hist_alpha, \n",
    "                                                  beta=self.hist_beta)\n",
    "    \n",
    "    def read_image(self, fn):\n",
    "        \"copy of TensorDicom3D.load\"\n",
    "        if isinstance(fn, str): fn = Path(fn)\n",
    "        if fn.is_dir(): \n",
    "            SeriesReader = sitk.ImageSeriesReader()\n",
    "            dicom_names = SeriesReader.GetGDCMSeriesFileNames(str(fn))\n",
    "            SeriesReader.SetFileNames(dicom_names)\n",
    "            im = SeriesReader.Execute()\n",
    "            return sitk.Cast(im, sitk.sitkFloat32)\n",
    "        elif fn.is_file():\n",
    "            return sitk.ReadImage(str(fn), outputPixelType=sitk.sitkFloat32)\n",
    "        else:\n",
    "            raise TypeError('the path \"{}\" is neither a valid directory nor a file'.format(str(fn)))     \n",
    "            \n",
    "        \n",
    "    def strip_suffix(self, fn):\n",
    "        fn = Path(fn)\n",
    "        extensions = \"\".join(fn.suffixes)\n",
    "        new_fn = str(fn).replace(extensions, '')\n",
    "        return new_fn+'/' if fn.is_dir() else new_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Linear Histogram Matching\n",
    "\n",
    "[1] N. Laszlo G and J. K. Udupa, “On Standardizing the MR Image Intensity Scale,” Magn. Reson. Med., vol. 42, pp. 1072–1081, 1999.\n",
    "\n",
    "[2] M. Shah, Y. Xiao, N. Subbanna, S. Francis, D. L. Arnold, D. L. Collins, and T. Arbel, “Evaluating intensity normalization on MRIs of human brain with multiple sclerosis,” Med. Image Anal., vol. 15, no. 2, pp. 267–282, 2011.\n",
    "\n",
    "Implementation adapted from: https://github.com/jcreinhold/intensity-normalization, ported to pytorch (no use of numpy, works in cuda).\n",
    "\n",
    "In contrast to `hist_scaled`, the piecewise linear histogram matching need pre-specified values for new scale and landmarks. It should be used to normalize a whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_percentile(t: Tensor, q: float) -> Union[int, float]:\n",
    "    \"\"\"   \n",
    "    Return the ``q``-th percentile of the flattened input tensor's data.\n",
    "    \n",
    "    CAUTION:\n",
    "     * Needs PyTorch >= 1.1.0, as ``torch.kthvalue()`` is used.\n",
    "     * Values are not interpolated, which corresponds to\n",
    "       ``numpy.percentile(..., interpolation=\"nearest\")``.\n",
    "       \n",
    "    :param t: Input tensor.\n",
    "    :param q: Percentile to compute, which must be between 0 and 100 inclusive.\n",
    "    :return: Resulting value (float).\n",
    "    \n",
    "    This function is twice as fast as torch.quantile and has no size limitations\n",
    "    \"\"\"\n",
    "    # Note that ``kthvalue()`` works one-based, i.e. the first sorted value\n",
    "    # indeed corresponds to k=1, not k=0! Use float(q) instead of q directly,\n",
    "    # so that ``round()`` returns an integer, even if q is a np.float32.\n",
    "    \n",
    "    k = 1 + round(.01 * float(q) * (t.numel() - 1))\n",
    "    result = t.view(-1).kthvalue(k)[0].item()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_landmarks(t: Tensor, percentiles: Tensor)->Tensor:\n",
    "    \"\"\"\n",
    "    Returns the input's landmarks.\n",
    "       \n",
    "    :param t (torch.Tensor): Input tensor.\n",
    "    :param percentiles (torch.Tensor): Peraentiles to calculate landmarks for.\n",
    "    :return: Resulting landmarks (torch.tensor).\n",
    "    \"\"\"\n",
    "    return tensor([get_percentile(t, perc.item()) for perc in percentiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def find_standard_scale(inputs, i_min=1, i_max=99, i_s_min=1, i_s_max=100, l_percentile=10, u_percentile=90, step=10):\n",
    "    \"\"\"\n",
    "    determine the standard scale for the set of images\n",
    "    Args:\n",
    "        inputs (list or L): set of TensorDicom3D objects which are to be normalized\n",
    "        i_min (float): minimum percentile to consider in the images\n",
    "        i_max (float): maximum percentile to consider in the images\n",
    "        i_s_min (float): minimum percentile on the standard scale\n",
    "        i_s_max (float): maximum percentile on the standard scale\n",
    "        l_percentile (int): middle percentile lower bound (e.g., for deciles 10)\n",
    "        u_percentile (int): middle percentile upper bound (e.g., for deciles 90)\n",
    "        step (int): step for middle percentiles (e.g., for deciles 10)\n",
    "    Returns:\n",
    "        standard_scale (np.ndarray): average landmark intensity for images\n",
    "        percs (np.ndarray): array of all percentiles used\n",
    "    \"\"\"\n",
    "    percs = torch.cat([torch.tensor([i_min]), \n",
    "                       torch.arange(l_percentile, u_percentile+1, step), \n",
    "                       torch.tensor([i_max])], dim=0)\n",
    "    standard_scale = torch.zeros(len(percs))\n",
    "    \n",
    "    for input_image in inputs:\n",
    "        mask_data = input_image > input_image.mean()\n",
    "        masked = input_image[mask_data > 0]\n",
    "        landmarks = get_landmarks(masked, percs)\n",
    "        min_p = get_percentile(masked, i_min)\n",
    "        max_p = get_percentile(masked, i_max)\n",
    "        new_landmarks = landmarks.interp_1d(torch.FloatTensor([i_s_min, i_s_max]), \n",
    "                                            torch.FloatTensor([min_p, max_p]))\n",
    "        standard_scale += new_landmarks\n",
    "    standard_scale = standard_scale / len(inputs)\n",
    "    return standard_scale, percs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def piecewise_hist(image:Tensor, landmark_percs, standard_scale)->Tensor:\n",
    "    \"\"\"\n",
    "    do the Nyul and Udupa histogram normalization routine with a given set of learned landmarks\n",
    "    Args:\n",
    "        input_image (TensorDicom3D): image on which to find landmarks\n",
    "        landmark_percs (torch.tensor): corresponding landmark points of standard scale\n",
    "        standard_scale (torch.tensor): landmarks on the standard scale\n",
    "    Returns:\n",
    "        normalized (TensorDicom3D): normalized image\n",
    "    \"\"\"\n",
    "    mask_data = image > image.mean()\n",
    "    masked = image[mask_data > 0]\n",
    "    landmarks = get_landmarks(masked, landmark_percs)    \n",
    "    if landmarks.device != image.device: landmarks = landmarks.to(image.device)\n",
    "    if standard_scale.device != image.device: standard_scale = standard_scale.to(image.device)\n",
    "    return image.flatten().interp_1d(landmarks, standard_scale).reshape(image.shape)\n",
    "\n",
    "class PiecewiseHistScaling(RandTransform):\n",
    "    split_idx,order = None, 10\n",
    "    def __init__(self, landmark_percs=None, standard_scale=None, p=1., **kwargs):\n",
    "        super().__init__(p, **kwargs)\n",
    "        if landmark_percs is None or standard_scale is None:\n",
    "            raise ValueError('Landmark parcs and standard scale nned to be provided.'\n",
    "                             'You can run `standard_scale_from_filelist` or `standard_scale_from_dls` '\n",
    "                             'To get an estiamtion of the values. Alternatively you can use the '\n",
    "                             '`PiecewiseHistNormalizationCallback` which will automatically calulated '\n",
    "                             'the needed values before the first epoch.')\n",
    "        store_attr()\n",
    "\n",
    "    def encodes(self, x:TensorDicom3D)->TensorDicom3D:\n",
    "        return x.piecewise_hist(self.landmark_percs, self.standard_scale)\n",
    "    \n",
    "    def encodes(self, x:TensorMask3D)->TensorMask3D: return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scale, percs = find_standard_scale(images)\n",
    "standard_scale, percs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.apply(PiecewiseHistScaling(landmark_percs=percs, \n",
    "                                  standard_scale=standard_scale)).show_L(nrow = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def standard_scale_from_filelist(fns:(list, pd.Series)):\n",
    "    scales = []\n",
    "    for fn in tqdm(fns):\n",
    "        x = TensorDicom3D.create(fn)\n",
    "        scale, percs = find_standard_scale(x)\n",
    "        scales.append(scale)\n",
    "    return torch.stack(scales).mean(0), percs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders # for compatibility with show_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def standard_scale_from_dls(dls:DataLoaders):\n",
    "    \"calculates standard scale from images in a dataloader\"\n",
    "    scales = [] \n",
    "    for i, pair in tqdm(enumerate(dls.train_ds)):\n",
    "        x, _ = pair\n",
    "        scale, percs = find_standard_scale(x)\n",
    "        scales.append(scale)\n",
    "    return torch.stack(scales).mean(0), percs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_basics.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_transforms.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_layers.ipynb.\n",
      "Converted 06_learner.ipynb.\n",
      "Converted 06a_models.alexnet.ipynb.\n",
      "Converted 06b_models.resnet.ipynb.\n",
      "Converted 06c_models.densenet.ipynb.\n",
      "Converted 06d_models.unet.ipynb.\n",
      "Converted 06e_models.deeplabv3.ipynb.\n",
      "Converted 06f_models.losses.ipynb.\n",
      "Converted 07_callback.ipynb.\n",
      "Converted 99_tools.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
