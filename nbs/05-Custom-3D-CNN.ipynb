{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing 3D CNNs\n",
    "\n",
    "The dimension of a CNN does not refer to the dimensions of the input but to the dimensions of the kernel stride.  \n",
    "1D kernel moves only left-right (or up-down)  \n",
    "2D kernel moves left-right and up-down  \n",
    "3D kernel moves left-right, up-down and forward-backwards.   \n",
    "\n",
    "Thus with a kernel of size (3,3,20) a 3D volume of size (150,150,20) could be processed. The present 2D CNN from pytorch and fastai could thus easily be adapted. However, small findings which only occur in a feq slices could disappear in the convolutions, so 3D CNNs with smaller kernels might be better.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models\n",
    "# export \n",
    "\n",
    "import torchvision, torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.register_buffer('noise', torch.tensor(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.expand(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow, in 3D CNNs, the input is not transfered to cuda. I believe something in the transforms is wrong. Until this is fixed, subcalssing _\n",
    "\n",
    "is the workarround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Sequential_(nn.Sequential):\n",
    "    \"Similar to nn.Sequential, but copies input to cuda\"\n",
    "    def forward(self, input):\n",
    "        for module in self:\n",
    "            input = module(input.cuda())\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom 3D CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def resnet_3d(n_input, n_classes):\n",
    "    return Sequential_(\n",
    "        # 1st Conv Block\n",
    "        nn.Conv3d(n_input, 128, kernel_size = (3,7,7), stride = (2, 2, 1), padding = (1, 3, 3), bias = True),\n",
    "        nn.BatchNorm3d(128, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "\n",
    "        # 2nd Conv Block\n",
    "        nn.Conv3d(128, 256, kernel_size = (3,4,4), stride = (2, 2, 2), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(256, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "        \n",
    "        # 3rd Conv Block\n",
    "        nn.Conv3d(256, 384, kernel_size = (3,1,1), stride = (1, 1, 1), padding = (0, 0, 0), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "        \n",
    "        # 1st Res Block\n",
    "        nn.Conv3d(384, 512, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(512, 512, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(512, 512, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(512, 512, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "                \n",
    "        nn.AdaptiveAvgPool3d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512, n_classes), \n",
    "        nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(20, 128, kernel_size=11, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.AvgPool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.softmax =  nn.LogSoftmax(dim=1)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "        out = self.layer1(x)\n",
    "   #     print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "   #     print(out.shape)\n",
    "        out = self.AvgPool(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.flatten(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.fc1(out)\n",
    " #       print(out.shape)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custon 3D UNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# copied from who????\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = Sequential_(\n",
    "            nn.Conv3d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = Sequential_(\n",
    "            nn.MaxPool3d(kernel_size = (2, 2, 2)),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if trilinear, use the normal convolutions to reduce the number of channels\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2, \n",
    "                        diffZ // 2, diffZ - diffZ // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        \n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = Sequential_(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, trilinear=False):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.trilinear = trilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if trilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, trilinear)\n",
    "        self.up2 = Up(512, 256 // factor, trilinear)\n",
    "        self.up3 = Up(256, 128 // factor, trilinear)\n",
    "        self.up4 = Up(128, 64, trilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "#        print('x:', x.shape)\n",
    "        x1 = self.inc(x)\n",
    "#        print('x1:', x1.shape)\n",
    "        x2 = self.down1(x1)\n",
    "#        print('x2:', x2.shape)\n",
    "        x3 = self.down2(x2)\n",
    "#        print('x3:', x3.shape)\n",
    "        x4 = self.down3(x3)\n",
    "#        print('x4:', x4.shape)\n",
    "        x5 = self.down4(x4)\n",
    "#        print('x5:', x5.shape)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "#        print('x:', x.shape)\n",
    "        x = self.up2(x, x3)\n",
    "#        print('x:', x.shape)\n",
    "        x = self.up3(x, x2)\n",
    "#        print('x:', x.shape)\n",
    "        x = self.up4(x, x1)\n",
    "#        print('x:', x.shape)\n",
    "        logits = self.outc(x)\n",
    "#        print(logits.shape)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DiceLossBinary():\n",
    "    \n",
    "    \"\"\"\n",
    "    Simple DICE loss as described in: \n",
    "        https://arxiv.org/pdf/1911.02855.pdf    \n",
    "    \n",
    "    Computes the Sørensen–Dice loss. Larger is better. \n",
    "    Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1. \n",
    "    \n",
    "    Args:\n",
    "        targ: a tensor of shape [B, 1, D, H, W].\n",
    "        pred: a tensor of shape [B, C, D, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability (acoid division by 0).\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, method = 'miletari', alpha = 0.5, beta = 0.5, eps = 1e-7, smooth = 1.) -> None:\n",
    "        self.method = method \n",
    "        self.alpha = alpha \n",
    "        self.beta = beta \n",
    "        self.eps = eps\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        if input.min() < 0 or input.max() > 1: \n",
    "            warn(\"Input is not in range between 0 and 1 but the loss will work better with input in that range. Consider rescaling your input. \")\n",
    "           \n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "\n",
    "        if self.method == 'simple':\n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            denominator  = torch.sum(input + target, dims) + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "\n",
    "        elif self.method == 'miletari':  \n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            denominator  = torch.sum(input**2 + target**2, dims) + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "\n",
    "        elif self.method == 'tversky':\n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            fps = torch.sum(input * (1 - target), dims)\n",
    "            fns = torch.sum((1 - input) * target, dims)\n",
    "\n",
    "            denominator  = numerator + self.alpha*fps + self.beta*fns + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "            \n",
    "        else: \n",
    "            raise NotImplementedError('The specified type of DICE loss is not implemented')\n",
    "\n",
    "        return 1-dice_loss \n",
    "    \n",
    "    \n",
    "class MCCLossBinary(DiceLossBinary):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the MCC loss. Larger is better. \n",
    "    For this loss to work best, the input should be in range 0-1, e.g. enforced through a sigmoid or softmax. \n",
    "    Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1. \n",
    "    Args:\n",
    "        input: a tensor of shape [B, 1, D, H, W].\n",
    "        target: a tensor of shape [B, C, D, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        if input.min() < 0 or input.max() > 1: \n",
    "            warn(\"Input is not in range between 0 and 1 but the loss will work better with input in that range. Consider rescaling your input. \")\n",
    "        \n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "\n",
    "        tps = torch.sum(input * target, dims) + self.smooth  # geht nur wenn preds zwischen 0 und 1 sind, softmax am ende des unets sollte noch gemacht werden\n",
    "        fps = torch.sum(input * (1 - target), dims)\n",
    "        fns = torch.sum((1 - input) * target, dims)\n",
    "        tns = torch.sum((1 - input) * (1-target), dims)\n",
    "            \n",
    "        numerator = (tps * tns - fps * fns) + self.smooth\n",
    "        denominator =  ((tps + fps) * (tns + tns) * (fps + tns) * (tps + fns))**0.5 + self.smooth\n",
    "\n",
    "        mcc_loss = numerator / (denominator + self.eps)\n",
    "        \n",
    "        return 1-mcc_loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"1 - `accuracy`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/fastai/metrics.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " fastai.metrics.error_rate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "def mcc_binary(input, target, thres = 0.5):\n",
    "    dims = (0,) + tuple(range(2, target.ndim))\n",
    "    input = torch.where(input > thres, tensor(1.).cuda(), tensor(0.).cuda())\n",
    "    mcc = MCCLossBinary(smooth = 0.)(input, target)\n",
    "\n",
    "    return torch.mean(1-mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.randn(5,5,5).cuda()\n",
    "i = torch.sigmoid(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(5,5,5).cuda()\n",
    "t = torch.where(t>0, tensor(1.).cuda(), tensor(0.).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0154, device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_binary(i, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
