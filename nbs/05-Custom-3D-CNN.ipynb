{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing 3D CNNs\n",
    "\n",
    "The dimension of a CNN does not refer to the dimensions of the input but to the dimensions of the kernel stride.  \n",
    "1D kernel moves only left-right (or up-down)  \n",
    "2D kernel moves left-right and up-down  \n",
    "3D kernel moves left-right, up-down and forward-backwards.   \n",
    "\n",
    "Thus with a kernel of size (3,3,20) a 3D volume of size (150,150,20) could be processed. The present 2D CNN from pytorch and fastai could thus easily be adapted. However, small findings which only occur in a feq slices could disappear in the convolutions, so 3D CNNs with smaller kernels might be better.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models\n",
    "# export \n",
    "\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.register_buffer('noise', torch.tensor(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.expand(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow, in 3D CNNs, the input is not transfered to cuda. I believe something in the transforms is wrong. Until this is fixed, subcalssing nn.Sequential is the workarround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Sequential_(nn.Sequential):\n",
    "    \"Similar to nn.Sequential, but copies input to cuda\"\n",
    "    def forward(self, input):\n",
    "        for module in self:\n",
    "            input = module(input.cuda())\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom 3D Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def resnet_3d(n_input, n_classes):\n",
    "    return Sequential_(\n",
    "        # 1st Conv Block\n",
    "        nn.Conv3d(n_input, 128, kernel_size = (7,7,3), stride = (2, 2, 1), padding = (3, 3, 1), bias = True),\n",
    "        nn.BatchNorm3d(128, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "\n",
    "        # 2nd Conv Block\n",
    "        nn.Conv3d(128, 256, kernel_size = (4,4,3), stride = (2, 2, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(256, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "        \n",
    "        # 3rd Conv Block\n",
    "        nn.Conv3d(256, 384, kernel_size = (1,1,3), stride = (1, 1, 2), padding = (0, 0, 0), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "        \n",
    "        # 1st Res Block\n",
    "        nn.Conv3d(384, 512, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(512, 512, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(512, 512, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(512, 512, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "                \n",
    "        nn.AdaptiveAvgPool3d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512, n_classes), \n",
    "        nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(20, 128, kernel_size=11, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.AvgPool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.softmax =  nn.LogSoftmax(dim=1)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "        out = self.layer1(x)\n",
    "   #     print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "   #     print(out.shape)\n",
    "        out = self.AvgPool(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.flatten(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.fc1(out)\n",
    " #       print(out.shape)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
