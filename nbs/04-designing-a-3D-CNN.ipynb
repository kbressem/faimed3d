{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing 3D CNNs\n",
    "\n",
    "The dimension of a CNN does not refer to the dimensions of the input but to the dimensions of the kernel stride.  \n",
    "1D kernel moves only left-right (or up-down)  \n",
    "2D kernel moves left-right and up-down  \n",
    "3D kernel moves left-right, up-down and forward-backwards.   \n",
    "\n",
    "Thus with a kernel of size (3,3,20) a 3D volume of size (150,150,20) could be processed. The present 2D CNN from pytorch and fastai could thus easily be adapted. However, small findings which only occur in a feq slices could disappear in the convolutions, so 3D CNNs with smaller kernels might be better.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models\n",
    "# export \n",
    "\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting 2d CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.vision.models as models\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"ResNet-18 model from\u001b[0m\n",
       "\u001b[0;34m    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        pretrained (bool): If True, returns a model pre-trained on ImageNet\u001b[0m\n",
       "\u001b[0;34m        progress (bool): If True, displays a progress bar of the download to stderr\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet18'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                   \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/fastai-v2/lib/python3.7/site-packages/torchvision/models/resnet.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torchvision.models.resnet18??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# https://github.com/Ontheroad123/ImageNet/blob/master/torch-alexnet-3D.py\n",
    "\n",
    "class AlexNet_3D(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2, n_dim=7):\n",
    "        super(AlexNet_3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(n_dim, 512, kernel_size=(5,5,1), stride=(2,2,1), padding=(2,2,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "\n",
    "            nn.Conv3d(512, 256, kernel_size=(5,5,3), padding=(2,2,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.8),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "            \n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.Conv3d(256, 128, kernel_size=(5,5,3), padding=(2,2,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.8),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "            \n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.Conv3d(128, 384, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "           \n",
    "            nn.BatchNorm3d(384),\n",
    "            nn.Conv3d(384, 256, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.Conv3d(256, 256, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(11520, 4096), #6 * 6* 4, 4096),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 512),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0),x.size(1)*x.size(2)*x.size(3)*x.size(4) ) #6 * 6 * 4)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def alexnet_3d(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"3D AlexNet model architecture, adapted from https://github.com/Ontheroad123/ImageNet/blob/master/torch-alexnet-3D.py\n",
    "    \n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = AlexNet_3D(**kwargs)\n",
    "    if pretrained:\n",
    "        \"currently no pretained weights for 3D Alexnet available\"\n",
    "        pass \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.vision.models as models\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a very basic 2d conv net\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(20, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(40000, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 2)\n",
    "        self.softmax =  nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "        out = self.layer1(x)\n",
    "   #     print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "   #     print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "   #     print(out.shape)\n",
    "        out = self.drop_out(out)\n",
    " #       print(out.shape)\n",
    "        out = self.fc1(out)\n",
    " #       print(out.shape)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basic alexnet, adapted for batchsize\n",
    "class AlexNet_(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet_, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(20, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(   \n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer5 = nn.Sequential(    \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        self.softmax =  nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "   #     print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.layer4(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.layer5(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "   #     print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "   #     print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
