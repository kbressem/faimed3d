{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import re\n",
    "import pathlib\n",
    "import torchvision\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.medical.imaging import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "import fastai\n",
    "from faimed3d import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(sitk.Version())\n",
    "for name, val in globals().items():\n",
    "    if isinstance(val, types.ModuleType):\n",
    "        try: \n",
    "            print(val.__name__ + ': ' + val.__version__)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "SimpleITK Version: 2.0.0rc3 (ITK 5.1)\n",
    "Compiled: Aug 25 2020 15:43:37\n",
    "\n",
    "re: 2.2.1\n",
    "torchvision: 0.7.0\n",
    "platform: 1.0.8\n",
    "numpy: 1.19.1\n",
    "csv: 1.0\n",
    "json: 2.0.9\n",
    "matplotlib: 3.3.1\n",
    "requests: 2.24.0\n",
    "yaml: 5.3.1\n",
    "pandas: 1.1.1\n",
    "scipy: 1.5.2\n",
    "scipy.ndimage: 2.0\n",
    "torch: 1.6.0\n",
    "PIL.Image: 7.2.0\n",
    "fastai: 2.0.10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Ontheroad123/ImageNet/blob/master/torch-alexnet-3D.py\n",
    "\n",
    "class AlexNet_3D(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AlexNet_3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(7, 512, kernel_size=(5,5,1), stride=(2,2,1), padding=(2,2,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "\n",
    "            nn.Conv3d(512, 256, kernel_size=(5,5,3), padding=(2,2,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.8),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "            \n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.Conv3d(256, 128, kernel_size=(5,5,3), padding=(2,2,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.8),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "            \n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.Conv3d(128, 384, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "           \n",
    "            nn.BatchNorm3d(384),\n",
    "            nn.Conv3d(384, 256, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.Conv3d(256, 256, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(11520, 4096), #6 * 6* 4, 4096),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 512),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0),x.size(1)*x.size(2)*x.size(3)*x.size(4) ) #6 * 6 * 4)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def alexnet_3d(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"3D AlexNet model architecture, adapted from https://github.com/Ontheroad123/ImageNet/blob/master/torch-alexnet-3D.py\n",
    "    \n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = AlexNet_3D(**kwargs)\n",
    "    if pretrained:\n",
    "        \"currently no pretained weights for 3D Alexnet available\"\n",
    "        pass \n",
    "    return model\n",
    "\n",
    "def make_pseudo_color(t): \n",
    "    '''\n",
    "    The 3D CNN still expects color images, so a pseudo color image needs to be created as long as I don't adapt the 3D CNN\n",
    "    '''\n",
    "    if t.size(0) % 3 == 0:\n",
    "        t_col = torch.stack((t[slice(0,t.size(0)-2,3), :, : ], \n",
    "                             t[slice(1,t.size(0)-1,3), :, : ], \n",
    "                             t[slice(2,t.size(0)-0,3), :, : ])).permute( 1, 2, 3, 0)\n",
    "    else:\n",
    "        import warnings\n",
    "        warnings.warn('slice number is not divisible by 3, will stack the same tensor three times to create the color channels,')\n",
    "        t_col = torch.stack((t, t, t)).permute( 1, 2, 3, 0) # important step, ensuring rigth format of tensors\n",
    "    return t_col.float() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://github.com/Ontheroad123/ImageNet/blob/master/torch-alexnet-3D.py\n",
    "\n",
    "class AlexNet_3D(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AlexNet_3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(7, 512, kernel_size=(5,5,1), stride=(2,2,1), padding=(2,2,1)),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "\n",
    "            nn.Conv3d(512, 256, kernel_size=(5,5,3), padding=(2,2,1)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "            \n",
    "            nn.Conv3d(256, 384, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.BatchNorm3d(384),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv3d(384, 256, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv3d(256, 256, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(480, 240), #6 * 6* 4, 4096),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(240, 120),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 480) #6 * 6 * 4)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def alexnet_3d(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"3D AlexNet model architecture, adapted from https://github.com/Ontheroad123/ImageNet/blob/master/torch-alexnet-3D.py\n",
    "    \n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = AlexNet_3D(**kwargs)\n",
    "    if pretrained:\n",
    "        \"currently no pretained weights for 3D Alexnet available\"\n",
    "        pass \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pytorch Dataloaders\n",
    "\n",
    "### Get data paths and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pathlib.Path('../../data/train')\n",
    "valid = pathlib.Path('../../data/valid')\n",
    "test = pathlib.Path('../../data/test')\n",
    "\n",
    "train_files = list(train.rglob('DICOM'))\n",
    "valid_files = list(valid.rglob('DICOM'))\n",
    "test_files = list(test.rglob('DICOM'))\n",
    "\n",
    "# take only T2 and T1 images for noe\n",
    "subset_train =[]\n",
    "for f in train_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_train.append(Path(m.string))\n",
    "        \n",
    "subset_valid =[]\n",
    "for f in valid_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_valid.append(Path(m.string))\n",
    "        \n",
    "subset_test = []\n",
    "for f in test_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_test.append(Path(m.string))\n",
    "        \n",
    "        \n",
    "def label_func(fn):\n",
    "    return re.findall(r'(Gesund|ProstataCa)', str(fn))[0]\n",
    "labels = ['Gesund', 'ProstataCa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling of healthy patients (id 0:33 of train dataset to create a class balance)\n",
    "oversampled_train = subset_train*10 + random.choices(subset_train[slice(0, 33)], k = 23*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(oversampled_train) # shuffles the list in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_presize = Pipeline([partial(read_medical_3d_image, return_scaled=True, return_normalized=True), \n",
    "                             partial(crop_3d_tensor, margins=(0.0, 0.15, 0.15), perc_margins=True), \n",
    "                             partial(resize_3d_tensor, new_shape=(27, 200, 200))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cropper = RandomCrop3D()\n",
    "Cropper.setup(items = ((3,25,25), (2,10,10))) # final size after cropping will be (21, 100, 100), which will then be stacked to (7, 100, 100, 3) by make_pseudo_color\n",
    "\n",
    "tfms = [Pipeline([RandomBrightness3D(p=0.9), Cropper], split_idx = 0), \n",
    "        Pipeline([RandomContrast3D(p=0.9), Cropper], split_idx = 0), \n",
    "        Pipeline([RandomWarp3D(p=0.9), Cropper], split_idx = 0), \n",
    "        Pipeline([RandomDihedral3D(p=0.9), Cropper], split_idx = 0), \n",
    "        Pipeline([RandomDihedral3D(p=0.9), Cropper], split_idx = 0), \n",
    "        Pipeline([RandomDihedral3D(p=0.9), Cropper], split_idx = 0), \n",
    "        Pipeline([RandomNoise3D(p=0.9), Cropper], split_idx = 0), \n",
    "        Pipeline([RandomRotate3DBy(p=0.9), Cropper], split_idx = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProstateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "        self.labels = [label_func(f) for f in files]\n",
    "        self.tcat = Categorize(vocab=labels)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        file = self.files[i]\n",
    "        cls = self.tcat(self.labels[i])\n",
    "        f = load_and_presize(file)\n",
    "        i = random.randint(0, len(tfms)-1)\n",
    "        f = tfms[i](f)\n",
    "        return (make_pseudo_color(f), torch.Tensor([cls]).squeeze())\n",
    "\n",
    "#    def __getitem__(self, i):\n",
    "#        file = self.files[i]\n",
    "#        cls = self.tcat(self.labels[i])\n",
    "#        f = self.preprocessing(file)\n",
    "#        f = self.get_tfm()(f)\n",
    "#        return (make_pseudo_color(f), torch.Tensor([cls]).squeeze())\n",
    "    \n",
    "    def set_tfms(self, tfms):\n",
    "        self.tfms = tfms\n",
    "        \n",
    "    def set_preprocessing(self, func):\n",
    "        self.preprocessing = func\n",
    "    \n",
    "    def get_tfm(self):\n",
    "        i = random.randint(0, len(self.tfms)-1)\n",
    "        return tfms[i]\n",
    "\n",
    "    def __len__(self): return len(self.files)\n",
    "    \n",
    "train_ds = ProstateDataset(oversampled_train) # fewer epochs, less clutter on the screen during training. Significant increase in accuracy does appear after 100-150 epochs (with single training subset)\n",
    "valid_ds = ProstateDataset(subset_valid)\n",
    "test_ds = ProstateDataset(subset_test)\n",
    "\n",
    "#train_ds.set_preprocessing(load_and_presize)\n",
    "#train_ds.set_tfms(tfms)\n",
    "\n",
    "#valid_ds.set_preprocessing(load_and_presize)\n",
    "#valid_ds.set_tfms(Pipeline([Cropper])\n",
    "\n",
    "#test_ds.set_preprocessing(load_and_presize)\n",
    "#test_ds.set_tfms(Pipeline([Cropper]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, \n",
    "          batch_size = 24, \n",
    "          pin_memory = False, \n",
    "          num_workers = 48)\n",
    "valid_dl = DataLoader(valid_ds, \n",
    "          batch_size = 20, \n",
    "          pin_memory = False, \n",
    "          num_workers = 48)\n",
    "test_dl = DataLoader(test_ds, \n",
    "          batch_size = 20, \n",
    "          pin_memory = False, \n",
    "          num_workers = 48)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dls.cuda()\n",
    "def loss_func(out, targ):\n",
    "    return CrossEntropyLossFlat()(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = RocAucBinary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, AlexNet_3D(), opt_func = SGD, loss_func = loss_func, metrics = [error_rate, roc])\n",
    "learn = learn.to_fp16()\n",
    "#learn = learn.to_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.707710</td>\n",
       "      <td>0.693286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>03:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(n_epoch = 1, lr_max = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, target = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = F.softmax(preds, dim = 1)[:, 1].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's usually because your network is not complex enough to find a pattern between your input vectors and your output vectors, and therefore, your last output layer is converging towards the average vector of all the outputs in your dataset.\n",
    "\n",
    "To overcome this there are a few techniques:\n",
    "\n",
    "1. Try to do some more preprocessing to your inputs, perhaps a PCA on your attributes.\n",
    "2. Visualize your layers, try to add random vectors as your input and check the outputs of each layer. There must be just one layer which would be outputting almost the same vector everytime, causing problems for your higher level neurons.\n",
    "3. Reduce your learning rate.\n",
    "4. Reduce your batch size.\n",
    "5. Stack more layers.\n",
    "6. Check if your model is actually learning : send random noise as your data, and the network loss should not be decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "ns_fpr, ns_tpr, _ = roc_curve(target.numpy(), preds)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(n_epoch = 100, lr_max = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11520/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
