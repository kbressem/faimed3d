{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a custom datablock for 3D images and fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import re\n",
    "import pathlib\n",
    "import torchvision\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.medical.imaging import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "import fastai\n",
    "from faimed3d import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pytorch Dataloaders\n",
    "\n",
    "### Get data paths and labels\n",
    "\n",
    "Data is divided into a train, valid and test dataset of different patients, which either have prostate cancer or are healthy. \n",
    "Each patient has three MRI sequences: T2, T1map and ADC. These sequences differ in number of slices and resolution. \n",
    "\n",
    "At first the paths to the data are specified: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pathlib.Path('../../data/train')\n",
    "valid = pathlib.Path('../../data/valid')\n",
    "test = pathlib.Path('../../data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, I am only interested into the DICOM data, not in the NIfTI segmentations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = list(train.rglob('DICOM'))\n",
    "valid_files = list(valid.rglob('DICOM'))\n",
    "test_files = list(test.rglob('DICOM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce complexity of the data, only the T2 map will be used for the first runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only T2 and T1 images for noe\n",
    "subset_train =[]\n",
    "for f in train_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_train.append(Path(m.string))\n",
    "        \n",
    "subset_valid =[]\n",
    "for f in valid_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_valid.append(Path(m.string))\n",
    "        \n",
    "subset_test = []\n",
    "for f in test_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_test.append(Path(m.string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the patient has prostate cancer or not, can be extracted from the file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Gesund', 'ProstataCa']\n",
    "def label_func(fn): return re.findall(r'(Gesund|ProstataCa)', str(fn))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt fastai dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "class TensorDicom3D(Tensor):\n",
    "    \"Base class for 3D Dicom Tensor. Inherits from `torch.Tensor`\"\n",
    "    \n",
    "    def freqhist_bins(self:Tensor, n_bins=100):\n",
    "        '''\n",
    "        A function to split the range of pixel values into groups, such that each group has around the same number of pixels. \n",
    "        taken from https://github.com/fastai/fastai/blob/master/fastai/medical/imaging.py#L78\n",
    "        '''\n",
    "        imsd = self.view(-1).sort()[0]\n",
    "        t = torch.cat([tensor([0.001]),\n",
    "                       torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n",
    "                       tensor([0.999])])\n",
    "        t = (len(imsd)*t).long()\n",
    "        return imsd[t].unique()\n",
    "\n",
    "    def hist_scaled(self:Tensor, brks=None):\n",
    "        '''\n",
    "        Scales a tensor using `freqhist_bins` to values between 0 and 1\n",
    "        taken from https://github.com/fastai/fastai/blob/master/fastai/medical/imaging.py#L78\n",
    "        '''\n",
    "        if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n",
    "        if brks is None: brks = self.freqhist_bins()\n",
    "        ys = np.linspace(0., 1., len(brks))\n",
    "        x = self.numpy().flatten()\n",
    "        x = np.interp(x, brks.numpy(), ys)\n",
    "        x = tensor(x).reshape(self.shape).clamp(0.,1.)\n",
    "        return retain_type(x, typ = TensorDicom3D)\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, fn:(Path,str,Tensor,ndarray), **kwargs)->None:\n",
    "        \"Open an `3D Image` from path `fn` or create it from an array\"\n",
    "        if isinstance(fn,ndarray): return cls(fn)\n",
    "        if isinstance(fn, Tensor): return cls(fn)\n",
    "        return cls(load_image_3d(fn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def load_image_3d(fn: (pathlib.Path, str)):\n",
    "    if isinstance(fn, str): fn = Path(fn)\n",
    "        \n",
    "    if fn.is_dir(): \n",
    "        SeriesReader = sitk.ImageSeriesReader()\n",
    "        dicom_names = SeriesReader.GetGDCMSeriesFileNames(str(fn))\n",
    "        SeriesReader.SetFileNames(dicom_names)\n",
    "        im = SeriesReader.Execute()\n",
    "        im = sitk.Cast(im, sitk.sitkInt16)\n",
    "    \n",
    "    elif fn.is_file():\n",
    "        im = sitk.ReadImage(str(fn), outputPixelType=sitk.sitkInt16)\n",
    "    \n",
    "    else:\n",
    "        raise TypeError('the path \"{}\" is neither a valid directory nor a file'.format(str(fn)))\n",
    "    \n",
    "    return torch.tensor(sitk.GetArrayFromImage(im)).float()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@patch\n",
    "def resize_3d(t: (TensorDicom3D), size: int):\n",
    "    \n",
    "    '''\n",
    "    A function to resize a 3D image using torch.nn.functional.grid_sample\n",
    "    \n",
    "    Taken form the offical documention: \n",
    "        Given an input and a flow-field grid, computes the output using input values and pixel locations from grid.\n",
    "        In the spatial (4-D) case, for input with shape (N,C,Hin,Win) and with grid in shape (N, Hout, Wout, 2), the output will have shape (N, C, Hout,Wout)\n",
    "        \n",
    "        In the case of 5D inputs, grid[n, d, h, w] specifies the x, y, z pixel locations for interpolating output[n, :, d, h, w]. \n",
    "        mode argument specifies nearest or bilinear interpolation method to sample the input pixels.\n",
    "        \n",
    "    Workflow of this function: \n",
    "    1. create a fake RGB 3D image through generating fake color channels.\n",
    "    2. add a 5th batch dimension\n",
    "    3. create a flow-field for rescaling:\n",
    "        a. create a 1D tensor giving a linear progression from -1 to 1\n",
    "        b. creat a mesh-grid (the flow field) from x,y,z tensors from (a)\n",
    "    4. resample the input tensor according to the flow field\n",
    "    5. remove fake color channels and batch dim, returning only the 3D tensor\n",
    "        \n",
    "    Args:\n",
    "        t (Tensor): a Rank 3 Tensor to be resized\n",
    "        new_dim (int): a tuple with the new x,y,z dimensions of the tensor after resize\n",
    "        \n",
    "    '''\n",
    "    if type(size) in (tuple, fastuple) and len(size) == 3:\n",
    "        z,x,y = size # for a reason, I do currently not understand, order of the axis changes from resampling. flipping the order of x,y,z is the current workaround\n",
    "    else:\n",
    "        raise ValueError('\"size\" must be a tuple with length 3, specifying the new (x,y,z) dimensions of the 3D tensor')\n",
    "    \n",
    "    t = torch.stack((t,t,t)) # create fake color channel\n",
    "    t = t.unsqueeze(0).float() # create batch dim    \n",
    "\n",
    "    x = torch.linspace(-1, 1, x) # create resampling 'directions' for pixels in each axis\n",
    "    y = torch.linspace(-1, 1, y)\n",
    "    z = torch.linspace(-1, 1, z)\n",
    "\n",
    "    meshx, meshy, meshz = torch.meshgrid((x, y, z)) # \n",
    "    grid = torch.stack((meshy, meshx , meshz), 3) # create flow field. x and y need to be switched as otherwise the images are rotated. \n",
    "    grid = grid.unsqueeze(0) # add batch dim\n",
    "    t_resized = F.grid_sample(t, grid, align_corners=True, mode = 'bilinear') # rescale the 5D tensor\n",
    "    return t_resized[0,0,:,:,:].permute(2,0,1).contiguous() # remove fake color channels and batch dim, reorder the image (the Z axis has moved to the back...)\n",
    "\n",
    "class Resize3D(RandTransform):\n",
    "    split_idx,order = None, 1\n",
    "    \"Resize a 3D image\"\n",
    "    \n",
    "    def __init__(self, size, **kwargs): \n",
    "        size = _process_sz_3d(size)\n",
    "        store_attr()\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def encodes(self, x: TensorDicom3D): return x.resize_3d(self.size)\n",
    "    \n",
    "def _process_sz_3d(size):\n",
    "    if len(size) == 2: size=(size[0],size[1], size[1])\n",
    "    return fastuple(size[0],size[1],size[2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "class ResizeCrop3D(RandTransform):\n",
    "    split_idx,order = None, 1\n",
    "    \n",
    "    \"Resize and crop a 3D tensor\"\n",
    "    \n",
    "    def __init__(self, crop_by, resize_to, perc_crop=False, p=1, **kwargs): \n",
    "        resize_to = _process_sz_3d(resize_to)\n",
    "        crop_by = crop_by\n",
    "        perc_crop = perc_crop\n",
    "        store_attr()\n",
    "        super().__init__(p=p,**kwargs)\n",
    "\n",
    "    def encodes(self, x:TensorDicom3D): \n",
    "        if type(self.crop_by) is tuple and len(self.crop_by) == 3:\n",
    "            cropx, cropy, cropz = self.crop_by\n",
    "            try: x1,x2 = cropx\n",
    "            except: x1,x2 = cropx,cropx\n",
    "            try: y1,y2 = cropy\n",
    "            except: y1,y2 = cropy,cropy\n",
    "            try: z1,z2 = cropz\n",
    "            except: z1,z2 = cropz,cropz\n",
    "                    \n",
    "            self.margins = (x1,x2,y1,y2,z1,z2)\n",
    "\n",
    "        else: raise ValueError('\"crop_by\" must be a tuple with length 3 in the form ox (x,y,z) or ((x1,x2),(y1,y2),(z1,z2))')\n",
    "        if any(self.margins) < 0: raise ValueError('cannot crop to a negative dimension')\n",
    "    \n",
    "        return x.crop_3d(margins = self.margins, perc_margins = self.perc_crop).resize_3d(self.size)\n",
    "\n",
    "def _process_sz_3d(size):\n",
    "    if len(size) == 2: size=(size[0],size[1], size[1])\n",
    "    return fastuple(size[0],size[1],size[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = read_medical_3d_image(subset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc3d = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (10, 50, 50), perc_crop = True),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ResizeCrop3D -- {'crop_by': (0.0, 0.1, 0.1), 'resize_to': (10, 50, 50), 'perc_crop': True, 'p': 1}:\n",
       " encodes: (TensorDicom3D,object) -> encodes\n",
       " decodes: ,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock(cls=TensorDicom3D), \n",
    "              CategoryBlock),\n",
    "    get_x = lambda x: x,\n",
    "    get_y = label_func, \n",
    "    item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (10, 50, 50), perc_crop = True),\n",
    "    splitter = RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from [Path('../../data/test/Gesund/A0041126717/T2/DICOM'), Path('../../data/test/Gesund/A0041720206/T2/DICOM'), Path('../../data/test/Gesund/A0041983224/T2/DICOM'), Path('../../data/test/Gesund/A0041886483/T2/DICOM'), Path('../../data/test/Gesund/A0040860335/T2/DICOM'), Path('../../data/test/Gesund/A0001504907/T2/DICOM'), Path('../../data/test/Gesund/A0041839275/T2/DICOM'), Path('../../data/test/Gesund/A0040169930/T2/DICOM'), Path('../../data/test/Gesund/A0001047141/T2/DICOM'), Path('../../data/test/Gesund/A0042256547/T2/DICOM'), Path('../../data/test/ProstataCa/A0071496463/T2/DICOM'), Path('../../data/test/ProstataCa/A0041794296/T2/DICOM'), Path('../../data/test/ProstataCa/A0041945145/T2/DICOM'), Path('../../data/test/ProstataCa/A0041324313/T2/DICOM'), Path('../../data/test/ProstataCa/A0041877685/T2/DICOM'), Path('../../data/test/ProstataCa/A0042184416/T2/DICOM'), Path('../../data/test/ProstataCa/A0001436600/T2/DICOM'), Path('../../data/test/ProstataCa/V0042226328/T2/DICOM'), Path('../../data/test/ProstataCa/A0042109450/T2/DICOM'), Path('../../data/test/ProstataCa/A0040518123/T2/DICOM')]\n",
      "Found 20 items\n",
      "2 datasets of sizes 16,4\n",
      "Setting up Pipeline: <lambda> -> TensorDicom3D.create\n",
      "Setting up Pipeline: label_func -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: <lambda> -> TensorDicom3D.create\n",
      "    starting from\n",
      "      ../../data/test/ProstataCa/V0042226328/T2/DICOM\n",
      "    applying <lambda> gives\n",
      "      ../../data/test/ProstataCa/V0042226328/T2/DICOM\n",
      "    applying TensorDicom3D.create gives\n",
      "      TensorDicom3D of size 25x736x736\n",
      "  Pipeline: label_func -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "    starting from\n",
      "      ../../data/test/ProstataCa/V0042226328/T2/DICOM\n",
      "    applying label_func gives\n",
      "      ProstataCa\n",
      "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
      "      TensorCategory(1)\n",
      "\n",
      "Final sample: (tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ..., 56.,  4., 11.],\n",
      "         [ 0.,  0.,  0.,  ..., 81.,  0.,  9.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  7.,  1.,  1.],\n",
      "         [ 0.,  0.,  0.,  ..., 10.,  0.,  1.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]), TensorCategory(1))\n",
      "\n",
      "\n",
      "Setting up after_item: Pipeline: ResizeCrop3D -- {'crop_by': (0.0, 0.1, 0.1), 'resize_to': (10, 50, 50), 'perc_crop': True, 'p': 1} -> ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ResizeCrop3D -- {'crop_by': (0.0, 0.1, 0.1), 'resize_to': (10, 50, 50), 'perc_crop': True, 'p': 1} -> ToTensor\n",
      "    starting from\n",
      "      (TensorDicom3D of size 25x736x736, TensorCategory(1))\n",
      "    applying ResizeCrop3D -- {'crop_by': (0.0, 0.1, 0.1), 'resize_to': (10, 50, 50), 'perc_crop': True, 'p': 1} gives\n",
      "      (TensorDicom3D of size 10x50x50, TensorCategory(1))\n",
      "    applying ToTensor gives\n",
      "      (TensorDicom3D of size 10x50x50, TensorCategory(1))\n",
      "\n",
      "Adding the next 3 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "Applying batch_tfms to the batch built\n",
      "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n",
      "    starting from\n",
      "      (TensorDicom3D of size 4x10x50x50, TensorCategory([1, 0, 1, 0], device='cuda:0'))\n",
      "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
      "      (TensorDicom3D of size 4x10x50x50, TensorCategory([1, 0, 1, 0], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "mris.summary(subset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f124be6c881c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCrossEntropyLossFlat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dls' is not defined"
     ]
    }
   ],
   "source": [
    "dls = dls.cuda()\n",
    "def loss_func(out, targ):\n",
    "    return CrossEntropyLossFlat()(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = RocAucBinary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, AlexNet_3D(), opt_func = SGD, loss_func = loss_func, metrics = [error_rate, roc])\n",
    "learn = learn.to_fp16()\n",
    "#learn = learn.to_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(n_epoch = 1, lr_max = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,t = learn.tta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, target = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = F.softmax(preds, dim = 1)[:, 1].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's usually because your network is not complex enough to find a pattern between your input vectors and your output vectors, and therefore, your last output layer is converging towards the average vector of all the outputs in your dataset.\n",
    "\n",
    "To overcome this there are a few techniques:\n",
    "\n",
    "1. Try to do some more preprocessing to your inputs, perhaps a PCA on your attributes.\n",
    "2. Visualize your layers, try to add random vectors as your input and check the outputs of each layer. There must be just one layer which would be outputting almost the same vector everytime, causing problems for your higher level neurons.\n",
    "3. Reduce your learning rate.\n",
    "4. Reduce your batch size.\n",
    "5. Stack more layers.\n",
    "6. Check if your model is actually learning : send random noise as your data, and the network loss should not be decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "ns_fpr, ns_tpr, _ = roc_curve(target.numpy(), preds)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(n_epoch = 100, lr_max = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11520/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
