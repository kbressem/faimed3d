{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom datablocks for 3D images and fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp data\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import re\n",
    "import pathlib\n",
    "import torchvision\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ln -s ../faimed3d/ faimed3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Get data paths and labels\n",
    "\n",
    "Data is divided into a train, valid and test dataset of different patients, which either have prostate cancer or are healthy. \n",
    "Each patient has three MRI sequences: T2, T1map and ADC. These sequences differ in number of slices and resolution. \n",
    "\n",
    "At first the paths to the data are specified: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pathlib.Path('../../dl-prostate-mapping/data/train')\n",
    "valid = pathlib.Path('../../dl-prostate-mapping/data/valid')\n",
    "test = pathlib.Path('../../dl-prostate-mapping/data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, I am only interested into the DICOM data, not in the NIfTI segmentations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = list(train.rglob('DICOM'))\n",
    "valid_files = list(valid.rglob('DICOM'))\n",
    "test_files = list(test.rglob('DICOM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce complexity of the data, only the T2 map will be used for the first runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only T2 and T1 images for noe\n",
    "subset_train =[]\n",
    "for f in train_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_train.append(Path(m.string))\n",
    "        \n",
    "subset_valid =[]\n",
    "for f in valid_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_valid.append(Path(m.string))\n",
    "        \n",
    "subset_test = []\n",
    "for f in test_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_test.append(Path(m.string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the patient has prostate cancer or not, can be extracted from the file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Gesund', 'ProstataCa']\n",
    "def label_func(fn): return re.findall(r'(Gesund|ProstataCa)', str(fn))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ScaleDicom(DisplayedTransform):\n",
    "    \"Transforms a TensorDicom3D volume to float and normalizes the data\"\n",
    "    def __init__(self, div=None, div_mask=1): store_attr()\n",
    "    \n",
    "    def encodes(self, x:(TensorDicom3D, TensorMask3D)):\n",
    "        \n",
    "        if isinstance(x, TensorMask3D): return x\n",
    "        \n",
    "        if self.div is None: \n",
    "            return normalize(x.hist_scaled()).float()\n",
    "        else:\n",
    "            return (x.hist_scaled()/div).float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ImageBlock3D(cls=TensorDicom3D):\n",
    "    \"A `TransformBlock` for images of `cls`\"\n",
    "    return TransformBlock(type_tfms=cls.create, batch_tfms=ScaleDicom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders for image classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "              CategoryBlock),\n",
    "    get_x = lambda x: x,\n",
    "    get_y = label_func, \n",
    "    item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "    batch_tfms = [\n",
    "        *aug_transforms_3d(), \n",
    "        RandomCrop3D(((3, 2), (25,25), (25,25)), (0, 25, 25)), \n",
    "        PseudoColor],\n",
    "    splitter = RandomSplitter())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mris.summary(subset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mris.dataloaders(subset_train, \n",
    "                       batch_size = 16, \n",
    "                       num_workers = 0\n",
    "                      )\n",
    "dls.valid.bs = 16 # defaults to 64 and will cause Cuda out of Memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch_3d(dls, max_n=9, **kwargs):\n",
    "    \"Workarround, until implemented into dls as dls.show_batch_3d()\"\n",
    "    xb, yb = dls.one_batch()\n",
    "    xb.show(**kwargs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "show_batch_3d(dls, axis = 0, nrow = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ResizeCrop3D -- {'crop_by': (0.0, 0.1, 0.1), 'resize_to': (20, 150, 150), 'perc_crop': True, 'p': 1} -> ToTensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.after_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ScaleDicom -- {'div': None, 'div_mask': 1} -> RandomWarp3D -- {'p': 0.1} -> RandomDihedral3D -- {'p': 0.1} -> RandomBrightness3D -- {'p': 0.1} -> RandomContrast3D -- {'p': 0.1} -> RandomNoise3D -- {'p': 0.1} -> RandomRotate3DBy -- {'p': 0.1} -> RandomFlip3D -- {'p': 0.1} -> RandomRotate3D -- {'p': 0.1} -> RandomCrop3D -- {'p': 1} -> PseudoColor -- {'p': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.after_batch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from faimed3d.models import *\n",
    "def loss_func(out, targ):\n",
    "    return CrossEntropyLossFlat()(out, targ.long())\n",
    "\n",
    "learn = Learner(dls, \n",
    "                resnet_3d(n_input = 1, n_classes = dls.c),\n",
    "                opt_func = Adam, \n",
    "                loss_func = loss_func, \n",
    "                metrics = [error_rate, RocAucBinary()],\n",
    "                model_dir = '../models/'\n",
    "               )\n",
    "learn = learn.to_fp16()\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(20, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Segmentation Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_train = [(p.parent/'Annotation').ls()[0] for p in subset_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_train)  == len(segmentation_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class AddMaskCodes3D(AddMaskCodes):\n",
    "    \"Add the code metadata to a `TensorMask`\"\n",
    "\n",
    "    def decodes(self, o:TensorMask3D):\n",
    "        o = o.int()\n",
    "        if self.codes is not None: o._meta = {'codes': self.codes}\n",
    "        return o\n",
    "\n",
    "def MaskBlock3D(codes = None):\n",
    "    \"A `TransformBlock` for images of `cls`\"\n",
    "    return TransformBlock(type_tfms=TensorMask3D.create, item_tfms=AddMaskCodes3D(codes=codes),  batch_tfms=ScaleDicom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def clamp_to_range(x:TensorMask3D, lwr, upr):\n",
    "    return torch.clamp(x, lwr, upr)    \n",
    "\n",
    "class ClampMask3D(RandTransform):\n",
    "    def __init__(self, lwr=0,upr=1,p=1): \n",
    "        super().__init__(p=p)\n",
    "        self.lwr=lwr\n",
    "        self.upr=upr\n",
    "        \n",
    "    def encodes(self, x:TensorMask3D): \n",
    "        x = x.clamp_to_range(self.lwr, self.upr)\n",
    "        return x if x.device.type == 'cpu' else x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "              MaskBlock3D(codes = ['void', \"peripheral\", 'transitional', 'cancer'])),\n",
    "    get_x = lambda x: x[0],\n",
    "    get_y = lambda x: x[1], \n",
    "    item_tfms = ResizeCrop3D(crop_by = (0.1, 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "    batch_tfms = [\n",
    "        *aug_transforms_3d(p_all=0.25, do_rotate_by = False), \n",
    "        RandomCrop3D(((4, 4), (25,25), (25,25)), (1, 10, 10)), \n",
    "        ClampMask3D,\n",
    "        PseudoColor],\n",
    "    splitter = RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'image' : subset_train, \n",
    "                  'mask' : segmentation_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mris.dataloaders(d, \n",
    "                       batch_size = 8, \n",
    "                       num_workers = 0,\n",
    "                      )\n",
    "dls.valid.bs = 8 # defaults to 64 and will cause Cuda out of Memory errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The show_batch_3d function needs to be adapted to additionally show the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def show_batch_3d(dls, max_n=9, with_mask=False, alpha_mask=0.3, figsize = (15, 15), **kwargs):\n",
    "    \"Workarround, until implemented into dls as dls.show_batch_3d()\"\n",
    "    xb, yb = dls.one_batch()\n",
    "    xb.show(figsize=figsize)\n",
    "    if with_mask: yb.show(add_to_existing = True, alpha = alpha_mask, cmap = 'jet', figsize=figsize)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When displaying the masks it may occure, that Nifti images are rotated and do not fit the original DICOM. Most likely it is due to different frames of reference. \n",
    "in Simple-ITK it is LPS, while NIfTI and FSL use RAS, so those matrices are the same after accounting for frame of reference (taken and adapted from https://discourse.itk.org/t/nifti-orientation-issues/431).\n",
    "So, luckly the malrotations are systematic and can be scripted.\n",
    "\n",
    "```python\n",
    "    def convert(fn):\n",
    "\n",
    "        if 'Gesund' in fn: return # healthy patients were already flipped once\n",
    "        im = sitk.ReadImage(fn)\n",
    "        arr = sitk.GetArrayFromImage(im)\n",
    "        arr = np.rot90(arr, 0)\n",
    "        arr = np.flip(arr, 1)\n",
    "        im2 = sitk.GetImageFromArray(arr)\n",
    "\n",
    "        for k in im.GetMetaDataKeys(): # Copy meta data from original image before overwriting it. \n",
    "            im2.SetMetaData(k, im.GetMetaData(k))\n",
    "\n",
    "        sitk.WriteImage(im2, fn)\n",
    "        return im2\n",
    "    \n",
    "    \n",
    "    for s in segmentation_train: \n",
    "    convert(str(s))\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch_3d(dls, with_mask=True, nrow = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def loss_func(out, targ):\n",
    "    targ = torch.cat(((targ,) * out.shape[1]), 0)\n",
    "    return MSELossFlat()(out, targ.long())\n",
    "\n",
    "def loss_func(out, targ):\n",
    "    targ = torch.cat(((targ,) * out.shape[1]), 0)\n",
    "    \n",
    "    return MSELossFlat()(out[targ == 0], targ[targ == 0].long()) + MSELossFlat()(out[targ != 0], targ[targ != 0].long())**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDiceLoss():\n",
    "    \n",
    "    \"\"\"\n",
    "    Simple DICE loss as described in: \n",
    "        https://arxiv.org/pdf/1911.02855.pdf    \n",
    "    \n",
    "    Computes the Sørensen–Dice loss. Larger is better. \n",
    "    Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1. \n",
    "    \n",
    "    Args:\n",
    "        targ: a tensor of shape [B, 1, D, H, W].\n",
    "        pred: a tensor of shape [B, C, D, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability (acoid division by 0).\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, method = 'miletari', alpha = 0.5, beta = 0.5, eps = 1e-7, smooth = 1.) -> None:\n",
    "        self.method = method \n",
    "        self.alpha = alpha \n",
    "        self.beta = beta \n",
    "        self.eps = eps\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "            \n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "\n",
    "        if self.method == 'simple':\n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            denominator  = torch.sum(input + target, dims) + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "\n",
    "        elif self.method == 'miletari':  \n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            denominator  = torch.sum(input**2 + target**2, dims) + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "\n",
    "        elif self.method == 'tversky':\n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            fps = torch.sum(input * (1 - target), dims)\n",
    "            fns = torch.sum((1 - input) * target, dims)\n",
    "\n",
    "            denominator  = numerator + self.alpha*fps + self.beta*fns + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "            \n",
    "        else: \n",
    "            raise NotImplementedError('The specified type of DICE loss is not implemented')\n",
    "\n",
    "        return 1-dice_loss if dice_loss < 1 else 1+dice_loss\n",
    "    \n",
    "class BinaryMCCLoss(BinaryDiceLoss):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the MCC loss. Larger is better. \n",
    "    Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1. \n",
    "    inherits from BinaryDiceLoss\n",
    "    Args:\n",
    "        input: a tensor of shape [B, 1, D, H, W].\n",
    "        target: a tensor of shape [B, C, D, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "\n",
    "        tps = torch.sum(input * target, dims) + self.smooth  # geht nur wenn preds zwischen 0 und 1 sind, softmax am ende des unets sollte noch gemacht werden\n",
    "        fps = torch.sum(input * (1 - target), dims)\n",
    "        fns = torch.sum((1 - input) * target, dims)\n",
    "        tns = torch.sum((1 - input) * (1-target), dims)\n",
    "            \n",
    "        numerator = (tps * tns - fps * fns) + self.smooth\n",
    "        denominator =  ((tps + fps) * (tns + tns) * (fps + tns) * (tps + fns))**0.5 + self.smooth\n",
    "\n",
    "        mcc_loss = numerator / (denominator + self.eps)\n",
    "        \n",
    "        return 1-mcc_loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if:  \n",
    "fps = torch.sum(input * (1 - target), dims)  \n",
    "fns = torch.sum((1 - input) * target, dims)  \n",
    "\n",
    "then:  \n",
    "tps = torch.sum(input * target, dims) + self.smooth  \n",
    "tns = torch.sum((1-input) * (1-target), dims) + self.smooth  \n",
    "  \n",
    "This enables calculation of many different loss functions: \n",
    "F1 Loss ( = DICE)\n",
    "MCC Loss  \n",
    "Sensitivity Loss  \n",
    "Specificity Loss  \n",
    "J-Score Loss ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idee: Leaky Loss bei noisy data\n",
    "\n",
    "loggen des Losses in der Klasse, wie hoch der durchschnittliche Loss pro Klasse war. \n",
    "Nach einer bestimmten Anzahl an batches, kann dann, wenn sich der Loss auf einer Klasse um mehr als eine SD vom Durchschnittlichen Loss unterscheided,(also viel zu hoch ist) ein Loss ausfallen. D.h. statt des hohen losses wird ein weniger hoher loss ausgegeben. Dies ist unter der Annahme, dass der hohe Loss durch ein falsch gelabeltes Bild erzeugt wird, welches aber richtig vom Algorithmus erkannt wurde. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faimed3d.models import *\n",
    "\n",
    "mcc_loss = BinaryMCCLoss()\n",
    "\n",
    "learn = Learner(dls, \n",
    "                UNet3D(n_channels = 1, n_classes = 1),\n",
    "                opt_func = SGD, \n",
    "                loss_func = mcc_loss, \n",
    "                model_dir = '../models/'\n",
    "               )\n",
    "learn = learn.to_fp16()\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      36.00% [9/25 04:20<07:43]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.016138</td>\n",
       "      <td>0.995479</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.014675</td>\n",
       "      <td>0.985637</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.011316</td>\n",
       "      <td>0.969096</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.005241</td>\n",
       "      <td>0.951802</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.996478</td>\n",
       "      <td>0.912450</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.982811</td>\n",
       "      <td>0.881336</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.958051</td>\n",
       "      <td>0.832077</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.935681</td>\n",
       "      <td>0.764029</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.912388</td>\n",
       "      <td>0.742929</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(100, 0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x-x.min())/x.max()\n",
    "x1 = TensorDicom3D(x[0:5, :,:,:,:].round())\n",
    "x2 = TensorDicom3D(x[0:5, :,:,:,:])\n",
    "\n",
    "y = TensorDicom3D(torch.clamp(y[0:5, :,:,:,:], 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x2.flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorDicom3D((x2).float()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.show(cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
