{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom datablocks for 3D images and fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp data\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import re\n",
    "import pathlib\n",
    "import torchvision\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ln -s ../faimed3d/ faimed3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Get data paths and labels\n",
    "\n",
    "Data is divided into a train, valid and test dataset of different patients, which either have prostate cancer or are healthy. \n",
    "Each patient has three MRI sequences: T2, T1map and ADC. These sequences differ in number of slices and resolution. \n",
    "\n",
    "At first the paths to the data are specified: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pathlib.Path('../../dl-prostate-mapping/data/train')\n",
    "valid = pathlib.Path('../../dl-prostate-mapping/data/valid')\n",
    "test = pathlib.Path('../../dl-prostate-mapping/data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, I am only interested into the DICOM data, not in the NIfTI segmentations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = list(train.rglob('DICOM'))\n",
    "valid_files = list(valid.rglob('DICOM'))\n",
    "test_files = list(test.rglob('DICOM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce complexity of the data, only the T2 map will be used for the first runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only T2 and T1 images for noe\n",
    "subset_train =[]\n",
    "for f in train_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_train.append(Path(m.string))\n",
    "        \n",
    "subset_valid =[]\n",
    "for f in valid_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_valid.append(Path(m.string))\n",
    "        \n",
    "subset_test = []\n",
    "for f in test_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_test.append(Path(m.string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the patient has prostate cancer or not, can be extracted from the file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Gesund', 'ProstataCa']\n",
    "def label_func(fn): return re.findall(r'(Gesund|ProstataCa)', str(fn))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ScaleDicom(DisplayedTransform):\n",
    "    \"Transforms a TensorDicom3D volume to float and normalizes the data\"\n",
    "    def __init__(self, div=None, div_mask=1): store_attr()\n",
    "    \n",
    "    def encodes(self, x:(TensorDicom3D, TensorMask3D)):\n",
    "        \n",
    "        if isinstance(x, TensorMask3D): return x\n",
    "        \n",
    "        if self.div is None: \n",
    "            return normalize(x.hist_scaled()).float()\n",
    "        else:\n",
    "            return (x.hist_scaled()/div).float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ImageBlock3D(cls=TensorDicom3D):\n",
    "    \"A `TransformBlock` for images of `cls`\"\n",
    "    return TransformBlock(type_tfms=cls.create, batch_tfms=ScaleDicom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders for image classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "              CategoryBlock),\n",
    "    get_x = lambda x: x,\n",
    "    get_y = label_func, \n",
    "    item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "    batch_tfms = [\n",
    "        *aug_transforms_3d(), \n",
    "        RandomCrop3D(((3, 2), (25,25), (25,25)), (0, 25, 25)), \n",
    "        PseudoColor],\n",
    "    splitter = RandomSplitter())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mris.summary(subset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mris.dataloaders(subset_train+subset_valid, \n",
    "                       batch_size = 16, \n",
    "                       num_workers = 0\n",
    "                      )\n",
    "dls.valid.bs = 16 # defaults to 64 and will cause Cuda out of Memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch_3d(dls, max_n=9, **kwargs):\n",
    "    \"Workarround, until implemented into dls as dls.show_batch_3d()\"\n",
    "    xb, yb = dls.one_batch()\n",
    "    xb.show(**kwargs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "show_batch_3d(dls, axis = 0, nrow = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ResizeCrop3D -- {'crop_by': (0.0, 0.1, 0.1), 'resize_to': (20, 150, 150), 'perc_crop': True, 'p': 1} -> ToTensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.after_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: ScaleDicom -- {'div': None, 'div_mask': 1} -> RandomWarp3D -- {'p': 0.1} -> RandomDihedral3D -- {'p': 0.1} -> RandomBrightness3D -- {'p': 0.1} -> RandomContrast3D -- {'p': 0.1} -> RandomNoise3D -- {'p': 0.1} -> RandomRotate3DBy -- {'p': 0.1} -> RandomFlip3D -- {'p': 0.1} -> RandomRotate3D -- {'p': 0.1} -> RandomCrop3D -- {'p': 1} -> PseudoColor -- {'p': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faimed3d.models import *\n",
    "def loss_func(out, targ):\n",
    "    return CrossEntropyLossFlat()(out, targ.long())\n",
    "\n",
    "learn = Learner(dls, \n",
    "                resnet_3d(n_input = 1, n_classes = dls.c),\n",
    "                opt_func = SGD, \n",
    "                loss_func = loss_func, \n",
    "                metrics = [error_rate, RocAucBinary()],\n",
    "                model_dir = '../models/'\n",
    "               )\n",
    "learn = learn.to_fp16()\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(20, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Segmentation Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_train = [(p.parent/'Annotation').ls()[0] for p in subset_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_train)  == len(segmentation_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class AddMaskCodes3D(AddMaskCodes):\n",
    "    \"Add the code metadata to a `TensorMask`\"\n",
    "\n",
    "    def decodes(self, o:TensorMask3D):\n",
    "        o = o.int()\n",
    "        if self.codes is not None: o._meta = {'codes': self.codes}\n",
    "        return o\n",
    "\n",
    "def MaskBlock3D(codes = None):\n",
    "    \"A `TransformBlock` for images of `cls`\"\n",
    "    return TransformBlock(type_tfms=TensorMask3D.create, item_tfms=AddMaskCodes3D(codes=codes),  batch_tfms=ScaleDicom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def clamp_to_range(x:TensorMask3D, lwr, upr):\n",
    "    return torch.clamp(x, lwr, upr)    \n",
    "\n",
    "class ClampMask3D(RandTransform):\n",
    "    def __init__(self, lwr=0,upr=1,p=1): \n",
    "        super().__init__(p=p)\n",
    "        self.lwr=lwr\n",
    "        self.upr=upr\n",
    "        \n",
    "    def encodes(self, x:TensorMask3D): \n",
    "        x = x.clamp_to_range(self.lwr, self.upr)\n",
    "        return x if x.device.type == 'cpu' else x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "              MaskBlock3D(codes = ['void', \"peripheral\", 'transitional', 'cancer'])),\n",
    "    get_x = lambda x: x[0],\n",
    "    get_y = lambda x: x[1], \n",
    "    item_tfms = ResizeCrop3D(crop_by = (0.1, 0.15, 0.15), resize_to = (20, 150, 150), perc_crop = True),\n",
    "    batch_tfms = [\n",
    "        *aug_transforms_3d(p_all=0.25, do_rotate_by = False), \n",
    "        RandomCrop3D(((1, 1), (25,25), (25,25)), (1, 10, 10)), \n",
    "        ClampMask3D,\n",
    "        PseudoColor],\n",
    "    splitter = RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'image' : subset_train, \n",
    "                  'mask' : segmentation_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mris.dataloaders(d, \n",
    "                       batch_size = 8, \n",
    "                       num_workers = 0,\n",
    "                      )\n",
    "dls.valid.bs = 8 # defaults to 64 and will cause Cuda out of Memory errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The show_batch_3d function needs to be adapted to additionally show the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def show_batch_3d(dls, max_n=9, with_mask=False, alpha_mask=0.3, figsize = (15, 15), **kwargs):\n",
    "    \"Workarround, until implemented into dls as dls.show_batch_3d()\"\n",
    "    xb, yb = dls.one_batch()\n",
    "    xb.show(figsize=figsize)\n",
    "    if with_mask: yb.show(add_to_existing = True, alpha = alpha_mask, cmap = 'jet', figsize=figsize)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When displaying the masks it may occure, that Nifti images are rotated and do not fit the original DICOM. Most likely it is due to different frames of reference. \n",
    "in Simple-ITK it is LPS, while NIfTI and FSL use RAS, so those matrices are the same after accounting for frame of reference (taken and adapted from https://discourse.itk.org/t/nifti-orientation-issues/431).\n",
    "So, luckly the malrotations are systematic and can be scripted.\n",
    "\n",
    "```python\n",
    "    def convert(fn):\n",
    "\n",
    "        if 'Gesund' in fn: return # healthy patients were already flipped once\n",
    "        im = sitk.ReadImage(fn)\n",
    "        arr = sitk.GetArrayFromImage(im)\n",
    "        arr = np.rot90(arr, 0)\n",
    "        arr = np.flip(arr, 1)\n",
    "        im2 = sitk.GetImageFromArray(arr)\n",
    "\n",
    "        for k in im.GetMetaDataKeys(): # Copy meta data from original image before overwriting it. \n",
    "            im2.SetMetaData(k, im.GetMetaData(k))\n",
    "\n",
    "        sitk.WriteImage(im2, fn)\n",
    "        return im2\n",
    "    \n",
    "    \n",
    "    for s in segmentation_train: \n",
    "    convert(str(s))\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch_3d(dls, with_mask=True, nrow = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if:  \n",
    "fps = torch.sum(input * (1 - target), dims)  \n",
    "fns = torch.sum((1 - input) * target, dims)  \n",
    "\n",
    "then:  \n",
    "tps = torch.sum(input * target, dims) + self.smooth  \n",
    "tns = torch.sum((1-input) * (1-target), dims) + self.smooth  \n",
    "  \n",
    "This enables calculation of many different loss functions: \n",
    "F1 Loss ( = DICE)\n",
    "MCC Loss  \n",
    "Sensitivity Loss  \n",
    "Specificity Loss  \n",
    "J-Score Loss ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idee: Leaky Loss bei noisy data\n",
    "\n",
    "loggen des Losses in der Klasse, wie hoch der durchschnittliche Loss pro Klasse war. \n",
    "Nach einer bestimmten Anzahl an batches, kann dann, wenn sich der Loss auf einer Klasse um mehr als eine SD vom Durchschnittlichen Loss unterscheided,(also viel zu hoch ist) ein Loss ausfallen. D.h. statt des hohen losses wird ein weniger hoher loss ausgegeben. Dies ist unter der Annahme, dass der hohe Loss durch ein falsch gelabeltes Bild erzeugt wird, welches aber richtig vom Algorithmus erkannt wurde. \n",
    "\n",
    "\n",
    "Kann leaky loss auch zum Lernen auf ungelabelten Daten genutzt werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faimed3d.models import *\n",
    "\n",
    "mcc_loss = BinaryMCCLoss()\n",
    "\n",
    "learn = Learner(dls, \n",
    "                UNet3D(n_channels = 1, n_classes = 1),\n",
    "                opt_func = SGD, \n",
    "                loss_func = mcc_loss, \n",
    "                model_dir = '../models/'\n",
    "               )\n",
    "learn = learn.to_fp16()\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
