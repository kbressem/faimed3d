{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp learner\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.preprocess import *\n",
    "from faimed3d.layers import *\n",
    "from faimed3d.data import *\n",
    "from faimed3d.models.unet import DynamicUnet3D\n",
    "from faimed3d.models.deeplab import DynamicDeepLab\n",
    "from faimed3d.models.losses import DiceLoss\n",
    "from fastai.vision.learner import _default_meta, _add_norm, model_meta, create_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('../data/radiopaedia_cases.csv')\n",
    "dls = ImageDataLoaders3D.from_df(d,\n",
    "                                 fn_col = 0,\n",
    "                                 label_col = 2, # in sample data 0: series, 1: segmentation mask, 2: random binary label\n",
    "                                 #item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "                                 size_for_resampling = (112, 112, 20),\n",
    "                                 bs = 2, \n",
    "                                 val_bs = 2,\n",
    "                                 num_workers = 0,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN learner\n",
    "The fastai cnn_learner class can be used to construct a 3D CNN with only a few modifications to the original functions. See the `faimed3d.layers` notebook for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "def cnn_learner_3d(dls, arch, loss_func=None, pretrained=True, cut=None, splitter=None,\n",
    "                y_range=None, config=None, n_out=None, normalize=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Build a convnet style learner from `dls` and `arch`\n",
    "    Same as fastai func but adds the `AddColorChannel` callback.\n",
    "    \"\"\"\n",
    "    if config is None: config = {}\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    # if normalize: _add_norm(dls, meta, pretrained) # no effect as no TenosrImage is passed in 3d\n",
    "    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n",
    "\n",
    "    model = create_cnn_model_3d(arch, n_out, ifnone(cut, meta['cut']), pretrained, y_range=y_range, **config)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, splitter=ifnone(splitter, meta['split']), **kwargs)\n",
    "    if pretrained: learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.video import r3d_18\n",
    "learn = cnn_learner_3d(dls, r3d_18, pretrained=False) # pretrained turned off for more speed while testing, default would be to load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.950297</td>\n",
       "      <td>1.161256</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.886324</td>\n",
       "      <td>2.045711</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fine_tune(1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(DynamicUnet3D.__init__)\n",
    "def create_unet_model_3d(arch, n_out, img_size, n_inp=1, pretrained=True, cut=None, n_in=3, **kwargs):\n",
    "    \"Create custom unet architecture\"\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    body = create_body(arch, n_in, pretrained, ifnone(cut, meta['cut']))\n",
    "    model = DynamicUnet3D(body, n_out, img_size, n_inp, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def unet_learner_3d(dls, arch, normalize=True, n_out=None, pretrained=True, config=None,\n",
    "                 # learner args\n",
    "                 loss_func=None, opt_func=Adam, lr=defaults.lr, splitter=None, cbs=None, metrics=None, path=None,\n",
    "                 model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,0.85,0.95),\n",
    "                 # other model args\n",
    "                 norm_type=NormType.Batch, **kwargs):\n",
    "    \"Build a unet learner from `dls` and `arch`\"\n",
    "\n",
    "    if config:\n",
    "        warnings.warn('config param is deprecated. Pass your args directly to unet_learner.')\n",
    "        kwargs = {**config, **kwargs}\n",
    "\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    # if normalize: _add_norm(dls, meta, pretrained) # no effect as no TenosrImage is passed in 3d\n",
    "\n",
    "    n_out = ifnone(n_out, get_c(dls))\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    img_size = dls.one_batch()[0].shape[-3:]\n",
    "    assert img_size, \"image size could not be inferred from data\"\n",
    "    model = create_unet_model_3d(arch, n_out, img_size,  pretrained=pretrained, norm_type=norm_type, **kwargs)\n",
    "\n",
    "    if loss_func is None: loss_func = DiceLoss(smooth=0.)\n",
    "    splitter=ifnone(splitter, meta['split'])\n",
    "    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
    "                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
    "                   moms=moms)\n",
    "    if pretrained: learn.freeze()\n",
    "    # keep track of args for loggers\n",
    "    store_attr('arch,normalize,n_out,pretrained', self=learn)\n",
    "    if kwargs: store_attr(self=learn, **kwargs)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = SegmentationDataLoaders3D.from_df(d,  \n",
    "                                codes = ['no covid', 'covid'],\n",
    "                                 item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 100, 100), perc_crop = True), \n",
    "                                 bs = 2, val_bs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner_3d(dls, r3d_18, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.581073</td>\n",
       "      <td>0.642846</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLab learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(DynamicDeepLab.__init__)\n",
    "def create_deeplab_model_3d(arch, n_out, img_size, n_inp=1, pretrained=True, cut=None, n_in=3, **kwargs):\n",
    "    \"Create custom unet architecture\"\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    body = create_body(arch, n_in, pretrained, ifnone(cut, meta['cut']))\n",
    "    model = DynamicDeepLab(body, n_out, img_size, n_inp, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def deeplab_learner_3d(dls, arch, normalize=True, n_out=None, pretrained=True, \n",
    "                 # learner args\n",
    "                 loss_func=None, opt_func=Adam, lr=defaults.lr, splitter=None, cbs=None, metrics=None, path=None,\n",
    "                 model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,0.85,0.95),\n",
    "                 # other model args\n",
    "                 norm_type=NormType.Batch, **kwargs):\n",
    "    \"Build a deeplab learner from `dls` and `arch`\"\n",
    "\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    # if normalize: _add_norm(dls, meta, pretrained) # no effect as no TenosrImage is passed in 3d\n",
    "\n",
    "    n_out = ifnone(n_out, get_c(dls))\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    img_size = dls.one_batch()[0].shape[-3:]\n",
    "    assert img_size, \"image size could not be inferred from data\"\n",
    "    model = create_deeplab_model_3d(arch, n_out, img_size, pretrained=pretrained, norm_type=norm_type, **kwargs)\n",
    "\n",
    "    if loss_func is None: loss_func = DiceLoss(smooth=0.)\n",
    "    splitter=ifnone(splitter, meta['split'])\n",
    "    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
    "                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
    "                   moms=moms)\n",
    "    if pretrained: learn.freeze()\n",
    "    # keep track of args for loggers\n",
    "    store_attr('arch,normalize,n_out,pretrained', self=learn)\n",
    "    if kwargs: store_attr(self=learn, **kwargs)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = SegmentationDataLoaders3D.from_df(d,  \n",
    "                                codes = ['no covid', 'covid'],\n",
    "                                 item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 100, 100), perc_crop = True), \n",
    "                                 bs = 2, val_bs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = deeplab_learner_3d(dls, r3d_18, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.593307</td>\n",
       "      <td>0.589266</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_basics.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_transforms.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_layers.ipynb.\n",
      "Converted 06_learner.ipynb.\n",
      "Converted 06a_models.alexnet.ipynb.\n",
      "Converted 06b_models.resnet.ipynb.\n",
      "Converted 06c_model.efficientnet.ipynb.\n",
      "Converted 06d_models.unet.ipynb.\n",
      "Converted 06e_models.deeplabv3.ipynb.\n",
      "Converted 06f_models.losses.ipynb.\n",
      "Converted 07_callback.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
