{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# faimed3d wrapper for Learner class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp learner\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.preprocess import *\n",
    "from faimed3d.layers import *\n",
    "from faimed3d.data import *\n",
    "from faimed3d.models.unet import DynamicUnet3D\n",
    "from faimed3d.models.losses import DiceLoss\n",
    "from fastai.vision.learner import _default_meta, _add_norm, model_meta, create_body, create_unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rescale method was used. This is not advisable due to high risk of exploding gradients. Falling back to mean scaling.\n"
     ]
    }
   ],
   "source": [
    "d =  pd.read_csv('../../mri-spa/data/train_knee.csv')\n",
    "dls = ImageDataLoaders3D.from_df(d, path='/media/..', \n",
    "                                 item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "                                 bs = 2, \n",
    "                                 val_bs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN learner\n",
    "The fastai cnn_learner class can be used to construct a 3D CNN with only a few modifactions to the original functions. See the `faimed3d.layers` notebook for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "def cnn_learner_3d(dls, arch, loss_func=None, pretrained=True, cut=None, splitter=None,\n",
    "                y_range=None, config=None, n_out=None, normalize=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Build a convnet style learner from `dls` and `arch`\n",
    "    Same as fastai func but adds the `AddColorChannel` callback.\n",
    "    \"\"\"\n",
    "    if config is None: config = {}\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    # if normalize: _add_norm(dls, meta, pretrained) # no effect as no TenosrImage is passed in 3d\n",
    "    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n",
    "    model = create_cnn_model(arch, n_out, ifnone(cut, meta['cut']), pretrained, y_range=y_range, **config)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, splitter=ifnone(splitter, meta['split']), **kwargs)\n",
    "    if pretrained: learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.video import r3d_18\n",
    "learn = cnn_learner_3d(dls, r3d_18, model_dir='/home/bressekk/Documents/faimed3d/nbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='142' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      28.40% [142/500 00:15<00:39 1.4095]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fine_tune(1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(DynamicUnet3D.__init__)\n",
    "def create_unet_model_3d(arch, n_out, img_size, pretrained=True, cut=None, n_in=3, **kwargs):\n",
    "    \"Create custom unet architecture\"\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    body = create_body(arch, n_in, pretrained, ifnone(cut, meta['cut']))\n",
    "    model = DynamicUnet3D(body, n_out, img_size, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(create_unet_model)\n",
    "def unet_learner_3d(dls, arch, normalize=True, n_out=None, pretrained=True, config=None,\n",
    "                 # learner args\n",
    "                 loss_func=None, opt_func=Adam, lr=defaults.lr, splitter=None, cbs=None, metrics=None, path=None,\n",
    "                 model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,0.85,0.95),\n",
    "                 # other model args\n",
    "                 **kwargs):\n",
    "    \"Build a unet learner from `dls` and `arch`\"\n",
    "\n",
    "    if config:\n",
    "        warnings.warn('config param is deprecated. Pass your args directly to unet_learner.')\n",
    "        kwargs = {**config, **kwargs}\n",
    "\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    # if normalize: _add_norm(dls, meta, pretrained) # no effect as no TenosrImage is passed in 3d\n",
    "\n",
    "    n_out = ifnone(n_out, get_c(dls))\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    img_size = dls.one_batch()[0].shape[-3:]\n",
    "    assert img_size, \"image size could not be inferred from data\"\n",
    "    model = create_unet_model_3d(arch, n_out, img_size, pretrained=pretrained, **kwargs)\n",
    "    \n",
    "    if loss_func is None: loss_func = DiceLoss(smooth=0.)\n",
    "    splitter=ifnone(splitter, meta['split'])\n",
    "    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
    "                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
    "                   moms=moms)\n",
    "    if pretrained: learn.freeze()\n",
    "    # keep track of args for loggers\n",
    "    store_attr('arch,normalize,n_out,pretrained', self=learn)\n",
    "    if kwargs: store_attr(self=learn, **kwargs)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate = pd.read_csv('../../dl-prostate-mapping/data/prostata-train.csv', sep = ',')[['t2_cropped_dcm', 't2_mask_cropped']]\n",
    "dls = SegmentationDataLoaders3D.from_df(prostate, path='/media/..', \n",
    "                                codes = ['void', 'transitional', 'peripheral', 'cancer'],\n",
    "                                 item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 100, 100), perc_crop = True), \n",
    "                                 bs = 2, val_bs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner_3d(dls, r3d_18, model_dir='/home/bressekk/Documents/faimed3d/nbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_basics.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_transforms.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_layers.ipynb.\n",
      "Converted 06_learner.ipynb.\n",
      "Converted 06a_models.alexnet.ipynb.\n",
      "Converted 06b_models.resnet.ipynb.\n",
      "Converted 06c_models.densenet.ipynb.\n",
      "Converted 06d_models.unet.ipynb.\n",
      "Converted 06e_models.deeplabv3.ipynb.\n",
      "Converted 06f_models.losses.ipynb.\n",
      "Converted 07_callback.ipynb.\n",
      "Converted 98_widgets.ipynb.\n",
      "Converted 99_tools.ipynb.\n",
      "Converted 99_widgets.cam.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted tutorial_mri-normalization.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
