{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# faimed3d Dataloaders for 3D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp learner\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.preprocess import *\n",
    "from faimed3d.data import *\n",
    "from fastai.vision.learner import _default_meta, _add_norm, model_meta, create_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faimed3d.models.resnet import *\n",
    "from faimed3d.augment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning tmpdir.\n",
      "removing 112 files from /tmp/faimed3d_metadata/\n",
      "You can disable automatic cleanup of the tmpdir (e.g. when doing multiple sessions in parallel) with setting clean_tmpdir=False\n",
      "No rescale method was used. This is not advisable due to high risk of exploding gradients. Falling back to mean scaling.\n"
     ]
    }
   ],
   "source": [
    "d =  pd.read_csv('../../mri-spa/data/train_knee.csv')\n",
    "dls = ImageDataLoaders3D.from_df(d, path='/media/..', \n",
    "                                 item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (20, 150, 150), perc_crop = True),\n",
    "                                 bs = 16, \n",
    "                                 val_bs = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def in_channels(m):\n",
    "    \"Return the shape of the first weight layer in `m`.\"\n",
    "    for l in flatten_model(m):\n",
    "        if getattr(l, 'weight', None) is not None and l.weight.ndim in [4,5]:\n",
    "            return l.weight.shape[1]\n",
    "    raise Exception('No weight layer')\n",
    "    \n",
    "def num_features_model(m):\n",
    "    \"Return the number of output features for `m`.\"\n",
    "    sz,ch_in = 32,in_channels(m)\n",
    "    while True:\n",
    "        #Trying for a few sizes in case the model requires a big input size.\n",
    "        try:\n",
    "            return model_sizes(m, (sz,sz,sz))[-1][1]\n",
    "        except Exception as e:\n",
    "            sz *= 2\n",
    "            print(sz)\n",
    "            if sz > 2048: raise e\n",
    "                \n",
    "def create_cnn_model(arch, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n",
    "                     concat_pool=True, **kwargs):\n",
    "    \"Create custom convnet architecture using `arch`, `n_in` and `n_out`\"\n",
    "    body = create_body(arch, n_in, pretrained, cut)\n",
    "    if custom_head is None:\n",
    "        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n",
    "        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n",
    "    else: head = custom_head\n",
    "    model = nn.Sequential(body, head)\n",
    "    if init is not None: apply_init(model[1], init)\n",
    "    return model\n",
    "\n",
    "def model_sizes(m, size=(64,64)):\n",
    "    \"Pass a dummy input through the model `m` to get the various sizes of activations.\"\n",
    "    with hook_outputs(m) as hooks:\n",
    "        _ = dummy_eval(m, size=size)\n",
    "        return [o.stored.shape for o in hooks]\n",
    "\n",
    "def dummy_eval(m, size=(64,64)):\n",
    "    \"Evaluate `m` on a dummy input of a certain `size`\"\n",
    "    ch_in = in_channels(m)\n",
    "    x = one_param(m).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.)\n",
    "    with torch.no_grad(): return m.eval()(x)\n",
    "    \n",
    "def create_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and out `n_out` classes.\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    pool = AdaptiveConcatPool3d() if concat_pool else nn.AdaptiveAvgPool3d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=True, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class AdaptiveConcatPool3d(Module):\n",
    "    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`\"\n",
    "    def __init__(self, size=None):\n",
    "        self.size = size or 1\n",
    "        self.ap = nn.AdaptiveAvgPool3d(self.size)\n",
    "        self.mp = nn.AdaptiveMaxPool3d(self.size)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "@delegates(Learner.__init__)\n",
    "def cnn_learner_3d(dls, arch, loss_func=None, pretrained=True, cut=None, splitter=None,\n",
    "                y_range=None, config=None, n_out=None, normalize=True, **kwargs):\n",
    "    \"Build a convnet style learner from `dls` and `arch`\"\n",
    "    if config is None: config = {}\n",
    "    meta = model_meta.get(arch, _default_meta)\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    if normalize: _add_norm(dls, meta, pretrained)\n",
    "    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n",
    "    model = create_cnn_model(arch, n_out, ifnone(cut, meta['cut']), pretrained, y_range=y_range, **config)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, splitter=ifnone(splitter, meta['split']), **kwargs)\n",
    "    learn = learn.add_cb(AddColorChannel())\n",
    "    if pretrained: learn.freeze()\n",
    "    return learn\n",
    "\n",
    "class AddColorChannel(Callback):\n",
    "    def __init__(self, dim=1):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "    def before_batch(self):\n",
    "        self.learn.xb = (torch.stack(self.learn.xb*3, self.dim), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner_3d(dls, resnet18_3d, model_dir='/home/bressekk/Documents/faimed3d/nbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.033566</td>\n",
       "      <td>0.901484</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.739561</td>\n",
       "      <td>0.647040</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_basics.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_transforms.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_learner.ipynb.\n",
      "Converted 06a_models.alexnet.ipynb.\n",
      "Converted 06b_models.resnet.ipynb.\n",
      "Converted 06c_models.densenet.ipynb.\n",
      "Converted 06d_models.DynamicUnet.ipynb.\n",
      "Converted 06d_models.unet.ipynb.\n",
      "Converted 06e_models.deeplabv3.ipynb.\n",
      "Converted 06f_models.losses.ipynb.\n",
      "Converted 07_callback.ipynb.\n",
      "Converted 99_tools.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
