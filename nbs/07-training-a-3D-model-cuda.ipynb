{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.models import *\n",
    "from faimed3d.data import *\n",
    "\n",
    "import pathlib\n",
    "import re\n",
    "from fastai.basics import *\n",
    "from fastai.vision.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pathlib.Path('../../dl-prostate-mapping/data/train')\n",
    "valid = pathlib.Path('../../dl-prostate-mapping/data/valid')\n",
    "test = pathlib.Path('../../dl-prostate-mapping/data/test')\n",
    "\n",
    "train_files = list(train.rglob('DICOM')) + list(train.rglob('T2W'))\n",
    "valid_files = list(valid.rglob('DICOM'))\n",
    "test_files = list(test.rglob('DICOM'))\n",
    "\n",
    "# take only T2 and T1 images for noe\n",
    "subset_train =[]\n",
    "for f in train_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_train.append(Path(m.string))\n",
    "        \n",
    "subset_valid =[]\n",
    "for f in valid_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_valid.append(Path(m.string))\n",
    "        \n",
    "subset_test = []\n",
    "for f in test_files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_test.append(Path(m.string))\n",
    "        \n",
    "        \n",
    "def label_func(fn):\n",
    "    return re.findall(r'(Gesund|ProstataCa)', str(fn))[0]\n",
    "labels = ['Gesund', 'ProstataCa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_train = subset_train +  subset_valid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Gesund', 'ProstataCa']\n",
    "def label_func(fn): return re.findall(r'(Gesund|ProstataCa)', str(fn))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mris = DataBlock(\n",
    "            blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "                      CategoryBlock),\n",
    "            get_x = lambda x: x,\n",
    "            get_y = label_func, \n",
    "            item_tfms = ResizeCrop3D(crop_by = (0., 0.15, 0.15), resize_to = (20, 200, 200), perc_crop = True),\n",
    "            batch_tfms = [*aug_transforms_3d(p_all =0.15), RandomCrop3D((0, 25, 25), (0, 10, 10)), PseudoColor],\n",
    "            splitter = RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mris.dataloaders(source = oversampled_train, \n",
    "                      num_workers = 0, \n",
    "                      batch_size = 8)\n",
    "dls.valid.bs = 8 # fastai takes a larger bs for valid dset, however for 3D this is to large"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(20, 128, kernel_size=11, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.AvgPool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.softmax =  nn.LogSoftmax(dim=1)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "        out = self.layer1(x)\n",
    "   #     print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "   #     print(out.shape)\n",
    "        out = self.AvgPool(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.flatten(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.fc1(out)\n",
    " #       print(out.shape)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class AlexNet_3D(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2, n_slices=7):\n",
    "        super(AlexNet_3D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(n_slices, 128, kernel_size=11, stride=2, padding=1),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "\n",
    "            nn.Conv3d(128, 256, kernel_size=5, padding=2)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.8),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "            \n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.Conv3d(256, 128, kernel_size=(5,5,3), padding=(2,2,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.8),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "            \n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.Conv3d(128, 384, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "           \n",
    "            nn.BatchNorm3d(384),\n",
    "            nn.Conv3d(384, 256, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.Conv3d(256, 256, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(3,3,1), stride=(2,2,1)),\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(5120, 2048), \n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.LeakyReLU(inplace = True), #    nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0),x.size(1)*x.size(2)*x.size(3)*x.size(4) ) #6 * 6 * 4)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class AlexNet_(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet_, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(20, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(   \n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer5 = nn.Sequential(    \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        self.softmax =  nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "   #     print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.layer3(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.layer4(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.layer5(x)\n",
    "   #     print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "   #     print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "   #     print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_(nn.Sequential):\n",
    "    \"Somehow, in 3D CNNs, the input is not transfered to cuda. I believe something in the transforms is wrong. Until this is fixed, subcalssing nn.Sequential is the workarround\"\n",
    "    def forward(self, input):\n",
    "        for module in self:\n",
    "            input = module(input.cuda())\n",
    "        return input\n",
    "\n",
    "def block(ni, nf, **kwargs): \n",
    "    return Sequential_(\n",
    "        ResBlock(1, ni, nf, stride = (2,2,1), ndim = 3, **kwargs), \n",
    "        ResBlock(1, nf, nf, ndim = 3))\n",
    "\n",
    "#def block(ni, nf, **kwargs): return ConvLayer(ni, nf, ndim = 3, **kwargs)\n",
    "\n",
    "def get_model():\n",
    "    return Sequential_(\n",
    "        block(20, 128, ks = 7),\n",
    "        block(128, 256, ks = 5),\n",
    "        block(256, 512),\n",
    "        block(512, 768),\n",
    "        nn.AdaptiveAvgPool3d(1),\n",
    "        Flatten(),\n",
    "        nn.Linear(768, dls.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(out, targ):\n",
    "    return CrossEntropyLossFlat()(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = RocAucBinary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.hook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, get_model(), opt_func = SGD, loss_func = loss_func, metrics=[error_rate, auc], cbs=ActivationStats(with_hist=True))\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(n_epoch = 100, lr_max = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_sched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.plot_layer_stats(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.activation_stats.color_dim(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
