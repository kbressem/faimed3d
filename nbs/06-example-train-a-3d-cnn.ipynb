{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom datablocks for 3D images and fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import re\n",
    "import pathlib\n",
    "import torchvision\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.data import *\n",
    "from faimed3d.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "Same approach as in Notebook 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pathlib.Path('../../dl-prostate-mapping/data/train')\n",
    "valid = pathlib.Path('../../dl-prostate-mapping/data/valid')\n",
    "\n",
    "train_files = list(train.rglob('DICOM'))\n",
    "valid_files = list(valid.rglob('DICOM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce complexity of the data, only the T2 map will be used for the first runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(valid_files)\n",
    "# files need to be shuffeld, because otherwise the scores will not work on the valid ds, since with a bs of 10, the first valid batch will only be positive cases and the second only negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = train_files + valid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only T2 images for now\n",
    "subset_files =[]\n",
    "for f in files: \n",
    "    m = re.search(r'T2', str(f)) \n",
    "    if hasattr(m, 'string'): subset_files.append(Path(m.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled = subset_files[0:34] + subset_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the patient has prostate cancer or not, can be extracted from the file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Gesund', 'ProstataCa']\n",
    "def label_func(fn): return re.findall(r'(Gesund|ProstataCa)', str(fn))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreatGreatGrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the great great grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o):\n",
    "        return _great_great_grandparent_idxs(o, train_name),_great_great_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _great_great_grandparent_idxs(items, name):\n",
    "    def _inner(items, name): return mask2idxs(Path(o).parent.parent.parent.parent.name == name for o in items)\n",
    "    return [i for n in L(name) for i in _inner(items,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "              CategoryBlock),\n",
    "    get_x = lambda x: x,\n",
    "    get_y = label_func, \n",
    "    item_tfms = ResizeCrop3D(crop_by = (0., 0.1, 0.1), resize_to = (14, 145, 145), perc_crop = True),\n",
    "    batch_tfms = [\n",
    "        *aug_transforms_3d(), \n",
    "        RandomCrop3D(((2, 2), (25,25), (25,25)), (0, 10, 10)), \n",
    "        PseudoColor],\n",
    "    splitter = GreatGreatGrandparentSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mris.dataloaders(oversampled, \n",
    "                       batch_size = 10, \n",
    "                       num_workers = 0\n",
    "                      )\n",
    "dls.valid.bs = 20 # defaults to 64 and will cause Cuda out of Memory errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple 3D ResNet\n",
    "\n",
    "The data is unbalanced, so I will use the mcc as loss function and as metric, as it strongly pentalizes wrong predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc_loss(out, targ):\n",
    "    targ = torch.stack((1-targ, targ), 1) # two classes are predicted: 0 = No Cancer, 1 = Cancer. So target also needs 2 dims.\n",
    "    return torch.mean(MCCLossBinary(smooth = 0.)(out, targ.long()))\n",
    "\n",
    "def mcc_score(out, targ):\n",
    "    targ = torch.stack((1-targ, targ), 1)\n",
    "    return mcc_binary(out, targ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, \n",
    "                resnet_3d(n_input = 1, n_classes = 2),\n",
    "                opt_func = SGD, \n",
    "                loss_func = mcc_loss,\n",
    "                metrics = [error_rate, mcc_score],\n",
    "                model_dir = '../models/'\n",
    "               )\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All weights are random, we are doing no transfer learning here. So for the first 10 epochs learning rate is very high and all layers are unfrozen. The `fit_one_cycle` function will still make sure we start with a reasonable small lr as warmup and decrease after some epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 0.1, wd = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "x, y = learn.get_preds()\n",
    "\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y.numpy(), x[:, 0])\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.annotate('AUC: '+ str(auc(ns_fpr, ns_tpr)), (0.75, 0.05))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
