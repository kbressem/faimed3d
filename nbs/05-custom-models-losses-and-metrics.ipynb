{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing 3D CNNs\n",
    "\n",
    "The dimension of a CNN does not refer to the dimensions of the input but to the dimensions of the kernel stride.  \n",
    "1D kernel moves only left-right (or up-down)  \n",
    "2D kernel moves left-right and up-down  \n",
    "3D kernel moves left-right, up-down and forward-backwards.   \n",
    "\n",
    "Thus with a kernel of size (3,3,20) a 3D volume of size (150,150,20) could be processed. The present 2D CNN from pytorch and fastai could thus easily be adapted. However, small findings which only occur in a feq slices could disappear in the convolutions, so 3D CNNs with smaller kernels might be better.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models\n",
    "# export \n",
    "\n",
    "import torchvision, torch\n",
    "from torch import nn, Tensor, tensor\n",
    "import torch.nn.functional as F\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.register_buffer('noise', tensor(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.expand(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow, in 3D CNNs, the input is not transfered to cuda. I believe something in the transforms is wrong. Until this is fixed, subcalssing _\n",
    "\n",
    "is the workarround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Sequential_(nn.Sequential):\n",
    "    \"Similar to nn.Sequential, but copies input to cuda\"\n",
    "    def forward(self, input):\n",
    "        for module in self:\n",
    "            input = module(input.cuda())\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom 3D CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def resnet_3d(n_input, n_classes):\n",
    "    return Sequential_(\n",
    "        # 1st Conv Block\n",
    "        nn.Conv3d(n_input, 64, kernel_size = (7,7,7), stride = (2, 2, 2), padding = (3, 3, 3), bias = True),\n",
    "        nn.BatchNorm3d(64, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "\n",
    "        # 2nd Conv Block\n",
    "        nn.Conv3d(64, 128, kernel_size = (5,5,5), stride = (2, 2, 2), padding = (2, 2, 2), bias = True),\n",
    "        nn.BatchNorm3d(128, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "        \n",
    "        # 3rd Conv Block\n",
    "        nn.Conv3d(128, 256, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(256, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "        \n",
    "        # 1st Res Block\n",
    "        nn.Conv3d(256, 384, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(384, 384, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(384, 384, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(384, 384, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "                \n",
    "        nn.AdaptiveAvgPool3d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(384, n_classes), \n",
    "        nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.vision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(20, 128, kernel_size=11, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.AvgPool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.softmax =  nn.LogSoftmax(dim=1)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "        out = self.layer1(x)\n",
    "   #     print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "   #     print(out.shape)\n",
    "        out = self.AvgPool(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.flatten(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.fc1(out)\n",
    " #       print(out.shape)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custon 3D UNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# copied from who????\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = Sequential_(\n",
    "            nn.Conv3d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = Sequential_(\n",
    "            nn.MaxPool3d(kernel_size = (2, 2, 2)),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if trilinear, use the normal convolutions to reduce the number of channels\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2, \n",
    "                        diffZ // 2, diffZ - diffZ // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        \n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, trilinear=False):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.trilinear = trilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if trilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, trilinear)\n",
    "        self.up2 = Up(512, 256 // factor, trilinear)\n",
    "        self.up3 = Up(256, 128 // factor, trilinear)\n",
    "        self.up4 = Up(128, 64, trilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "#        print('x:', x.shape)\n",
    "        x1 = self.inc(x)\n",
    "#        print('x1:', x1.shape)\n",
    "        x2 = self.down1(x1)\n",
    "#        print('x2:', x2.shape)\n",
    "        x3 = self.down2(x2)\n",
    "#        print('x3:', x3.shape)\n",
    "        x4 = self.down3(x3)\n",
    "#        print('x4:', x4.shape)\n",
    "        x5 = self.down4(x4)\n",
    "#        print('x5:', x5.shape)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "#        print('x:', x.shape)\n",
    "        x = self.up2(x, x3)\n",
    "#        print('x:', x.shape)\n",
    "        x = self.up3(x, x2)\n",
    "#        print('x:', x.shape)\n",
    "        x = self.up4(x, x1)\n",
    "#        print('x:', x.shape)\n",
    "        logits = self.outc(x)\n",
    "#        print(logits.shape)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DiceLossBinary():\n",
    "    \n",
    "    \"\"\"\n",
    "    Simple DICE loss as described in: \n",
    "        https://arxiv.org/pdf/1911.02855.pdf    \n",
    "    \n",
    "    Computes the Sørensen–Dice loss. Larger is better. \n",
    "    Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1. \n",
    "    \n",
    "    Args:\n",
    "        targ:    A tensor of shape [B, 1, D, H, W].\n",
    "        pred:    A tensor of shape [B, 1, D, H, W]. Corresponds to\n",
    "                 the raw output or logits of the model.\n",
    "        method:  The method, how the DICE score should be calcualted. \n",
    "                    \"simple\"   = standard DICE loss\n",
    "                    \"miletari\" = squared denominator for faster convergence\n",
    "                    \"tversky\"  = variant of the DICE loss which allows to weight FP vs FN. \n",
    "        alpha, beta: weights for FP and FN for \"tversky\" loss, if both values are 0.5 the \n",
    "                 \"tversky\" loss corresponds to the \"simple\" DICE loss\n",
    "        smooth:  Added smoothing factor. \n",
    "        eps: added to the denominator for numerical stability (acoid division by 0).\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, method = 'miletari', alpha = 0.5, beta = 0.5, eps = 1e-7, smooth = 1.) -> None:\n",
    "        self.method = method \n",
    "        self.alpha = alpha \n",
    "        self.beta = beta \n",
    "        self.eps = eps\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        if input.min() < 0 or input.max() > 1: \n",
    "            warn(\"Input is not in range between 0 and 1 but the loss will work better with input in that range. Consider rescaling your input. \")\n",
    "           \n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "\n",
    "        if self.method == 'simple':\n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            denominator  = torch.sum(input + target, dims) + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "\n",
    "        elif self.method == 'miletari':  \n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            denominator  = torch.sum(input**2 + target**2, dims) + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "\n",
    "        elif self.method == 'tversky':\n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            fps = torch.sum(input * (1 - target), dims)\n",
    "            fns = torch.sum((1 - input) * target, dims)\n",
    "\n",
    "            denominator  = numerator + self.alpha*fps + self.beta*fns + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "            \n",
    "        else: \n",
    "            raise NotImplementedError('The specified type of DICE loss is not implemented')\n",
    "\n",
    "        return 1-dice_loss "
   ]
  },
  {
   "attachments": {
    "mcc formula.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABLkAAABJBAMAAAAjyOn0AAAAMFBMVEX///8AAAAAAAAAAAAAAAAA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\n"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the MCC score as loss function:  \n",
    "\n",
    "\n",
    "$$\\frac{ \n",
    "        \\sum_{i}^{n} p_{ i }g_{ i } * \\sum_{i}^{n}  1-p_{ i } 1-g_{ i } +\n",
    "        \\sum_{i}^{n}  1-p_{ i } g_{ i } * \\sum_{i}^{n}  p_{ i } 1-g_{ i }}{ \\sqrt{ \n",
    "        (\\sum_{i}^{n}  p_{ i } g_{ i } + \\sum_{i}^{n}  1-p_{ i } g_{ i }) * \n",
    "        (\\sum_{i}^{n}  p_{ i } g_{ i } + \\sum_{i}^{n} p_{ i } 1-g_{ i }) *  \n",
    "        (\\sum_{i}^{n}  1-p_{ i } g_{ i } + \\sum_{i}^{n} 1-p_{ i } 1-g_{ i }) * \n",
    "        (\\sum_{i}^{n}  p_{ i } 1-g_{ i } + \\sum_{i}^{n} 1-p_{ i } 1-g_{ i }) \n",
    "     } }$$\n",
    "\n",
    "where p_i is the prediction for pixel i and g_i the corresponding ground truth pixel and gamma is the smoothing factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MCCLossBinary(DiceLossBinary):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the MCC loss. \n",
    "    \n",
    "    From Wikipedia (https://en.wikipedia.org/wiki/Matthews_correlation_coefficient):\n",
    "        > The coefficient takes into account true and false positives and negatives and is generally \n",
    "        > regarded as a balanced measure which can be used even if the classes are of very different sizes\n",
    "        > The MCC is in essence a correlation coefficient between the observed \n",
    "        > and predicted binary classifications; it returns a value between −1 and +1. \n",
    "        > A coefficient of +1 represents a perfect prediction, 0 no better than random prediction\n",
    "        > and −1 indicates total disagreement between prediction and observation    \n",
    "    \n",
    "    For this loss to work best, the input should be in range 0-1, e.g. enforced through a sigmoid or softmax. \n",
    "    Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1. \n",
    "\n",
    "    Latex formula: \n",
    "    \\frac{ \n",
    "        \\Sum{ i }{ n }{ p_{ i } g_{ i }} * \\Sum{ i }{ n }{ 1-p_{ i } 1-g_{ i }} +\n",
    "        \\Sum{ i }{ n }{ 1-p_{ i } g_{ i }} * \\Sum{ i }{ n }{ p_{ i } 1-g_{ i }} }\n",
    "\n",
    "    { \\sqrt{ \n",
    "        (\\Sum{ i }{ n }{ p_{ i } g_{ i }} + \\Sum{ i }{ n }{ 1-p_{ i } g_{ i }}) * \n",
    "        (\\Sum{ i }{ n }{ p_{ i } g_{ i }} + \\Sum{ i }{ n }{ p_{ i } 1-g_{ i }}) *  \n",
    "        (\\Sum{ i }{ n }{ 1-p_{ i } g_{ i }} + \\Sum{ i }{ n }{ 1-p_{ i } 1-g_{ i }}) * \n",
    "        (\\Sum{ i }{ n }{ p_{ i } 1-g_{ i }} + \\Sum{ i }{ n }{ 1-p_{ i } 1-g_{ i }}) \n",
    "     } }\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        input:   A tensor of shape [B, 1, D, H, W]. Predictions. \n",
    "        target:  A tensor of shape [B, 1, D, H, W]. Ground truth. \n",
    "        smooth:  Smoothing factor, default is 1. Inherited from DiceLossBinary base class \n",
    "        eps:     Added for numerical stability.\n",
    "    Returns:\n",
    "        mmc_loss: loss based on Matthews correlation coefficient\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:         \n",
    "        return self.compute_loss(input, target)\n",
    "    \n",
    "    def activation(self, input):\n",
    "        return torch.sigmoid(input)\n",
    "       \n",
    "    def compute_loss(self, input: Tensor, target: Tensor):\n",
    "        \n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "        \n",
    "        tps = torch.sum(self.activation(input) * target, dims) \n",
    "        fps = torch.sum(self.activation(input) * (1 - target), dims)\n",
    "        fns = torch.sum((1 - self.activation(input)) * target, dims)\n",
    "        tns = torch.sum((1 - self.activation(input)) * (1-target), dims)\n",
    "            \n",
    "        numerator = (tps * tns - fps * fns) + self.smooth \n",
    "        denominator =  ((tps + fps) * (tps + fns) * (fps + tns) * (tns + fns) + self.eps)**0.5 + self.smooth\n",
    "        \n",
    "        mcc_loss = numerator / (denominator)\n",
    "        \n",
    "        return 1-mcc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0001])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.randn(5,1,2,25,25).sigmoid()\n",
    "t = torch.randn(5,1,2,25,25).sigmoid().round()\n",
    "\n",
    "MCCLossBinary()(i, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MCCLossMulti(MCCLossBinary):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the MCC loss for a multilabel target. Basically the same as `MCCLossBinary` \n",
    "    but one hot encodes the target before computation. \n",
    "    \n",
    "    Args:\n",
    "        num_features: Number of different features in y. \n",
    "                 Must correspond to the maximum number of overall features in the whole dataset.\n",
    "        input:   A tensor of shape [B, C, D, H, W], where the `n_classes` should correspond to C.\n",
    "        target:  A tensor of shape [B, 1, D, H, W]. Ground truth. \n",
    "        weights: Either a str: 'auto' for autocalculation, None or a list/tuple of soecified weights\n",
    "        smooth:  Smoothing factor, default is 1. Inherited from DiceLossBinary base class \n",
    "        eps:     Added for numerical stability.\n",
    "        n_classes: number of classes to predict\n",
    "    Returns:\n",
    "        mmc_loss: loss based on Matthews correlation coefficient\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes, weights=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weights = weights\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        \n",
    "        self.get_weights(input)\n",
    "        target = self.to_one_hot(target)\n",
    "\n",
    "        return torch.mean(super().__call__(input, target)*self.weights)\n",
    "    \n",
    "    def get_weights(self, target):\n",
    "        if self.weights == 'auto': \n",
    "            \"estimates weights from the percentage distribution of a finding.\"\n",
    "            dims = (0,) + tuple(range(2, target.ndim))\n",
    "            self.weights = 1/torch.mean(target, dims)\n",
    "        elif self.weights == None: \n",
    "            self.weights = 1.\n",
    "        elif isinstance(self.weights, (tuple, list)):\n",
    "            self.weights = tensor(self.weights)\n",
    "    \n",
    "    def make_binary(self, t, set_to_one):\n",
    "        return (t == set_to_one).float()\n",
    "  \n",
    "    def to_one_hot(self, target:Tensor):\n",
    "        target = target.squeeze(1).long() # remove the solitary color channel (if there is one) and set type to int64\n",
    "        one_hot = [self.make_binary(target, set_to_one=i) for i in range(0, self.n_classes)]\n",
    "    \n",
    "        return torch.stack(one_hot, 1)\n",
    "    \n",
    "    def activation(self, input): \n",
    "        return F.softmax(input, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9953)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.randn(5,5,2,25,25)\n",
    "t = torch.randint(0, 5, (5,1,2,25,25))\n",
    "\n",
    "MCCLossMulti(5)(i, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MCCScore(MCCLossMulti):\n",
    "    def __init__(self, n_classes = None, thres = 0.5, **kwargs):\n",
    "        super().__init__(n_classes, **kwargs)\n",
    "        \n",
    "        self.n_classes = 1 if n_classes is None else n_classes\n",
    "        self.thres = thres\n",
    "    \n",
    "    def __call__(self, input:Tensor , target: Tensor):\n",
    "        if self.n_classes is not None: \n",
    "            target = self.to_one_hot(target)\n",
    "            \n",
    "            return 1-torch.mean(super().__call__(input, target))\n",
    "        \n",
    "    def activation(self, input): \n",
    "        return (input > self.thres).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0050)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCCScore()(i, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schätzung der TP, TN, FP, FN durch Regression\n",
    "\n",
    "Um den Sensitivität und Spezifität berechen zu können müssen zuerst die TP, FP, TN und FN erechnet werden. \n",
    "Allerdings ist es auch Möglich die Sensitivität und Spezifität durch eine logistische Regression zu ermitteln (https://doi.org/10.1016/0895-4356(92)90180-u). \n",
    "Die log odds von Sensitivität und Spezifität können als folgende Funktion dargestellt werden:\n",
    "\n",
    "\n",
    "$$ logit Pr(Y=1 | X) = \\alpha + \\sum_{k=1}^{K} \\beta_{k}X_{k}$$\n",
    "\n",
    "Die Schäzung der logit Sensitivität und logit Spezifität geschieht aus $(1...k)$ Variablen mit ihren entsprechenden Betacoeffizienten, wobei eine dieser Variablen dem Goldstandard entspricht. \n",
    "\n",
    "Die Ermittlung der Sensitivität ist daraufhin: \n",
    "$$\\frac{1}{1+exp(-(\\alpha+\\sum_{k=1}^{K}\\beta_{k}X_{k})} \\quad \\textrm{wobei} \\quad X_{k}=1$$\n",
    "\n",
    "\n",
    "Die Ermittlung der Spezifität ist ähnlich: \n",
    "$$1-(\\frac{1}{1+exp(-(\\alpha+\\sum_{k=1}^{K}\\beta_{k}X_{k}}) \\quad \\textrm{wobei} \\quad X_{k}=0$$\n",
    "\n",
    "\n",
    "von hier aus können Rückschlüsse auf die TP und TN gezogen werden durch: \n",
    "\n",
    "$$TP = Sens * P \\quad \\textrm{wobei} \\quad P = \\sum_{k=1}^{K} X_{k} \\quad \\textrm{fuer} \\quad X=1$$\n",
    "\n",
    "$$TN = Spec * N \\quad \\textrm{wobei} \\quad N = \\sum_{k=1}^{K} X_{k} \\quad \\textrm{fuer} \\quad X_{k}=0$$\n",
    "\n",
    "$$FN = (1-Sens) * P \\quad \\textrm{wobei} \\quad P = \\sum_{k=1}^{K} X_{k} \\quad \\textrm{fuer} \\quad X_{k}=1$$\n",
    "\n",
    "$$FP = (1-Spec) * N \\quad \\textrm{wobei} \\quad N = \\sum_{k=1}^{K} X_{k} \\quad \\textrm{fuer} \\quad X_{k}=0$$\n",
    "\n",
    "\n",
    "Wenn $X$ in $(0...1)$ dann kann $N = \\sum_{k=1}^{K} 1-X_{k} \\quad \\textrm{fuer} \\quad X=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation des Verfahrens in Pytorch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.randn(1000, 1).sigmoid().round()\n",
    "y_data = torch.randn(1000, 1).sigmoid().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion für die Errechnung von Sensitivität und Spezifität durch eine Konfusionsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(input, target): \n",
    "    tps = torch.sum(input * target) \n",
    "    fps = torch.sum(input * (1 - target))\n",
    "    fns = torch.sum((1 - input) * target)\n",
    "    tns = torch.sum((1 - input) * (1-target))\n",
    "    \n",
    "    sen = tps / (tps + fns)\n",
    "    spec = tns /(tns + fps)\n",
    "    \n",
    "    return sen, spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineares Regressionsmodell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(2, 1)    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "def lin_reg(x, y):\n",
    "    model = LinearRegression()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    x = torch.cat((x, y), dim = 1)\n",
    "\n",
    "    for epoch in range(10000):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()    # Forward pass\n",
    "        y_pred = model(x)    # Compute Loss\n",
    "        loss = criterion(y_pred, y)    # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model(x)\n",
    "\n",
    "def sen_spe(pred, x_data):\n",
    "    sen = 1/torch.exp(1+torch.mean(-pred[x_data == 0]))\n",
    "    spe = 1-1/torch.exp(1+torch.mean(-pred[x_data == 0]))\n",
    "    return sen, spe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.4785), tensor(0.5000))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.6368, grad_fn=<MulBackward0>),\n",
       " tensor(0.3632, grad_fn=<RsubBackward1>))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = lin_reg(x_data, y_data)\n",
    "print(cm(x_data, y_data))\n",
    "sen_spe(p, x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)~",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
