{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "Special Callbacks for 3D data or training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp callback\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.preprocess import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Manipulation\n",
    "\n",
    "Fpr processing multiple 3D volumes, the volumes can be stacked to the color dimension. This need to be implemented as callback, before the batch is presented to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StackVolumes(Callback):\n",
    "    \"\"\"\n",
    "    Takes multiple 3D volumes and stacks them in the color dim.\n",
    "    This is usefull when using mutli-sequence medical data. \n",
    "    \n",
    "    Can also merge multiple segmentation masks, through pooling (max, min or mean) alongside the color dim, \n",
    "    then convertes the mask to one-hot encoded type. However, this can lead to 'ugly' masks with punch-out like \n",
    "    appearences\n",
    "    \n",
    "    Example: \n",
    "        Having the Tensors of size (10, 1, 5, 25, 25) would lead to a single Tensor of \n",
    "        size (10, 3, 5, 25, 25).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes, pool_type='max', stack_yb=False):\n",
    "        store_attr()\n",
    "    \n",
    "    def before_batch(self):\n",
    "        self.learn.xb = (torch.cat(self.learn.xb, dim=1), )      \n",
    "        \n",
    "        if self.stack_yb:\n",
    "            if self.pool_type=='max':\n",
    "                yb = torch.cat(self.learn.yb, dim = 1).max(dim=1)[0] # get max at color channel\n",
    "            elif self.pool_type=='mean':\n",
    "                yb = torch.cat(self.learn.yb, dim = 1).mean(dim=1)[0].round() # get mean at color channel\n",
    "            elif self.pool_type=='min':\n",
    "                yb = torch.cat(self.learn.yb, dim = 1).min(dim=1)[0] # get min at color channel\n",
    "\n",
    "            else: raise NotImplementedError('Pooling type {} for mask not implemented'.format(self.pool_type))\n",
    "            yb = self.to_one_hot(yb, self.n_classes)\n",
    "            self.learn.yb = (yb, )\n",
    "        \n",
    "    def make_binary(self, target, val):\n",
    "        return torch.where(target == val, tensor(1.).to(target.device), tensor(0.).to(target.device))\n",
    "\n",
    "    def to_one_hot(self, target, n_classes):\n",
    "        target = target.squeeze(1).long() # remove the solitary color channel (if there is one) and set type to int64\n",
    "        one_hot = [self.make_binary(target, val=i) for i in range(0, n_classes)]\n",
    "        return torch.stack(one_hot, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks for Volume Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In medical imaging, small regions in the image are often decisive for the diagnosis. This means, given a smaller subregion of the image, the model could still correctly detect the pathology. Through splitting the volumes the data might thus be augmented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SplitVolumes(Callback):\n",
    "    \"\"\"\n",
    "        Separates a 3D tensor into smaller equal sized subvolumes. \n",
    "        \n",
    "         o---o---o       o---o---o       \n",
    "         | A | A |       | B | B |        o---o  o---o  o---o  o---o  o---o  o---o  o---o  o---o\n",
    "         o---o---o   +   o---o---o  ==>   | A | +| A | +| B | +| B | +| A | +| A | +| B | +| B |\n",
    "         | A | A |       | B | B |        o---o  o---o  o---o  o---o  o---o  o---o  o---o  o---o\n",
    "         o---o---o       o---o---o        \n",
    "\n",
    "\n",
    "        Args: \n",
    "            n_subvol = number of subvolumes\n",
    "            split_along_depth = whether volumes should also be split along the D dimension fpr a [B, C, D, H, W] tensor\n",
    "    \"\"\"\n",
    "    run_after = StackVolumes\n",
    "    def __init__(self, n_subvol = 2**3, split_along_depth = True):\n",
    "        store_attr()\n",
    "        \n",
    "    def before_batch(self):\n",
    "        xb = self.learn.xb\n",
    "        if len(xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')     \n",
    "        self.learn.xb = self.split_volume(xb)\n",
    "        self.learn.yb = self.split_volume(self.learn.yb)\n",
    "\n",
    "    def after_pred(self):\n",
    "        self.learn.xb = self.patch_volume(self.learn.xb)\n",
    "        self.learn.pred = detuplify(self.patch_volume(self.learn.pred))\n",
    "        self.learn.yb = self.patch_volume(self.learn.yb)\n",
    "    \n",
    "    def split_volume(self, xb:(Tensor, TensorDicom3D, TensorMask3D)):\n",
    "        \"splits a large tensor into multiple smaller tensors\"\n",
    "\n",
    "        xb = detuplify(xb) # xb is always a tuple\n",
    "        # calculate number of splits per dimension\n",
    "        self.n = self.n_subvol**(1/3) if self.split_along_depth else self.n_subvol**0.5\n",
    "        self.n = int(self.n)\n",
    "        \n",
    "        # check if shape of dims is divisible by n, if not resize the Tensor acordingly\n",
    "        shape = [s if s % self.n == 0 else s - s % self.n for s in xb.shape[-3:]] \n",
    "        if not self.split_along_depth: shape[0]=xb.shape[0]    \n",
    "        xb = F.interpolate(xb, size = shape, mode = \"trilinear\", align_corners=True)\n",
    "        \n",
    "        # split each dim into smaller dimensions\n",
    "        d, h, w = shape\n",
    "        if self.split_along_depth: xb = xb.reshape(xb.size(0), xb.size(1), self.n, int(d/self.n), self.n, int(h/self.n), self.n, int(w/self.n))\n",
    "        else: xb = xb.reshape(xb.size(0), xb.size(1),1, d, self.n, int(h/self.n), self.n, int(w/self.n))    \n",
    "            \n",
    "        # swap the dimensions an flatten Batchdim and the newly created dims    \n",
    "        # return a tuple as xb is always a tuple\n",
    "        return (xb.permute(1, 3, 5, 7, 0, 2, 4, 6).flatten(-4).permute(4, 0, 1, 2, 3), )\n",
    "\n",
    "    def patch_volume(self, p:(Tensor, TensorDicom3D, TensorMask3D)):\n",
    "        \"patches a prior split volume back together\"\n",
    "        p = detuplify(p)\n",
    "\n",
    "        old_shape = p.shape[0]//self.n_subvol, p.shape[1], *[s * self.n for s in p.shape[2:]]\n",
    "        if not self.split_along_depth: old_shape[2]=p.shape[2]\n",
    "        p = p.reshape(old_shape[0], self.n, self.n, self.n, *p.shape[1:])\n",
    "        return (p.permute(0, 4, 1, 5, 2, 6, 3, 7).reshape(old_shape), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsampling the subvolumes allows for more variability in the image and also training with a batch size < 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SubsampleShuffle(SplitVolumes):\n",
    "    \"\"\"\n",
    "        After splitting rhe volume into multiple subvolumes, draws a radnom amount of subvolumes for training.\n",
    "        Would allow to train on an effective batch size < 1. \n",
    "        \n",
    "        o---o---o        o---o---o       \n",
    "        | A | A |        | B | B |        o---o  o---o  o---o  o---o  o---o  o---o\n",
    "        o---o---o    +   o---o---o  ==>   | B | +| A | +| A | +| A | +| B | +| A |\n",
    "        | A | A |        | B | B |        o---o  o---o  o---o  o---o  o---o  o---o\n",
    "        o---o---o        o---o---o        \n",
    "        \n",
    "        Args: \n",
    "            p: percentage of subvolumes to train on\n",
    "    \"\"\"\n",
    "    run_after = [StackVolumes]\n",
    "    \n",
    "    def __init__(self, p = 0.5, n_subvol=2**3, split_along_depth = True):\n",
    "        store_attr()\n",
    "        \n",
    "    def before_batch(self):    \n",
    "        \n",
    "        xb = self.learn.xb\n",
    "        if len(xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')     \n",
    "        self.learn.xb = self.split_volume(xb)\n",
    "        self.learn.yb = self.split_volume(self.learn.yb)\n",
    "        \n",
    "        if self.training:\n",
    "            xb = detuplify(self.learn.xb)\n",
    "            yb = detuplify(self.learn.yb)\n",
    "            draw = tuple(random.sample(range(0, xb.size(0)), int(xb.size(0)*self.p)))\n",
    "            self.learn.xb = (xb[draw, :], )\n",
    "            self.learn.yb = (yb[draw, :], )\n",
    "\n",
    "    def after_pred(self):\n",
    "        if not self.training:\n",
    "            self.learn.xb = self.patch_volume(self.learn.xb)\n",
    "            self.learn.pred = detuplify(self.patch_volume(self.learn.pred))\n",
    "            self.learn.yb = self.patch_volume(self.learn.yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming, a small finding is predominantly located in the, e.g. upper left image region, the model might wrongly learn the location as an important factor for the finding. Mixing subvolumes might help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MixSubvol(SplitVolumes):\n",
    "    \"\"\"\n",
    "        After splitting rhe volume into multiple subvolumes, shuffels the subvolumes and sticks the images back together.\n",
    "        \n",
    "        o---o---o        o---o---o        o---o---o        o---o---o\n",
    "        | A | A |        | B | B |        | B | B |        | A | B |\n",
    "        o---o---o    +   o---o---o  ==>   o---o---o    +   o---o---o \n",
    "        | A | A |        | B | B |        | A | A |        | B | A |\n",
    "        o---o---o        o---o---o        o---o---o        o---o---o\n",
    "\n",
    "        \n",
    "        Args: \n",
    "            p: probability that the callback will be applied\n",
    "            n_subvol: number of subvolumina to create\n",
    "            split_along_depth: whether the depth dimension should be included\n",
    "            \n",
    "    \"\"\"\n",
    "    run_after = [StackVolumes]\n",
    "    \n",
    "    def __init__(self, p = 0.25, n_subvol=2**3, split_along_depth = True):\n",
    "        store_attr()\n",
    "        \n",
    "    def before_batch(self):    \n",
    "        if self.training and random.random() < self.p:\n",
    "            xb = self.learn.xb\n",
    "            if len(xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')     \n",
    "            xb = detuplify(self.split_volume(xb))\n",
    "            yb = detuplify(self.split_volume(self.learn.yb))\n",
    "            shuffle = tuple(random.sample(range(0, xb.size(0)), xb.size(0)))\n",
    "            self.learn.xb = self.patch_volume((xb[shuffle, :], ))\n",
    "            self.learn.yb = self.patch_volume((yb[shuffle, :], ))\n",
    "            \n",
    "    def after_pred(self): \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation for MixUp on 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MixUp3D(Callback):\n",
    "    \"\"\"\n",
    "    Implementation of MixUp for 3D images. \n",
    "    Note that the loss function does not need to be adapted like in fastais MixUp, as MCC and DICE loss accept float values. \n",
    "    \n",
    "    ToDo:\n",
    "        Currently, MixUp can generate false labels. Eg mixing 50% of Label 1 and 50% of Label 3 will give Label 2, which is wrong. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    run_after = [Normalize, StackVolumes]\n",
    "    def __init__(self, p = 0.5):\n",
    "        store_attr()\n",
    "        warnings.warn('currently MixUp generates wrong labels if there are more than two differnt labels.'\n",
    "                      'Use with caution.')\n",
    "    \n",
    "    def before_batch(self):\n",
    "        if self.training and random.random() < self.p:\n",
    "            if len(self.learn.xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')   \n",
    "            shuffled_idx = list(range(0, detuplify(self.learn.xb).size(0)))\n",
    "            random.shuffle(shuffled_idx)\n",
    "            xj = detuplify(self.learn.xb)[shuffled_idx, :]\n",
    "            yj = detuplify(self.learn.yb)[shuffled_idx, :]\n",
    "            w = random.random()\n",
    "            self.learn.xb = (detuplify(self.learn.xb)*w + xj*(1-w), )\n",
    "            self.learn.yb = (detuplify(self.learn.yb)*w + yj*(1-w), )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracker Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ReloadBestFit(TrackerCallback):\n",
    "    \"A `TrackerCallback` that reloads the previous best model if not improvement happend for n epochs\"\n",
    "    def __init__(self, fname,  monitor='valid_loss', comp=None, min_delta=0., patience=1):\n",
    "        super().__init__(monitor=monitor, comp=comp, min_delta=min_delta)\n",
    "        self.patience = patience\n",
    "        self.fname = fname\n",
    "        \n",
    "    def before_fit(self): self.wait = 0; super().before_fit()\n",
    "    def after_epoch(self):\n",
    "        \"Compare the value monitored to its best score and maybe stop training.\"\n",
    "        super().after_epoch()\n",
    "        if self.new_best: self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print(f'No improvement since epoch {self.epoch-self.wait}: reloading previous best model.')\n",
    "                self.learn = self.learn.load(self.fname)\n",
    "                self.wait=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback for Pixel value rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PiecewiseHistNormalizationCallback(Callback):\n",
    "    \"\"\"\n",
    "    Applies Piecewise Histogram Matching to batches. \n",
    "    Generates standard_scale and percs before fit, if not provided. \n",
    "    \"\"\"\n",
    "    \n",
    "    run_before = [Normalize]\n",
    "    def __init__(self, standard_scale=None, percs=None):\n",
    "        store_attr()\n",
    "    \n",
    "    def before_fit(self):\n",
    "        if self.standard_scale is None or self.percs is None: \n",
    "            print('No standard scale for normalization was provided. '\n",
    "                  'Iterating through {} items of the training dataset to define scale.'.format(len(self.dls.train_ds)))\n",
    "            scales = [] \n",
    "            for i, batch in tqdm(enumerate(self.dls.train_ds)):\n",
    "                xb, yb = batch\n",
    "                scale, percs = find_standard_scale(xb)\n",
    "                scales.append(scale)\n",
    "\n",
    "            self.standard_scale = torch.stack(scales).mean(0)\n",
    "            self.percs = percs\n",
    "            print('Standard scale was found to be {} '.format(self.standard_scale.numpy()))\n",
    "            print('Percs were found to be {} '.format(self.percs.numpy()))\n",
    "            with open('std_scale.txt', 'w+') as f:\n",
    "                for s in self.standard_scale.numpy():\n",
    "                    f.write(str(s)+ ',')\n",
    "                f.write('\\n' )    \n",
    "                for p in self.percs.numpy():\n",
    "                    f.write(str(p)+ ',')\n",
    "            print('Wrote standard scale and percs to file at std_scale.txt')\n",
    "            \n",
    "    def before_batch(self):\n",
    "        xb = detuplify(self.learn.xb)\n",
    "        for i in range(0, xb.size(0)):\n",
    "            xb[i]= xb[i].piecewise_hist(self.percs, self.standard_scale) \n",
    "        xb = (xb - xb.mean()) / xb.std()\n",
    "        self.learn.xb = (xb, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_basics.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_transforms.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_learner.ipynb.\n",
      "Converted 06a_models.alexnet.ipynb.\n",
      "Converted 06b_models.resnet.ipynb.\n",
      "Converted 06c_models.densenet.ipynb.\n",
      "Converted 06d_models.DynamicUnet.ipynb.\n",
      "Converted 06d_models.unet.ipynb.\n",
      "Converted 06e_models.deeplabv3.ipynb.\n",
      "Converted 06f_models.losses.ipynb.\n",
      "Converted 07_callback.ipynb.\n",
      "Converted 99_tools.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
