{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "\n",
    "The classes and functions in this notebook are highly specific and probably not usefull for the most tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp callback\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.data import *\n",
    "from faimed3d.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Path('../../dl-prostate-mapping/data/train') # ../data/train would work to, but with this lon string, I can also test the nb in faimed3d\n",
    "valid = Path('../../dl-prostate-mapping/data/valid')\n",
    "\n",
    "files = list(train.rglob('DICOM')) + list(valid.rglob('DICOM'))\n",
    "\n",
    "# take only T2 images for now\n",
    "t2_files, adc_files, dwi_files = [], [], []\n",
    "for f in files: \n",
    "    m = re.search(r'T2|ADC|DWI', str(f)) \n",
    "    if hasattr(m, 'string'):\n",
    "        if 'T2' in m.string: t2_files.append(Path(m.string)/'cropped_volume.nii.gz') \n",
    "        if 'ADC' in m.string: adc_files.append(Path(m.string)/'cropped_volume.nii.gz') \n",
    "        if 'DWI' in m.string: dwi_files.append(Path(m.string)/'cropped_volume.nii.gz')     \n",
    "            \n",
    "t2_segmentation = [(p.parent.parent/'Annotation/cropped_mask_adapted.nii.gz') for p in t2_files]\n",
    "adc_segmentation = [(p.parent.parent/'Annotation/cropped_mask_adapted.nii.gz') for p in adc_files]\n",
    "\n",
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "              ImageBlock3D(cls=TensorDicom3D), \n",
    "              ImageBlock3D(cls=TensorDicom3D), \n",
    "              MaskBlock3D(codes = ['void', \"peripheral\", 'transitional', 'cancer']), \n",
    "              MaskBlock3D(codes = ['void', \"peripheral\", 'transitional', 'cancer']), \n",
    "             ),\n",
    "    get_x = [lambda x: x[0], lambda x: x[1], lambda x: x[2]],\n",
    "    get_y = [lambda x: x[3], lambda x: x[4]],\n",
    "    item_tfms = ResizeCrop3D(crop_by = (0, 0, 0), resize_to = (16, 80, 80)),\n",
    "    batch_tfms = [\n",
    "        *aug_transforms_3d(p_all=0.15, do_rotate_by = False), \n",
    "        PseudoColor],\n",
    "    splitter = ColSplitter(),\n",
    "    n_inp = 3)\n",
    "\n",
    "d = pd.DataFrame({'T2' : t2_files,\n",
    "                  'ADC': adc_files,\n",
    "                  'DWI': dwi_files,\n",
    "                  'mask_t2' : t2_segmentation, \n",
    "                  'mask_adc': adc_segmentation,\n",
    "                  'is_valid': [1 if 'valid' in str(o) else 0 for o in t2_files]})\n",
    "\n",
    "dls = mris.dataloaders(d, \n",
    "                       batch_size = 10, \n",
    "                       num_workers = 0,\n",
    "                      )\n",
    "dls.valid.bs = 20 # defaults to 64 and will cause Cuda out of Memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StackVolumes(Callback):\n",
    "    \"\"\"\n",
    "    Takes multiple 3D volumes and stacks them in the color dim.\n",
    "    This is usefull when using mutli-sequence medical data. \n",
    "    \n",
    "    Also merges multiple segmentation masks, through pooling (max, min or mean) alongside the color dim, \n",
    "    then convertes the mask to one-hot encoded type. \n",
    "    \n",
    "    Example: \n",
    "        Having the Tensors of size (10, 1, 5, 25, 25) would lead to a single Tensor of \n",
    "        size (10, 3, 5, 25, 25).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes, pool_type='max'):\n",
    "        store_attr()\n",
    "    \n",
    "    def before_batch(self):\n",
    "        self.learn.xb = (torch.cat(self.learn.xb, dim=1), )      \n",
    "        \n",
    "        if self.pool_type=='max':\n",
    "            yb = torch.cat(self.learn.yb, dim = 1).max(dim=1)[0] # get max at color channel\n",
    "        elif self.pool_type=='mean':\n",
    "            yb = torch.cat(self.learn.yb, dim = 1).mean(dim=1)[0].round() # get mean at color channel\n",
    "        elif self.pool_type=='min':\n",
    "            yb = torch.cat(self.learn.yb, dim = 1).min(dim=1)[0] # get min at color channel\n",
    "\n",
    "        else: raise NotImplementedError('Pooling type {} for mask not implemented'.format(self.pool_type))\n",
    "        yb = self.to_one_hot(yb, self.n_classes)\n",
    "        self.learn.yb = (yb, )\n",
    "        \n",
    "    def make_binary(self, target, val):\n",
    "        return torch.where(target == val, tensor(1.).to(target.device), tensor(0.).to(target.device))\n",
    "\n",
    "    def to_one_hot(self, target, n_classes):\n",
    "        target = target.squeeze(1).long() # remove the solitary color channel (if there is one) and set type to int64\n",
    "        one_hot = [self.make_binary(target, val=i) for i in range(0, n_classes)]\n",
    "        return torch.stack(one_hot, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SplitVolumes(Callback):\n",
    "    \"\"\"\n",
    "        Separates a 3D tensor into smaller equal sized subvolumes. \n",
    "        \n",
    "         o---o---o       o---o---o       \n",
    "         | A | A |       | B | B |        o---o  o---o  o---o  o---o  o---o  o---o  o---o  o---o\n",
    "         o---o---o   +   o---o---o  ==>   | A | +| A | +| B | +| B | +| A | +| A | +| B | +| B |\n",
    "         | A | A |       | B | B |        o---o  o---o  o---o  o---o  o---o  o---o  o---o  o---o\n",
    "         o---o---o       o---o---o        \n",
    "\n",
    "\n",
    "        Args: \n",
    "            n_subvol = number of subvolumes\n",
    "            split_along_depth = whether volumes should also be split along the D dimension fpr a [B, C, D, H, W] tensor\n",
    "    \"\"\"\n",
    "    run_after = StackVolumes\n",
    "    def __init__(self, n_subvol = 2**3, split_along_depth = True):\n",
    "        store_attr()\n",
    "        \n",
    "    def before_batch(self):\n",
    "        xb = self.learn.xb\n",
    "        if len(xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')     \n",
    "        self.learn.xb = self.split_volume(xb)\n",
    "        self.learn.yb = self.split_volume(self.learn.yb)\n",
    "\n",
    "    def after_pred(self):\n",
    "        self.learn.xb = self.patch_volume(self.learn.xb)\n",
    "        self.learn.pred = detuplify(self.patch_volume(self.learn.pred))\n",
    "        self.learn.yb = self.patch_volume(self.learn.yb)\n",
    "    \n",
    "    def split_volume(self, xb:(Tensor, TensorDicom3D, TensorMask3D)):\n",
    "        \"splits a large tensor into multiple smaller tensors\"\n",
    "\n",
    "        xb = detuplify(xb) # xb is always a tuple\n",
    "        # calculate number of splits per dimension\n",
    "        self.n = self.n_subvol**(1/3) if self.split_along_depth else self.n_subvol**0.5\n",
    "        self.n = int(self.n)\n",
    "        \n",
    "        # check if shape of dims is divisible by n, if not resize the Tensor acordingly\n",
    "        shape = [s if s % self.n == 0 else s - s % self.n for s in xb.shape[-3:]] \n",
    "        if not self.split_along_depth: shape[0]=xb.shape[0]    \n",
    "        xb = F.interpolate(xb, size = shape, mode = \"trilinear\", align_corners=True)\n",
    "        \n",
    "        # split each dim into smaller dimensions\n",
    "        d, h, w = shape\n",
    "        if self.split_along_depth: xb = xb.reshape(xb.size(0), xb.size(1), self.n, int(d/self.n), self.n, int(h/self.n), self.n, int(w/self.n))\n",
    "        else: xb = xb.reshape(xb.size(0), xb.size(1),1, d, self.n, int(h/self.n), self.n, int(w/self.n))    \n",
    "            \n",
    "        # swap the dimensions an flatten Batchdim and the newly created dims    \n",
    "        # return a tuple as xb is always a tuple\n",
    "        return (xb.permute(1, 3, 5, 7, 0, 2, 4, 6).flatten(-4).permute(4, 0, 1, 2, 3), )\n",
    "\n",
    "    def patch_volume(self, p:(Tensor, TensorDicom3D, TensorMask3D)):\n",
    "        \"patches a prior split volume back together\"\n",
    "        p = detuplify(p)\n",
    "\n",
    "        old_shape = p.shape[0]//self.n_subvol, p.shape[1], *[s * self.n for s in p.shape[2:]]\n",
    "        if not self.split_along_depth: old_shape[2]=p.shape[2]\n",
    "        p = p.reshape(old_shape[0], self.n, self.n, self.n, *p.shape[1:])\n",
    "        return (p.permute(0, 4, 1, 5, 2, 6, 3, 7).reshape(old_shape), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SubsampleShuffle(SplitVolumes):\n",
    "    \"\"\"\n",
    "        After splitting rhe volume into multiple subvolumes, draws a radnom amount of subvolumes for training.\n",
    "        Would allow to train on an effective batch size < 1. \n",
    "        \n",
    "        o---o---o        o---o---o       \n",
    "        | A | A |        | B | B |        o---o  o---o  o---o  o---o  o---o  o---o\n",
    "        o---o---o    +   o---o---o  ==>   | B | +| A | +| A | +| A | +| B | +| A |\n",
    "        | A | A |        | B | B |        o---o  o---o  o---o  o---o  o---o  o---o\n",
    "        o---o---o        o---o---o        \n",
    "        \n",
    "        Args: \n",
    "            p: percentage of subvolumes to train on\n",
    "    \"\"\"\n",
    "    run_after = [StackVolumes]\n",
    "    \n",
    "    def __init__(self, p = 0.5, n_subvol=2**3, split_along_depth = True):\n",
    "        store_attr()\n",
    "        \n",
    "    def before_batch(self):    \n",
    "        \n",
    "        xb = self.learn.xb\n",
    "        if len(xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')     \n",
    "        self.learn.xb = self.split_volume(xb)\n",
    "        self.learn.yb = self.split_volume(self.learn.yb)\n",
    "        \n",
    "        if self.training:\n",
    "            xb = detuplify(self.learn.xb)\n",
    "            yb = detuplify(self.learn.yb)\n",
    "            draw = tuple(random.sample(range(0, xb.size(0)), int(xb.size(0)*self.p)))\n",
    "            self.learn.xb = (xb[draw, :], )\n",
    "            self.learn.yb = (yb[draw, :], )\n",
    "\n",
    "    def after_pred(self):\n",
    "        if not self.training:\n",
    "            self.learn.xb = self.patch_volume(self.learn.xb)\n",
    "            self.learn.pred = detuplify(self.patch_volume(self.learn.pred))\n",
    "            self.learn.yb = self.patch_volume(self.learn.yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MixSubvol(SplitVolumes):\n",
    "    \"\"\"\n",
    "        After splitting rhe volume into multiple subvolumes, shuffels the subvolumes and sticks the images back together.\n",
    "        \n",
    "        o---o---o        o---o---o        o---o---o        o---o---o\n",
    "        | A | A |        | B | B |        | B | B |        | A | B |\n",
    "        o---o---o    +   o---o---o  ==>   o---o---o    +   o---o---o \n",
    "        | A | A |        | B | B |        | A | A |        | B | A |\n",
    "        o---o---o        o---o---o        o---o---o        o---o---o\n",
    "\n",
    "        \n",
    "        Args: \n",
    "            p: probability that the callback will be applied\n",
    "            n_subvol: number of subvolumina to create\n",
    "            split_along_depth: whether the depth dimension should be included\n",
    "            \n",
    "    \"\"\"\n",
    "    run_after = [StackVolumes]\n",
    "    \n",
    "    def __init__(self, p = 0.25, n_subvol=2**3, split_along_depth = True):\n",
    "        store_attr()\n",
    "        \n",
    "    def before_batch(self):    \n",
    "        if self.training and random.random() < self.p:\n",
    "            xb = self.learn.xb\n",
    "            if len(xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')     \n",
    "            xb = detuplify(self.split_volume(xb))\n",
    "            yb = detuplify(self.split_volume(self.learn.yb))\n",
    "            shuffle = tuple(random.sample(range(0, xb.size(0)), xb.size(0)))\n",
    "            self.learn.xb = self.patch_volume((xb[shuffle, :], ))\n",
    "            self.learn.yb = self.patch_volume((yb[shuffle, :], ))\n",
    "            \n",
    "    def after_pred(self): \n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MixUp3D(Callback):\n",
    "    \"\"\"\n",
    "    Implementation of MixUp for 3D images. \n",
    "    Note that the loss function does not need to be adapted like in fastais MixUp, as MCC and DICE loss accept float values. \n",
    "    \"\"\"\n",
    "    \n",
    "    run_after = [Normalize, StackVolumes]\n",
    "    def __init__(self, p = 0.5):\n",
    "        store_attr()\n",
    "    \n",
    "    def before_batch(self):\n",
    "        if self.training and random.random() < self.p:\n",
    "            if len(self.learn.xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')   \n",
    "            shuffled_idx = list(range(0, detuplify(self.learn.xb).size(0)))\n",
    "            random.shuffle(shuffled_idx)\n",
    "            xj = detuplify(self.learn.xb)[shuffled_idx, :]\n",
    "            yj = detuplify(self.learn.yb)[shuffled_idx, :]\n",
    "            w = random.random()\n",
    "            self.learn.xb = (detuplify(self.learn.xb)*w + xj*(1-w), )\n",
    "            self.learn.yb = (detuplify(self.learn.yb)*w + yj*(1-w), )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, \n",
    "                UResNet3D(n_channels = 3, n_classes = 4),\n",
    "                opt_func = SGD, \n",
    "                loss_func = MCCLossMulti(4),\n",
    "                cbs = [StackVolumes, MixUp3D],\n",
    "               )\n",
    "learn = learn.to_fp16()\n",
    "#learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa, xb, xc, ya, yb = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = torch.cat((xa, xb, xc), dim=1)  \n",
    "shuffle = list(range(0, xi.size(0)))\n",
    "random.shuffle(shuffle)\n",
    "xj = xi[shuffle, :]\n",
    "w = torch.stack([torch.ones(xi.shape[1:])*random.random() for i in range(xi.size(0))]).to(xi.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mix = xi*w + xj*(1-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_3d_images(x_mix, nrow = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_3d_images(xi, nrow = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
