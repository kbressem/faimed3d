{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "\n",
    "The classes and functions in this notebook are highly specific and probably not usefull for the most tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# default_exp callback\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from faimed3d.basics import *\n",
    "from faimed3d.augment import *\n",
    "from faimed3d.data import *\n",
    "from faimed3d.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Path('../../dl-prostate-mapping/data/train') # ../data/train would work to, but with this lon string, I can also test the nb in faimed3d\n",
    "valid = Path('../../dl-prostate-mapping/data/valid')\n",
    "\n",
    "files = list(train.rglob('DICOM')) + list(valid.rglob('DICOM'))\n",
    "\n",
    "# take only T2 images for now\n",
    "t2_files, adc_files, dwi_files = [], [], []\n",
    "for f in files: \n",
    "    m = re.search(r'T2|ADC|DWI', str(f)) \n",
    "    if hasattr(m, 'string'):\n",
    "        if 'T2' in m.string: t2_files.append(Path(m.string)/'cropped_volume.nii.gz') \n",
    "        if 'ADC' in m.string: adc_files.append(Path(m.string)/'cropped_volume.nii.gz') \n",
    "        if 'DWI' in m.string: dwi_files.append(Path(m.string)/'cropped_volume.nii.gz')     \n",
    "            \n",
    "t2_segmentation = [(p.parent.parent/'Annotation/cropped_mask_adapted.nii.gz') for p in t2_files]\n",
    "adc_segmentation = [(p.parent.parent/'Annotation/cropped_mask_adapted.nii.gz') for p in adc_files]\n",
    "\n",
    "mris = DataBlock(\n",
    "    blocks = (ImageBlock3D(cls=TensorDicom3D), \n",
    "              ImageBlock3D(cls=TensorDicom3D), \n",
    "              ImageBlock3D(cls=TensorDicom3D), \n",
    "              MaskBlock3D(codes = ['void', \"peripheral\", 'transitional', 'cancer']), \n",
    "              MaskBlock3D(codes = ['void', \"peripheral\", 'transitional', 'cancer']), \n",
    "             ),\n",
    "    get_x = [lambda x: x[0], lambda x: x[1], lambda x: x[2]],\n",
    "    get_y = [lambda x: x[3], lambda x: x[4]],\n",
    "    item_tfms = ResizeCrop3D(crop_by = (0, 0, 0), resize_to = (16, 80, 80)),\n",
    "    batch_tfms = [\n",
    "        *aug_transforms_3d(p_all=0.15, do_rotate_by = False), \n",
    "        PseudoColor],\n",
    "    splitter = ColSplitter(),\n",
    "    n_inp = 3)\n",
    "\n",
    "d = pd.DataFrame({'T2' : t2_files,\n",
    "                  'ADC': adc_files,\n",
    "                  'DWI': dwi_files,\n",
    "                  'mask_t2' : t2_segmentation, \n",
    "                  'mask_adc': adc_segmentation,\n",
    "                  'is_valid': [1 if 'valid' in str(o) else 0 for o in t2_files]})\n",
    "\n",
    "dls = mris.dataloaders(d, \n",
    "                       batch_size = 10, \n",
    "                       num_workers = 0,\n",
    "                      )\n",
    "dls.valid.bs = 20 # defaults to 64 and will cause Cuda out of Memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitVolumes(Callback):\n",
    "    \"\"\"\n",
    "        Separates a 3D tensor into smaller equal sized subvolumes. \n",
    "\n",
    "        Args: \n",
    "            n_subvol = number of subvolumes\n",
    "            split_along_depth = whether volumes should also be split along the D dimension fpr a [B, C, D, H, W] tensor\n",
    "    \"\"\"\n",
    "    def __init__(self, n_subvol = 2**3, split_along_depth = True):\n",
    "        store_attr()\n",
    "        \n",
    "    def before_batch(self):\n",
    "        xb = self.learn.xb\n",
    "        if len(xb) > 1: raise ValueError('Got multiple items in x batch. You need to concatenate the batch first.')     \n",
    "        self.learn.xb = self.split_volume(xb)\n",
    "        self.learn.yb = self.split_volume(self.learn.yb)\n",
    "\n",
    "    def after_pred(self):\n",
    "        self.learn.xb = self.patch_volume(self.learn.xb)\n",
    "        self.learn.pred = detuplify(self.patch_volume(self.learn.pred))\n",
    "        self.learn.yb = self.patch_volume(self.learn.yb)\n",
    "    \n",
    "    def split_volume(self, xb:(Tensor, TensorDicom3D, TensorMask3D)):\n",
    "        \"splits a large tensor into multiple smaller tensors\"\n",
    "\n",
    "        xb = detuplify(xb) # xb is always a tuple\n",
    "        # calculate number of splits per dimension\n",
    "        self.n = self.n_subvol**(1/3) if self.split_along_depth else self.n_subvol**0.5\n",
    "        self.n = int(self.n)\n",
    "        \n",
    "        # check if shape of dims is divisible by n, if not resize the Tensor acordingly\n",
    "        shape = [s if s % self.n == 0 else s - s % self.n for s in xb.shape[-3:]] \n",
    "        if not self.split_along_depth: shape[0]=xb.shape[0]    \n",
    "        xb = F.interpolate(xb, size = shape, mode = \"trilinear\", align_corners=True)\n",
    "        \n",
    "        # split each dim into smaller dimensions\n",
    "        d, h, w = shape\n",
    "        if self.split_along_depth: xb = xb.reshape(xb.size(0), xb.size(1), self.n, int(d/self.n), self.n, int(h/self.n), self.n, int(w/self.n))\n",
    "        else: xb = xb.reshape(xb.size(0), xb.size(1),1, d, self.n, int(h/self.n), self.n, int(w/self.n))    \n",
    "            \n",
    "        # swap the dimensions an flatten Batchdim and the newly created dims    \n",
    "        # return a tuple as xb is always a tuple\n",
    "        return (xb.permute(1, 3, 5, 7, 0, 2, 4, 6).flatten(-4).permute(4, 0, 1, 2, 3), )\n",
    "\n",
    "    def patch_volume(self, p:(Tensor, TensorDicom3D, TensorMask3D)):\n",
    "        \"patches a prior split volume back together\"\n",
    "        p = detuplify(p)\n",
    "\n",
    "        old_shape = p.shape[0]//self.n_subvol, p.shape[1], *[s * self.n for s in p.shape[2:]]\n",
    "        if not self.split_along_depth: old_shape[2]=p.shape[2]\n",
    "        p = p.reshape(old_shape[0], self.n, self.n, self.n, *p.shape[1:])\n",
    "        return (p.permute(0, 4, 1, 5, 2, 6, 3, 7).reshape(old_shape), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class StackVolumesCallback(Callback):\n",
    "    run_before = SplitVolumes\n",
    "    def before_batch(self):\n",
    "        self.learn.xb = (torch.cat(self.learn.xb, dim=1), )       \n",
    "    \n",
    "        y_one_hot = [self.to_one_hot(y, n_classes = 4) for y in self.learn.yb]\n",
    "        y_cat = torch.stack(y_one_hot).max(dim = 0)[0]\n",
    "        self.learn.yb = (y_cat, )\n",
    "        \n",
    "    def make_binary(self, target, set_to_one):\n",
    "        return (target == set_to_one).float()\n",
    "\n",
    "    def to_one_hot(self, target, n_classes):\n",
    "        target = target.squeeze(1).long() # remove the solitary color channel (if there is one) and set type to int64\n",
    "        one_hot = [self.make_binary(target, set_to_one=i) for i in range(0, n_classes)]\n",
    "        return torch.stack(one_hot, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, \n",
    "                UResNet3D(n_channels = 3, n_classes = 4),\n",
    "                opt_func = SGD, \n",
    "                loss_func = MCCLossMulti(4),\n",
    "                cbs = [StackVolumesCallback, SplitVolumes],\n",
    "               )\n",
    "learn = learn.to_fp16()\n",
    "#learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.914040</td>\n",
       "      <td>1.000124</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
