{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing 3D CNNs\n",
    "\n",
    "The dimension of a CNN does not refer to the dimensions of the input but to the dimensions of the kernel stride.  \n",
    "1D kernel moves only left-right (or up-down)  \n",
    "2D kernel moves left-right and up-down  \n",
    "3D kernel moves left-right, up-down and forward-backwards.   \n",
    "\n",
    "Thus with a kernel of size (3,3,20) a 3D volume of size (150,150,20) could be processed. The present 2D CNN from pytorch and fastai could thus easily be adapted. However, small findings which only occur in a feq slices could disappear in the convolutions, so 3D CNNs with smaller kernels might be better.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models\n",
    "# export \n",
    "from fastai.basics import *\n",
    "import torchvision, torch\n",
    "from torch import nn, Tensor, tensor\n",
    "import torch.nn.functional as F\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buggy\n",
    "\n",
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.register_buffer('noise', tensor(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.expand(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow, in 3D CNNs, the input is not transfered to cuda. I believe something in the transforms is wrong. Until this is fixed, subclassing `nn.Sequential` is the workarround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Sequential_(nn.Sequential):\n",
    "    \"Similar to nn.Sequential, but copies input to cuda\"\n",
    "    def forward(self, input):\n",
    "        for module in self:\n",
    "            input = module(input.cuda())\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet Blocks\n",
    "\n",
    "### Convolutional Blocks\n",
    "\n",
    "Standard Convulutional-Block for UNet adapted for 3D. \n",
    "\n",
    "    1. 3D Convolution with 3**3 Kernel\n",
    "    2. 3D BatchNorm\n",
    "    3. ReLu\n",
    "    4. Repeat 1-3 once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = Sequential_(\n",
    "            nn.Conv3d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double Conv-Block changed to Single ResNet-like Block with Bottleneck-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if not mid_channels: \n",
    "            mid_channels = int(out_channels/2)\n",
    "        \n",
    "        self.res_block = Sequential_(\n",
    "            nn.Conv3d(in_channels, mid_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(mid_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(mid_channels, mid_channels, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            nn.BatchNorm3d(mid_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(mid_channels, out_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.res_block(x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double ResBlock with additional grouping in the middel Layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class DoubleResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if not mid_channels: \n",
    "            mid_channels = out_channels//2\n",
    "        \n",
    "        self.res_block = Sequential_(\n",
    "            # 1st Block\n",
    "            nn.Conv3d(in_channels, mid_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(mid_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(mid_channels, mid_channels, kernel_size = 3, stride = 1, padding = 1, bias = False, groups = 4),\n",
    "            nn.BatchNorm3d(mid_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(mid_channels, mid_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(mid_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),      \n",
    "            nn.ReLU(inplace=True),            \n",
    "            \n",
    "            \n",
    "            # 2nd Block\n",
    "            nn.Conv3d(mid_channels, out_channels, kernel_size = 1, stride = 1, bias = False, groups = 16),\n",
    "            nn.BatchNorm3d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False, groups = 16),\n",
    "            nn.BatchNorm3d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.res_block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = Sequential_(\n",
    "            nn.MaxPool3d(kernel_size = (2, 2, 2)),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class ResDown(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then resblock\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = Sequential_(\n",
    "            nn.MaxPool3d(kernel_size = (2, 2, 2)),\n",
    "            ResBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "    \n",
    "class DoubleResDown(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double res block\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = Sequential_(\n",
    "            nn.MaxPool3d(kernel_size = (1, 2, 2)),\n",
    "            DoubleResBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upscaling Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if trilinear, use the normal convolutions to reduce the number of channels\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2, \n",
    "                        diffZ // 2, diffZ - diffZ // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        \n",
    "        return self.conv(x)\n",
    "\n",
    "class ResUp(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if trilinear, use the normal convolutions to reduce the number of channels\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "            self.conv = ResBlock(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = ResBlock(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2, \n",
    "                        diffZ // 2, diffZ - diffZ // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        \n",
    "        return self.conv(x)\n",
    "    \n",
    "class DoubleResUp(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, trilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if trilinear, use the normal convolutions to reduce the number of channels\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "            self.conv = DoubleResBlock(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleResBlock(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2, \n",
    "                        diffZ // 2, diffZ - diffZ // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        \n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class OutDuoubleRes(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super(OutDuoubleRes, self).__init__()\n",
    "        if mid_channels is None: mid_channels = in_channels // 4\n",
    "        self.conv =  Sequential_(\n",
    "            # 1st Block\n",
    "            nn.Conv3d(in_channels, mid_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(mid_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(mid_channels, mid_channels, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            nn.BatchNorm3d(mid_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(mid_channels, mid_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(mid_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),      \n",
    "            nn.ReLU(inplace=True),            \n",
    "            \n",
    "            \n",
    "            # 2nd Block\n",
    "            nn.Conv3d(mid_channels, out_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            nn.BatchNorm3d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm3d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      \n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def resnet_3d(n_input, n_classes):\n",
    "    return Sequential_(\n",
    "        # 1st Conv Block\n",
    "        nn.Conv3d(n_input, 64, kernel_size = (7,7,7), stride = (2, 2, 2), padding = (3, 3, 3), bias = True),\n",
    "        nn.BatchNorm3d(64, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "\n",
    "        # 2nd Conv Block\n",
    "        nn.Conv3d(64, 128, kernel_size = (5,5,5), stride = (2, 2, 2), padding = (2, 2, 2), bias = True),\n",
    "        nn.BatchNorm3d(128, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "        \n",
    "        # 3rd Conv Block\n",
    "        nn.Conv3d(128, 256, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(256, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "        \n",
    "        # 1st Res Block\n",
    "        nn.Conv3d(256, 384, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(384, 384, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(384, 384, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Conv3d(384, 384, kernel_size = (3,3,3), stride = (1, 1, 1), padding = (1, 1, 1), bias = True),\n",
    "        nn.BatchNorm3d(384, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout3d(),\n",
    "                \n",
    "        nn.AdaptiveAvgPool3d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(384, n_classes), \n",
    "        nn.Softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(20, 128, kernel_size=11, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.AvgPool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.softmax =  nn.LogSoftmax(dim=1)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.device.type == 'cpu': x = x.cuda()\n",
    "        out = self.layer1(x)\n",
    "   #     print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "   #     print(out.shape)\n",
    "        out = self.AvgPool(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.flatten(out)\n",
    "  #      print(out.shape)\n",
    "        out = self.fc1(out)\n",
    " #       print(out.shape)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D UNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AbstractUNet3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AbstractUNet3D, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UNet3D(AbstractUNet3D):\n",
    "    def __init__(self, n_channels, n_classes, trilinear=False):\n",
    "        super(UNet3D, self).__init__()\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if trilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, trilinear)\n",
    "        self.up2 = Up(512, 256 // factor, trilinear)\n",
    "        self.up3 = Up(256, 128 // factor, trilinear)\n",
    "        self.up4 = Up(128, 64, trilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UResNet3D(AbstractUNet3D):\n",
    "    def __init__(self, n_channels, n_classes, trilinear=True):\n",
    "        super(UResNet3D, self).__init__()\n",
    "\n",
    "        self.inc = DoubleResBlock(n_channels, 64)\n",
    "        self.down1 = DoubleResDown(64, 128)\n",
    "        self.down2 = DoubleResDown(128, 256)\n",
    "        self.down3 = DoubleResDown(256, 512)\n",
    "        factor = 2 if trilinear else 1\n",
    "        self.down4 = DoubleResDown(512, 1024 // factor)\n",
    "        self.up1 = DoubleResUp(1024, 512 // factor, trilinear)\n",
    "        self.up2 = DoubleResUp(512, 256 // factor, trilinear)\n",
    "        self.up3 = DoubleResUp(256, 128 // factor, trilinear)\n",
    "        self.up4 = DoubleResUp(128, 64, trilinear)\n",
    "        self.outc = OutDuoubleRes(64, n_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "\n",
    "### DICE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DiceLossBinary():\n",
    "    \n",
    "    \"\"\"\n",
    "    Simple DICE loss as described in: \n",
    "        https://arxiv.org/pdf/1911.02855.pdf    \n",
    "    \n",
    "    Computes the Sørensen–Dice loss. Larger is better. \n",
    "    Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1. \n",
    "    \n",
    "    Args:\n",
    "        targ:    A tensor of shape [B, 1, D, H, W].\n",
    "        pred:    A tensor of shape [B, 1, D, H, W]. Corresponds to\n",
    "                 the raw output or logits of the model.\n",
    "        method:  The method, how the DICE score should be calcualted. \n",
    "                    \"simple\"   = standard DICE loss\n",
    "                    \"miletari\" = squared denominator for faster convergence\n",
    "                    \"tversky\"  = variant of the DICE loss which allows to weight FP vs FN. \n",
    "        alpha, beta: weights for FP and FN for \"tversky\" loss, if both values are 0.5 the \n",
    "                 \"tversky\" loss corresponds to the \"simple\" DICE loss\n",
    "        smooth:  Added smoothing factor. \n",
    "        eps: added to the denominator for numerical stability (acoid division by 0).\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, method = 'miletari', alpha = 0.5, beta = 0.5, eps = 1e-7, smooth = 1.) -> None:\n",
    "        store_attr()\n",
    "    \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        if input.min() < 0 or input.max() > 1: \n",
    "            warn(\"Input is not in range between 0 and 1 but the loss will work better with input in that range. Consider rescaling your input. \")\n",
    "           \n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "\n",
    "        if self.method == 'simple':\n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            denominator  = torch.sum(input + target, dims) + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "\n",
    "        elif self.method == 'miletari':  \n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            denominator  = torch.sum(input**2 + target**2, dims) + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "\n",
    "        elif self.method == 'tversky':\n",
    "            numerator  = torch.sum(input * target, dims) + self.smooth\n",
    "            fps = torch.sum(input * (1 - target), dims)\n",
    "            fns = torch.sum((1 - input) * target, dims)\n",
    "\n",
    "            denominator  = numerator + self.alpha*fps + self.beta*fns + self.smooth\n",
    "            dice_loss = (2. * numerator / (denominator + self.eps))\n",
    "            \n",
    "        else: \n",
    "            raise NotImplementedError('The specified type of DICE loss is not implemented')\n",
    "\n",
    "        return 1-dice_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class DiceLossMulti(DiceLossBinary):\n",
    "    def __init__(self, n_classes, weights=None, **kwargs):\n",
    "        store_attr()\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def __call__(self, input:Tensor, target:Tensor) -> Tensor:\n",
    "        self.get_weights(input)\n",
    "\n",
    "        if target.size(1) == 1:\n",
    "            target = self.to_one_hot(target)\n",
    "        elif target.size(1) != input.size(1):\n",
    "            raise ValueError(\"Number of Channels between input and target do not match.\"\n",
    "                             \"Expected target to have 1 or {} channels but got {}\".format(input.size(1), target.size(1)))\n",
    "        input = self.activation(input)\n",
    "        return torch.mean(super().__call__(input, target)*self.weights)\n",
    "    \n",
    "    def get_weights(self, target):\n",
    "        if self.weights == 'auto':\n",
    "            \"estimates weights from the percentage distribution of a finding.\"\n",
    "            dims = (0,) + tuple(range(2, target.ndim))\n",
    "            self.weights = 1/torch.mean(target, dims)\n",
    "        elif self.weights == None:\n",
    "            self.weights = 1.\n",
    "        elif isinstance(self.weights, (tuple, list)):\n",
    "            self.weights = tensor(self.weights)\n",
    "\n",
    "    def make_binary(self, t, set_to_one):\n",
    "        return (t == set_to_one).float()\n",
    "\n",
    "    def to_one_hot(self, target:Tensor):\n",
    "        target = target.squeeze(1).long() # remove the solitary color channel (if there is one) and set type to int64\n",
    "        one_hot = [self.make_binary(target, set_to_one=i) for i in range(0, self.n_classes)]\n",
    "\n",
    "        return torch.stack(one_hot, 1)\n",
    "\n",
    "    def activation(self, input):\n",
    "        return F.softmax(input, 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCC Loss\n",
    "\n",
    "Implementing the MCC score as loss function:  \n",
    "\n",
    "\n",
    "$$\\frac{ \n",
    "        \\sum_{i}^{n} p_{ i }g_{ i } * \\sum_{i}^{n}  1-p_{ i } 1-g_{ i } +\n",
    "        \\sum_{i}^{n}  1-p_{ i } g_{ i } * \\sum_{i}^{n}  p_{ i } 1-g_{ i }}{ \\sqrt{ \n",
    "        (\\sum_{i}^{n}  p_{ i } g_{ i } + \\sum_{i}^{n}  1-p_{ i } g_{ i }) * \n",
    "        (\\sum_{i}^{n}  p_{ i } g_{ i } + \\sum_{i}^{n} p_{ i } 1-g_{ i }) *  \n",
    "        (\\sum_{i}^{n}  1-p_{ i } g_{ i } + \\sum_{i}^{n} 1-p_{ i } 1-g_{ i }) * \n",
    "        (\\sum_{i}^{n}  p_{ i } 1-g_{ i } + \\sum_{i}^{n} 1-p_{ i } 1-g_{ i }) \n",
    "     } }$$\n",
    "\n",
    "where p_i is the prediction for pixel i and g_i the corresponding ground truth pixel and gamma is the smoothing factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MCCLossBinary(DiceLossBinary):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the MCC loss. \n",
    "    \n",
    "    From Wikipedia (https://en.wikipedia.org/wiki/Matthews_correlation_coefficient):\n",
    "        > The coefficient takes into account true and false positives and negatives and is generally \n",
    "        > regarded as a balanced measure which can be used even if the classes are of very different sizes\n",
    "        > The MCC is in essence a correlation coefficient between the observed \n",
    "        > and predicted binary classifications; it returns a value between −1 and +1. \n",
    "        > A coefficient of +1 represents a perfect prediction, 0 no better than random prediction\n",
    "        > and −1 indicates total disagreement between prediction and observation    \n",
    "    \n",
    "    For this loss to work best, the input should be in range 0-1, e.g. enforced through a sigmoid or softmax. \n",
    "    Note that PyTorch optimizers minimize a loss. So the loss is subtracted from 1. \n",
    "\n",
    "    Math: \n",
    "        \\frac{ \n",
    "            \\sum_{i}^{n} p_{ i }g_{ i } * \\sum_{i}^{n}  1-p_{ i } 1-g_{ i } +\n",
    "            \\sum_{i}^{n}  1-p_{ i } g_{ i } * \\sum_{i}^{n}  p_{ i } 1-g_{ i }}{ \\sqrt{ \n",
    "            (\\sum_{i}^{n}  p_{ i } g_{ i } + \\sum_{i}^{n}  1-p_{ i } g_{ i }) * \n",
    "            (\\sum_{i}^{n}  p_{ i } g_{ i } + \\sum_{i}^{n} p_{ i } 1-g_{ i }) *  \n",
    "            (\\sum_{i}^{n}  1-p_{ i } g_{ i } + \\sum_{i}^{n} 1-p_{ i } 1-g_{ i }) * \n",
    "            (\\sum_{i}^{n}  p_{ i } 1-g_{ i } + \\sum_{i}^{n} 1-p_{ i } 1-g_{ i }) \n",
    "         } }\n",
    "\n",
    "    Args:\n",
    "        input:   A tensor of shape [B, 1, D, H, W]. Predictions. \n",
    "        target:  A tensor of shape [B, 1, D, H, W]. Ground truth. \n",
    "        smooth:  Smoothing factor, default is 1. Inherited from DiceLossBinary base class \n",
    "        eps:     Added for numerical stability.\n",
    "    Returns:\n",
    "        mmc_loss: loss based on Matthews correlation coefficient\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:         \n",
    "        return self.compute_loss(input, target)\n",
    "    \n",
    "    def activation(self, input):\n",
    "        return torch.sigmoid(input)\n",
    "       \n",
    "    def compute_loss(self, input: Tensor, target: Tensor):\n",
    "        \n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "        \n",
    "        tps = torch.sum(self.activation(input) * target, dims) \n",
    "        fps = torch.sum(self.activation(input) * (1 - target), dims)\n",
    "        fns = torch.sum((1 - self.activation(input)) * target, dims)\n",
    "        tns = torch.sum((1 - self.activation(input)) * (1-target), dims)\n",
    "            \n",
    "        numerator = (tps * tns - fps * fns) + self.smooth \n",
    "        denominator =  ((tps + fps) * (tps + fns) * (fps + tns) * (tns + fns) + self.eps)**0.5 + self.smooth\n",
    "        \n",
    "        mcc_loss = numerator / (denominator)\n",
    "        \n",
    "        return 1-mcc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9982])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.randn(5,1,2,25,25).sigmoid()\n",
    "t = torch.randn(5,1,2,25,25).sigmoid().round()\n",
    "\n",
    "MCCLossBinary()(i, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MCCLossMulti(MCCLossBinary):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the MCC loss for a multilabel target. Basically the same as `MCCLossBinary` \n",
    "    but one hot encodes the target before computation. \n",
    "    \n",
    "    Args:\n",
    "        num_features: Number of different features in y. \n",
    "                 Must correspond to the maximum number of overall features in the whole dataset.\n",
    "        input:   A tensor of shape [B, C, D, H, W], where the `n_classes` should correspond to C.\n",
    "        target:  A tensor of shape [B, 1, D, H, W] or [B, C, D, H, W] where C is the same size as in the input.  \n",
    "        weights: Either a str: 'auto' for autocalculation, None or a list/tuple of soecified weights\n",
    "        smooth:  Smoothing factor, default is 1. Inherited from DiceLossBinary base class \n",
    "        eps:     Added for numerical stability.\n",
    "        n_classes: number of classes to predict\n",
    "    Returns:\n",
    "        mcc_loss: loss based on Matthews correlation coefficient\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes, weights=None, **kwargs):\n",
    "        store_attr()\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def __call__(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        \n",
    "        self.get_weights(input)\n",
    "        \n",
    "        if target.size(1) == 1:\n",
    "            target = self.to_one_hot(target)\n",
    "        elif target.size(1) != input.size(1):\n",
    "            raise ValueError(\"Number of Channels between input and target do not match.\"\n",
    "                             \"Expected target to have 1 or {} channels but got {}\".format(input.size(1), target.size(1)))\n",
    "            \n",
    "        return torch.mean(super().__call__(input, target)*self.weights)\n",
    "    \n",
    "    def get_weights(self, target):\n",
    "        if self.weights == 'auto': \n",
    "            \"estimates weights from the percentage distribution of a finding.\"\n",
    "            dims = (0,) + tuple(range(2, target.ndim))\n",
    "            self.weights = 1/torch.mean(target, dims)\n",
    "        elif self.weights == None: \n",
    "            self.weights = 1.\n",
    "        elif isinstance(self.weights, (tuple, list)):\n",
    "            self.weights = tensor(self.weights)\n",
    "    \n",
    "    def make_binary(self, t, set_to_one):\n",
    "        return (t == set_to_one).float()\n",
    "  \n",
    "    def to_one_hot(self, target:Tensor):\n",
    "        target = target.squeeze(1).long() # remove the solitary color channel (if there is one) and set type to int64\n",
    "        one_hot = [self.make_binary(target, set_to_one=i) for i in range(0, self.n_classes)]\n",
    "        return torch.stack(one_hot, 1)\n",
    "    \n",
    "    def activation(self, input): \n",
    "        return F.softmax(input, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0057)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.randn(5,5,2,25,25)\n",
    "t = torch.randint(0, 5, (5,1,2,25,25))\n",
    "\n",
    "MCCLossMulti(5)(i, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SoftMCCLossMulti(MCCLossMulti):\n",
    "    \"\"\"\n",
    "    Same as MCCLossMulti but can handle float values. \n",
    "    Example: \n",
    "        t = torch.randn(2,5); t\n",
    "        >>> tensor([[ 0.9113, -0.7525, -2.1771, -0.2420, -0.2245],\n",
    "                    [ 1.9503, -1.2903,  0.1201,  0.2830,  0.0473]])\n",
    "                   \n",
    "        MCCLossMulti(2).make_binary(t, 1)\n",
    "        >>> tensor([[0., 0., 0., 0., 0.],\n",
    "                    [0., 0., 0., 0., 0.]])\n",
    "        \n",
    "        SoftMCCLossMulti(2).soft_binary(t, 0)\n",
    "        >>> tensor([[0.9113, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "                    [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
    "    \"\"\"\n",
    "    \n",
    "    def soft_binary(self, t, set_to_one):\n",
    "        return torch.where(t.gt(set_to_one - 0.49) != t.gt(set_to_one + 0.49), \n",
    "                           t.float(), \n",
    "                           tensor(0.).to(t.device) if set_to_one > 0 else tensor(1.).to(t.device))\n",
    "    \n",
    "    def to_one_hot(self, target:Tensor):\n",
    "        target = target.squeeze(1) # remove the solitary color channel (if there is one) and set type to int64\n",
    "        one_hot = [self.soft_binary(target, set_to_one=i) for i in range(0, self.n_classes)]\n",
    "        return torch.stack(one_hot, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0087)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SoftMCCLossMulti(5)(i, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class WeightedMCCLossMulti(MCCLossMulti):\n",
    "    \"\"\"\n",
    "    Weighted version of `MCCLossMulti`. \n",
    "    Note that class specific weight can still be added through `weights` during initialization. \n",
    "    \n",
    "    Args: \n",
    "        alpha: weight for true positives\n",
    "        beta: weight for false positives\n",
    "        gamma: weight for false negatives\n",
    "        delta: weight for true negatives\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=0.5, delta=0.5,*args, **kwargs):\n",
    "        \"alpha and beta are already inherited from `DiceLossBinary`\"\n",
    "        store_attr()\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compute_loss(self, input: Tensor, target: Tensor):\n",
    "\n",
    "        dims = (0,) + tuple(range(2, target.ndim))\n",
    "\n",
    "        tps = torch.sum(self.activation(input) * target, dims) \n",
    "        fps = torch.sum(self.activation(input) * (1 - target), dims) \n",
    "        fns = torch.sum((1 - self.activation(input)) * target, dims)\n",
    "        tns = torch.sum((1 - self.activation(input)) * (1-target), dims)\n",
    "\n",
    "        numerator = (tps * tns - fps * fns) + self.smooth\n",
    "        denominator =  ((tps * self.alpha + fps * self.beta) * (tps * self.alpha + fns * self.gamma) * (fps * self.beta + tns * self.delta) * (tns * self.delta + fns * self.gamma) + self.eps)**0.5 + self.smooth\n",
    "\n",
    "        mcc_loss = numerator / (denominator)\n",
    "\n",
    "        return 1-mcc_loss\n",
    "    \n",
    "    def activation(self, x): \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MCCScore(MCCLossMulti):\n",
    "    def __init__(self, n_classes = None, thres = 0.5, **kwargs):\n",
    "        super().__init__(n_classes, **kwargs)\n",
    "        \n",
    "        self.n_classes = 1 if n_classes is None else n_classes\n",
    "        self.thres = thres\n",
    "    \n",
    "    def __call__(self, input:Tensor , target: Tensor):\n",
    "        if self.n_classes is not None: \n",
    "            target = self.to_one_hot(target)\n",
    "            \n",
    "            return 1-torch.mean(super().__call__(input, target))\n",
    "        \n",
    "    def activation(self, input): \n",
    "        return (input > self.thres).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0050)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCCScore()(i, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schätzung der TP, TN, FP, FN durch Regression\n",
    "\n",
    "Um den Sensitivität und Spezifität berechen zu können müssen zuerst die TP, FP, TN und FN erechnet werden. \n",
    "Allerdings ist es auch Möglich die Sensitivität und Spezifität durch eine logistische Regression zu ermitteln (https://doi.org/10.1016/0895-4356(92)90180-u). \n",
    "Die log odds von Sensitivität und Spezifität können als folgende Funktion dargestellt werden:\n",
    "\n",
    "\n",
    "$$ logit Pr(Y=1 | X) = \\alpha + \\sum_{k=1}^{K} \\beta_{k}X_{k}$$\n",
    "\n",
    "Die Schäzung der logit Sensitivität und logit Spezifität geschieht aus $(1...k)$ Variablen mit ihren entsprechenden Betacoeffizienten, wobei eine dieser Variablen dem Goldstandard entspricht. \n",
    "\n",
    "Die Ermittlung der Sensitivität ist daraufhin: \n",
    "$$\\frac{1}{1+exp(-(\\alpha+\\sum_{k=1}^{K}\\beta_{k}X_{k})} \\quad \\textrm{wobei} \\quad X_{k}=1$$\n",
    "\n",
    "\n",
    "Die Ermittlung der Spezifität ist ähnlich: \n",
    "$$1-(\\frac{1}{1+exp(-(\\alpha+\\sum_{k=1}^{K}\\beta_{k}X_{k}}) \\quad \\textrm{wobei} \\quad X_{k}=0$$\n",
    "\n",
    "\n",
    "von hier aus können Rückschlüsse auf die TP und TN gezogen werden durch: \n",
    "\n",
    "$$TP = Sens * P \\quad \\textrm{wobei} \\quad P = \\sum_{k=1}^{K} X_{k} \\quad \\textrm{fuer} \\quad X=1$$\n",
    "\n",
    "$$TN = Spec * N \\quad \\textrm{wobei} \\quad N = \\sum_{k=1}^{K} X_{k} \\quad \\textrm{fuer} \\quad X_{k}=0$$\n",
    "\n",
    "$$FN = (1-Sens) * P \\quad \\textrm{wobei} \\quad P = \\sum_{k=1}^{K} X_{k} \\quad \\textrm{fuer} \\quad X_{k}=1$$\n",
    "\n",
    "$$FP = (1-Spec) * N \\quad \\textrm{wobei} \\quad N = \\sum_{k=1}^{K} X_{k} \\quad \\textrm{fuer} \\quad X_{k}=0$$\n",
    "\n",
    "\n",
    "Wenn $X$ in $(0...1)$ dann kann $N = \\sum_{k=1}^{K} 1-X_{k} \\quad \\textrm{fuer} \\quad X=1$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (fastai v2)",
   "language": "python",
   "name": "fastai-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
